### **Breaking the Resolution Barrier: Arbitrary-resolution Deep Image** **Steganography Framework**

**Xinjue Hu** [1], **Chi Wang** [1], **Boyu Wang** [1], **Xiang Zhang** [1], **Zhenshan Tan** [1] and **Zhangjie Fu** [1] _[∗]_

1Engineering Research Center of Digital Forensics, Ministry of Education, Nanjing University of
Information Science and Technology
_{_ huxinjue, 202412200715, 202412200714, zhangxiang, zstan, fzj _}_ @nuist.edu.cn



**Abstract**


Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image
to maintain the same resolution as the cover image during hiding and revealing. This leads to two
challenges: secret images with inconsistent resolutions must undergo resampling beforehand which
results in detail loss during recovery, and the secret
image cannot be recovered to its original resolution
when the resolution value is unknown. To address
these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm
from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch,
we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into
a resolution-aligned global basis and a resolutionagnostic high-frequency latent to hide in a fixedresolution cover. Second, for recovery, we propose
a Latent-Guided Implicit Reconstructor to perform
deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency
residuals onto the recovered global basis, ensuring
faithful restoration of original details. Furthermore,
to achieve blind recovery, we introduce an Implicit
Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and
hiding them in the redundant space of the feature
domain, the reconstructor can correctly decode the
secret’s resolution directly from the steganographic
representation. Experimental results demonstrate
that ARDIS significantly outperforms state-of-theart methods in both invisibility and cross-resolution
recovery fidelity.


**1** **Introduction**

Deep image steganography aims to hide a secret image within
a cover image imperceptibly while ensuring the receiver can


*Corresponding authors.



Figure 1: Overview of our ARDIS compared with existing methods. (a) Existing methods: The sender must manually resample the
secret image to the same resolution as the cover image to hide it,
and the recovered secret image will look strange due to the different resolution (e.g., different aspect ratio). (b) Our ARDIS enables
arbitrary-resolution hiding and high-fidelity blind restoration.


recover the secret image with high fidelity. Due to its covert
nature, it has been widely applied in copyright protection

[Zhang _et al._, 2024a; Zhang _et al._, 2024b], digital forensics

[Zhang _et al._, 2025], military communications [Wani _et al._,
2022], etc.

Existing DIS methods are mainly based on three architectures. Autoencoder-based methods [Baluja, 2017] rely
on end-to-end encoder-decoder networks, which are prone
to information loss due to repeated downsampling or nonlinear transformations. Methods based on invertible neural
networks (INNs) [Lu _et al._, 2021] model the hiding and revealing of the secret image as a pair of bijective mappings
with shared parameters, which theoretically avoids information loss and thus enables near-lossless high-quality hiding.
Recently, some works have introduced diffusion models [Ho
_et al._, 2020a] into steganography [Yu _et al._, 2023], using



Sender



What? Resampling will
lose a lot of details. Receiver Why so strange



Receiver



and blurry?



Resampling

(256×256)


Secret
(256×1024) Cover
(256×256)



Stego
(256×256)


**(a) Existing methods**



Re-secret
(256×256)

**Wrong**
**Resolution!**



Sender


Secret
(256×1024)



Global basis


Detail latent


Resolution
information

Frequency decoupling



Wow! I can hide secret
image of any resolution Perfect!

Receiver



Re-secret
(256×1024)



Stego
(256×256)



Global basis


Detail latent


256×1024



Cover (256×256)



**(b) Our ARDIS**


prompts to guide the hiding and revealing process. However,
their random sampling nature often limits pixel-level reconstruction accuracy.
Despite their architectural differences, existing methods
share a critical limitation: the **fixed-resolution constraint** .
They formulate DIS as a discrete pixel-mapping problem,
learning local mappings on spatially aligned pixels. This
paradigm requires the secret and cover images to own the
same dimension. This constraint presents two challenges in
real-world applications, as shown in Figure 1. **First, Resolu-**
**tion Mismatch Dilemma** : When the secret image differs in
resolution from the cover, the sender must preform native resampling on the secret image, resulting in irreversible loss of
high-frequency details in the recovered secret image. **Second,**
**Blind Recovery Incapacity** : The receiver cannot obtain the
resolution information of the secret image in advance, which
means they can only recover a secret image with the same resolution as the cover image, but it is wrong. Relying on external transmission of metadata violates the principle of covert
communication.
To bridge this gap, we propose ARDIS, the first ArbitraryResolution DIS framework. First, in order to solve the problem of detail loss caused by forced resampling under resolution mismatch at the sender side, our design is based on
an intuitive idea: global low-frequency information is robust
to resampling, but high-frequency details are highly susceptible. If they are processed as a whole, the fragile highfrequency details will inevitably be damaged due to resolution alignment constraints. Therefore, we propose frequency
decoupling framework to decouple the secret image into a
global visual basis and high-frequency detail latent information. The former characterizes global semantic cues and is
aligned with the cover image’s resolution. The latter carries high-frequency residuals in a compressed, resolutionagnostic representation. This decoupling mechanism eliminates the impact of alignment constraints, ensuring that highfrequency details are not involved in lossy operations. Second, we find that the problem of lost detail in the recovered
secret image caused by resolution mismatch stems from the
limitations of the discrete pixel mapping paradigm: due to
the limitations of fixed resolution, it must rely on interpolation operations when recovering secrets with wrong resolutions. To overcome this limitation, we shift the DIS paradigm
from discrete pixel mapping to reference-guided continuous
signal reconstruction, and design a latent-guided implicit reconstructor, which is a deterministic coordinate query in continuous space. We utilize the extracted high-frequency latent
information as a conditional prior to modulate the implicit
function, projecting the precise original high-frequency residuals onto the global basis to obtain a high-fidelity arbitraryresolution secret image. Finally, to enable our reconstructor
to perform blind recovery without violating steganography
protocols, we introduce an implicit resolution encoding strategy. Simply hiding the resolution as a discrete scalar is extremely fragile, because the recovery process is not lossless,
and small numerical fluctuations can lead to errors in resolution metadata. Therefore, we utilize the spatial redundancy of
feature channels, broadcasting the resolution data into a dense
feature map and embedding it, which provides a certain de


gree of fault tolerance. The receiver can adaptively infer the
correct original resolution from the stego image, eliminating
the dependence on external metadata.
Our contributions can be summarized as follows:


1. To our knowledge, the proposed ARDIS is the first
arbitrary-resolution DIS framework, effectively breaking the long-standing fixed-resolution constraint.

2. We design a frequency decoupling architecture for
structure-detail separation of secret images at arbitrary
resolutions. It encodes high-frequency textures that cannot be spatially aligned into a resolution-agnostic latent representation, thereby removing the dependence on
cover-secret resolution alignment.

3. We propose a latent-guided implicit reconstructor that
reformulates DIS recovery process as continuous image
reconstruction based on a high-frequency detail latent,
enabling high-fidelity texture recovery at arbitrary resolutions.

4. We introduce an implicit resolution coding strategy that
leverages spatial redundancy in the feature domain to
implicitly embed resolution priors, achieving geometryconsistent blind recovery when the secret resolution is
unknown.


**2** **Related Work**
**Autoencoder-based DIS methods.** Baluja [Baluja, 2017;
Baluja, 2019] first introduced deep learning into image
steganography, modeling the task as an end-to-end encodingdecoding process. Subsequent researchers have improved
steganographic performance by designing various network
architectures [Hayes and Danezis, 2017; Rahim _et al._, 2018;
Duan _et al._, 2019; Yu, 2020; Zhang _et al._, 2020; Ke _et al._,
2024; Liu _et al._, 2025]. However, since the parameters of the
hiding and revealing networks are not shared, it is difficult to
achieve a perfect balance between the visual imperceptibility of the stego image and the recovery fidelity of the secret
image.
**INNs-based DIS methods.** To address the aforementioned
trade-off, inspired by the success of Invertible Neural Networks (INNs) [Dinh _et al._, 2014; Dinh _et al._, 2016] in fields
such as image translation [van der Ouderaa and Worrall,
2019], researchers have attempted to reconstruct the steganographic task by leveraging the strict invertibility of INNs [Lu
_et al._, 2021; Jing _et al._, 2021; Xu _et al._, 2022; Duan _et al._,
2024; Li _et al._, 2024; Luo _et al._, 2024; Wang _et al._, 2025;
Zhou _et al._, 2025]. For example, ISN [Lu _et al._, 2021] first
exploited this property to model the hiding and revealing processes as reciprocal mathematical transformations. HiNet

[Jing _et al._, 2021] further enhanced the hiding capacity for
high-frequency information by incorporating wavelet transforms. Although these methods achieve near-lossless hiding
and recovery, they strictly rely on the spatial alignment of input and output dimensions, rendering them incapable of handling cross-scale steganography scenarios with mismatched
resolutions.
**Diffusion-based DIS methods.** Recently, with the rapid development of AIRC, Diffusion Models [Ho _et al._, 2020b;


**Hiding Stage**

**Frequency Decoupling**

**R**



**X** _s_


**n**



**R**



**X** _c_


**A** **V**
**H** **D**

**DWT**



**A** **V**
**H** **D**

**DWT**

## **c**


**DHVA**



**Invertible Hiding Network**


**Revealing Stage**



_**e**_
_**φ**_ _**γ**_

_**η**_



**DHVA**

**IWT**



**X** _g_


**X** _d_


**M** _r_



**...**



**X** _sec_


_Hsec,Wsec_


**X** _rs_



**Detail**
**encoder**
# **-**


## **c**

**MLP**
...

**MLP**


_pr_



**r**



**Implicit Resolution Coding**


**Spatial stripe**

**broadcasting**


**R**


_**zt**_ ***** **c** **(Δ** _**x**_ **,Δ** _**y**_ **)**



**Feature**
**extractor**



_**γ**_
_**e**_



...



**X** _rc_



**z**


## c X rg X rc IWT φ η



**X** _rg_



**X** _s_


**n** ’



**IWT**



_z_ 00* _z_ 01*

_x_ ~~_q_~~


_z_ 10* _z_ 11*



**A** **V**
**H** **D**

**DWT**



**Feature**
**extractor** **IWT**



**DHVA**



_Mrr_



_**H**_ **ˆ** **sec,** _**W**_ **ˆsec**



**X** _rd_


**Voting-based**
**denoising decoding**



**Invertible Hiding Network**


**R**
## **c**
# Subtract - Concat Add Multiply Resample



**Latent-Guided Implicit Reconstructor**



Figure 2: **Overview of the proposed ARDIS,** which supports hiding and revealing secret images at arbitrary resolutions.



Song _et al._, 2020] have been introduced into the steganography domain due to their powerful capability in modeling
data distributions. CRoSS [Yu _et al._, 2023] leverages the randomness in the generation of diffusion models to design a
training-free steganography scheme. DiffStega [Yang _et al._,
2024] further added a preset password to avoid the risk of
text prompts leaking information. However, diffusion models are fundamentally probabilistic generation processes, and
their reverse sampling process possesses inherent randomness. This results in uncontrollable detail hallucinations or
deviations during the recovery phase, making it difficult to
achieve pixel-level precise restoration. Furthermore, these
methods also fail to break free from the dependence on fixed
resolutions.


**3** **Method**


**3.1** **Overview**


Our method consists of two stages: hiding and revealing. In
hiding stage, shown in Figure 2 (top), we first decouple the
arbitrary-resolution secret image **X** _sec_ into a global visual basis **X** _g_, which matches the resolution of the cover **X** _c_, and a
high-frequency detail latent code **X** _d_ via the frequency decoupling architecture (FDA). Simultaneously, the spatial di


mensions value ( _Hsec, Wsec_ ) are encoded into a feature map
**M** _e_ via the implicit resolution coding strategy (IRC). **X** _c_,
**X** _g_, and **X** _d_ are converted into frequency features using discrete wavelet transform (DWT), and then fed along with **M** _e_
into an invertible hiding network (IHN) consisting of a series
of hidden blocks. The output of the last hidden blockof the
IHN is then go through an inverse wavelet transform (IWT)
to generate the stego image **X** _s_ and the lost information **n** .
In revealing stage, shown in Figure 2 (bottom), **X** _s_ and auxiliary variable **n** _[′]_ are processed by DWT, inverse IHN, and
IWT operations to obtain the recovered global visual basis
**X** _rg_, detail latent code **X** _rd_, and resolution map **M** _re_ . _Mre_
is decoded into the original dimensions via a resolution decoder. Subsequently, the recovered secret image **X** _rs_ is reconstructed by latent-guided implicit reconstructor (LGIR).
Explicitly conditioned on the detail latent, the reconstructor
performs continuous spatial queries to predict fine-grained
residuals _pr_, enabling high-fidelity secret image reconstruction at arbitrary target resolutions. FDA, LGIR, and IRC are
detailed in Sections 3.2, 3.3, and 3.4, respectively.


**3.2** **Frequency Decoupling Architecture**


Frequency Decoupling Architecture (FDA) is designed to disentangles the secret into a resolution-aligned global basis and


a resolution-agnostic high-frequency latent code.
Formally, Given a secret image **X** _sec ∈_ R _[H][sec][×][W][sec][×]_ [3] and
a cover image **X** _c ∈_ R _[H][c][×][W][c][×]_ [3], we define an adaptive resampling operator _R_ ( **X** _,_ ( _H, W_ )), which can adjust the input **X** _∈_ R _[H][x][×][W][x][×]_ [3] to the target size ( _H, W_ ) through bicubic interpolation. This operator can automatically perform
downsampling (when _Hx > H_ or _Wx > W_ ) and upsampling (when _Hx < H_ or _Wx < W_ ) according to the actual
situation. First, we extract the global visual basis **X** _g_ :


**X** _g_ = _R_ ( **X** _sec,_ ( _Hc, Wc_ )) _,_ (1)


where **X** _g_ is resolution-aligned with **X** _c_, preserving the basic
global topological structure. It’s worth noting that we choose
explicit resampling over a general global extractor for this operation. This is because a learnable extractor introduces complex nonlinear global distortions, whereas resampling is a linear operation that strictly limits decoupled detail residuals to
high frequencies and is spatially sparse. This is a prerequisite
for subsequent detail encoding operations.
Then, we calculate the precise detail loss **r** _∈_
R _[H][sec][×][W][sec][×]_ [3] :


**r** = **X** _sec −R_ ( **X** _g,_ ( _Hsec, Wsec_ )) _._ (2)


By explicitly resampling **X** _g_ back to the original resolution and calculating the residual, we can precisely capture
the pixel-level detail loss during the alignment process. **r** is
spatially sparse, mainly existing at edges and texture variations, thus it has high compressibility. Finally, we utilize a
lightweight detail encoder _Edetail_ to encode _r_ into a compact
high-frequency detail latent:


**X** _d_ = _Edetail_ ( _r_ ) _,_ (3)


where **X** _d ∈_ R _[H][c][×][W][c][×][c][lat]_ . Through adaptive spatial processing, _Edetail_ transforms the arbitrary-resolution **r** into the
fixed resolution latent. Although **X** _d_ is spatially aligned with
the cover for embedding, it is effectively used as a resolutionagnostic continuous prior for the subsequent reconstruction.


**3.3** **Latent-Guided Implicit Reconstructor**


We propose Latent-Guided Implicit Reconstructor (LGIR),
redefining the recovery process of the arbitrary-resolution
secret image as a reference-guided deterministic continuous
signal reconstruction, ensuring high-fidelity recovery of the
secret image.
Inspired by Local Implicit Image Function (LIIF) [Chen _et_
_al._, 2021], we define a decoding function _ϕθ_ to map continuous 2D coordinates **x** _∈_ R [2] to RGB values **s** _∈_ R [3] of the
secret image:


**s** = _ϕθ_ ( **z** _, δ, c_ ) _,_ (4)


where _c_ = [ _ryH_ 2 _sec_ _[,]_ _rxW_ 2 _sec_ []][ is the cell decoding,] _[ r][y]_ [ and] _[ r][x]_ [ are]
variable scaling factors. _δ_ represents the relative coordinate.
**z** is a feature vector, extracted differently from standard LIIF.



LIIF relies solely on low-resolution input to extract **z** and infers missing details from blurred information. It only optimizes statistical plausibility rather than instance fidelity, inevitably introducing generic hallucinations. This constitutes
a fatal flaw for deep image steganography which demands
precise recovery. In contrast, we introduce the recovered detail latent code as a deterministic conditional mechanism:


**z** = [ _Eg_ ( **X** _rg_ ) _, Ed_ ( **X** _rd_ )] (5)


where _Eg_ and _Ed_ are feature encoder. Furthermore, in order
to recover the original resolution secret image **X** _rs_, where the
resolution is calculated by the resolution decoder in the IRC
(mentioned in section 3.5), we define the query coordinates
**x** _q_ of **X** _rs_ at the target resolution. The RGB value at **x** _q_ can
be reconstructed from the nearest surrounding latent codes
**z** _[∗]_ _t_ _[, t][ ∈{]_ [00] _[,]_ [ 01] _[,]_ [ 10] _[,]_ [ 11] _[}]_ [,]



where I( _·_ )is defined as:


�1 _,_ if _C_ is True
I( _C_ ) = _._ (9)
0 _,_ otherwise



**X** _rs_ ( **x** _q_ ) = 


_ωtϕθ_ ( **z** _[∗]_ _t_ _[,]_ **[ x]** _[q]_ _[−]_ **[v]** _t_ _[∗][, c]_ [)]
_t_



_t_ (6)

+ _R_ ( **X** _rg,_ ( _Hsec, Wsec_ ))( **x** _q_ ) _,_



where **v** _t_ _[∗]_ [is the coordinate of] **[ z]** _t_ _[∗]_ [,] _[ ω][t]_ [is calculated based on]
the area of the rectangle formed by **x** _q_ and **x** _[∗]_ _t_ [, and satisfies]


_t_ _[ω][t]_ [ = 1][. This formulation explicitly compels the implicit]
function to synthesize missing textures guided by the detail
latent, ensuring faithful restoration across continuous scales.



**3.4** **Implicit Resolution Coding Strategy**

We propose an implicit resolution coding strategy (IRC) to
address the problem that the receiver cannot recover the original resolution the secret image in blind recovery scenarios.
During the hiding stage, for the resolution ( _Hsec, Wsec_ )
of the secret image, we first quantize it into a L-bit binary
sequence **b** _∈{_ 0 _,_ 1 _}_ _[L]_ . To resist potential distortion from
subsequent IHN convolution operations, we design a spatial
stripe broadcasting mechanism to generate a resolution feature map **M** _r ∈_ R _Hc_ 2 _[×]_ _[Wc]_ 2 . This map is spatially aligned with



2 _[×]_ _[Wc]_ 2



ture map **M** _r ∈_ R 2 _[×]_ 2 . This map is spatially aligned with

the cover features after DWT and is partitioned into _L_ disjoint
horizontal stripes, denoted as _{_ Ω _k}_ _[L]_ _k_ =1 [. For the] _[ k]_ [-th bit] _[ b][k]_ [ in]
**b**, we map it to a specific stripe region Ω _k_ in the **M** _r_ :


**M** _r_ ( _x, y_ ) = 2 _bk −_ 1 _,_ _∀_ ( _x, y_ ) _∈_ Ω _k._ (7)


where the mapped values are normalized to _{−_ 1 _,_ 1 _}_,which
ensures the zero-mean property, thus aligning with the underlying spatial distribution of the subsequent IHN.
During the revealing stage, since the recovered resolution
map **M** _rr_ contain some distortion _ϵ_, we design a voting-based
denoising decoding mechanism:















 _>_ 0



ˆ _bk_ = I







 [1]







 _._ (8)



_|_ Ω _k|_



**M** _rr_ ( _x, y_ )

( _x,y_ ) _∈_ Ω _k_


Table 1: Controlled scaling performance evaluation results. “Blind Rec.” signifies the ability to recover the secret image without explicit
resolution metadata. **It’s important to note that to calculate these visual metrics, we explicitly passed the resolution metadata to the**
**contrastive methods that could not be blindly recovered. However, this is not permitted in real-world scenarios.**



**Blind**
**Method** **Venue**
**Rec.**



**DIV2K**
**Avg.**

**Res:** 256 _×_ 256 **Res:** 512 _×_ 512 **Res:** 720 _×_ 720 **Res:** 1024 _×_ 1024

**RRE** %

Stego Resecret Stego Resecret Stego Resecret Stego Resecret

_↓_



PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_
ISN CVPR’21 _×_ 46.79 0.9938 42.98 0.9894 45.81 0.9922 27.88 0.8379 44.64 0.9896 26.05 0.7728 44.27 0.9885 24.80 0.7076 63.12
HiNet ICCV’21 _×_ 41.69 0.9790 46.16 0.9942 39.80 0.9680 27.88 0.8400 37.73 0.9508 26.05 0.7739 37.14 0.9440 24.79 0.7083 63.12
StegFormer AAAI’24 _×_ 47.21 0.9948 40.78 0.9924 47.02 **0.9946** 27.74 0.8361 **46.68 0.9941** 25.98 0.7725 **46.56 0.9939** 24.74 0.7085 63.12
AIS ICML’25 _×_ 44.57 0.9574 33.22 0.8875 44.27 0.9566 26.33 0.7516 43.83 0.9535 24.67 0.6629 43.63 0.9522 23.63 0.6048 63.12
**ARDIS** - ✓ **48.09 0.9951 48.39 0.9966 47.23** 0.9940 **30.93 0.8917** 46.28 0.9923 **28.08 0.8151** 45.81 0.9913 **26.63 0.7516** **0**



**Blind**
**Method** **Venue**
**Rec.**



**Flickr2K**
**Avg.**

**Res:** 256 _×_ 256 **Res:** 512 _×_ 512 **Res:** 720 _×_ 720 **Res:** 1024 _×_ 1024

**RRE** %

Stego Resecret Stego Resecret Stego Resecret Stego Resecret

_↓_



PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_ PSNR _↑_ SSIM _↑_
ISN CVPR’21 _×_ 46.60 0.9937 42.54 0.9858 45.66 0.9921 28.66 0.8501 44.57 0.9896 26.73 0.7909 44.19 0.9887 25.15 0.7218 63.12
HiNet ICCV’21 _×_ 41.63 0.9781 45.86 0.9928 39.91 0.9680 28.72 0.8532 37.98 0.9518 26.76 0.7930 37.37 0.9469 25.17 0.7229 63.12
StegFormer AAAI’24 _×_ 46.53 0.9933 40.90 0.9906 46.40 0.9931 28.44 0.8484 46.12 **0.9926** 26.60 0.7903 **46.03 0.9924** 25.07 0.7220 63.12
AIS ICML’25 _×_ 44.35 0.9436 34.45 0.8811 44.18 0.9426 27.02 0.7620 43.82 0.9403 25.23 0.6821 43.67 0.9391 23.95 0.6202 63.12
**ARDIS** - ✓ **47.68 0.9949 48.20 0.9960 46.93 0.9939 31.88 0.9022 46.13** 0.9925 **28.73 0.8304** 45.73 0.9918 **26.97 0.7636** **0**



This mechanism performs collective voting and leverages
the law of large numbers to cancel out randomly distributed
distortion _ϵ_, thereby enabling bit-by-bit accurate recovery of
ˆ _bk_ . This ensures zero-error recovery of the original resolution
( _H_ [ˆ] _sec,_ _W_ [ˆ] _sec_ ) of the secret image.


**4** **Experiment**


**4.1** **Datasets and Implementation Details**


**Implementation Details.** We implement the framework using PyTorch on an NVIDIA Tesla V100 GPU. The training
process employs the Adam optimizer with an initial learning
rate of 10 _[−]_ [4] and a Cosine Annealing decay schedule over 800
epochs. A channel-wise learnable clamp in IHN is initialized
at 2.0 to stabilize high-frequency embedding. The MLP decoder in LGIR consists of 4 layers with a width of 256 using
ReLU activations.
**Evaluation Protocols.** To establish an arbitrary resolution
DIS evaluation benchmark, we constructed a multi-protocol
evaluation benchmark to evaluate the invisibility of the stego
image and the fidelity of the recovered secret image. We
used four public datasets: DIV2K [Agustsson and Timofte, 2017], Flickr2K [Li _et al._, 2022], COCO [Lin _et al._,
2014], and Stego260 [Yu _et al._, 2023]. **Protocol-1: Con-**
**trolled Resolution Performance Evaluation.** Based on
DIV2K and Flickr2K, their high resolution supports dynamic cropping to simulate arbitrary resolution secrets without interpolation artifacts. In this protocol, the cover image is fixed at 256 _×_ 256 resolution, and the secret image is
cropped to four resolutions: 256 _×_ 256, 512 _×_ 512, 720 _×_ 720,
and 1024 _×_ 1024. **Protocol-2: Generalization Evaluation in**
**Complex Scenes.** Based on the COCO dataset, this evaluates the model’s adaptability to realistic, complex textured
scenes and its ability to recover detail fidelity of the secret image across diverse image aspect ratios. In this protocol, the cover image is fixed at 256 _×_ 256 resolution, while
the secret image retains its original resolution. **Protocol-**



**3: Domain-Specific Evaluation.** Stego260 is used for a
fair comparison with the diffusion-based DIS methods. This
dataset is derived from public datasets [AISegment.cn, 2019;
Banerjee, 2022] and the Google search engine and contains
carefully crafted prompts from CRoSS. In this protocol, the
cover image is fixed at 256 _×_ 256 resolution and the secret image retains its original resolution.
**Evaluation strategy.** Since existing methods cannot perform blind recovery, we implement an asymmetric evaluation strategy: the contrasting methods are evaluated under
settings that explicitly provide the true resolution, while our
method is evaluated under a blind recovery setting. We used
PSNR, SSIM, and LPIPS to evaluate hiding and recovery performance. Furthermore, we defined relative resolution error
(RRE) specifically to evaluate our blind recovery capability:



where _H_ [ˆ] and _W_ [ˆ] are predicted resolution, _Hgt_ and _Wgt_ are
ground-truth resolution.
**Benchmarks.** We compared the current state-of-the-art DIS
methods, including ISN [Lu _et al._, 2021], HiNet [Jing _et_
_al._, 2021], CRoSS [Yu _et al._, 2023], StegFormer [Ke _et al._,
2024], DiffStega [Yang _et al._, 2024], AIS [Zhou _et al._, 2025].
Among them, CRoSS and DiffStega are diffusion-based coverless DIS methods.


**4.2** **Experimental Results**
**Quantitative Results.** In controlled resolution benchmarks,
as shown in Table 1, maintains competitive invisibility for the
stego image while exhibiting remarkable performance for the
recovered secret image. This recovery superiority is particularly evident in the extreme scenario where the secret resolution is 1024×1024, a setting where the effective payload
amounts to 16× the cover’s spatial capacity. Despite this immense information density, ARDIS outperforms the secondbest method by 1.83 dB in PSNR and 0.044 in SSIM on the



�� _W_ ˆ _−_ _Wgt_ ��

- 
_Wgt_



�� _H_ ˆ _−_ _Hgt_ ��

- 
+
_Hgt_






 _×_ 100% _._ (10)



_RRE_ = [1]

2









Figure 3: Visual comparisons of our ARDIS with leading deep image steganography methods for stego and recovering secret images in
arbitrary-resolution hiding scenarios. The recovery of secret images presents two scenarios. (1) Without explicitly transmitting resolution
metadata, no comparison methods can recover the secret image at the original resolution. (2) Explicitly transmitting resolution metadata, the
comparison methods relies on resampling for recovery, which results in the loss of many details.



Our cover

256×256



Secret
1229×1229



Stego Resecret
CRoSS DiffStega ARDIS CRoSS DiffStega ARDIS



**1** **For CRoSS** : a pigeon standing on top of a blanket with jewelry around its neck **1** **[For DiffStega]** [: null-text]

a dove standing on top of a blanket with jewelry around its neck
**2**



Our cover

256×256



Secret
1500×1500



Stego Resecret
CRoSS DiffStega ARDIS CRoSS DiffStega ARDIS


**1**



**1** **For CRoSS** : a penguin stands in the middle of a snowy field **1** **For DiffStega** : null-text **2** a puffin stands in the middle of a snowy field


Figure 4: The visual comparison of ARDIS and the diffusion-based DIS method on the Stego260 dataset. The diffusion-based DIS method
requires no cover and simply follows the prompts to generate the corresponding stego image. The settings for prompts 1 and 2 completely
follow the design of the CRoSS and Diffstega methods.



DIV2K dataset. Crucially, ARDIS is the unique solution capable of blind recovery with a 0% RRE, while other methods can only recover secret images at the same resolution
as the cover image, resulting in an RRE as high as 63.12%.
Table 2 presents the results for generalization evaluation in
complex scenes. ARDIS achieves dominant performance
across both hiding and revealing stages by securing state-ofthe-art results in PSNR, SSIM, and LPIPS simultaneously.
This comprehensive superiority confirms that ARDIS recover
complex real-world textures significantly better than existing
approaches. Finally, results for domain-specific evaluation
in Table 3 confirm a fundamental advantage over diffusionbased paradigms. For recovery secret images, ARDIS surpasses diffusion-based DIS method such as DiffStega by over
8 dB in PSNR. Furthermore, because the diffusion-based DIS
method is coverless and requires a 512 _×_ 512 input for the
secret image, the RRE value differs from other comparison
methods that cannot be blindly recovered.


**Qualitative Results.** Visual comparisons further demonstrate



the superiority of ARDIS. As shown in Figure 3, without
explicitly informing the receiver of the secret image resolution, other comparison methods recover secret images with
severe geometric distortions, such as the Statue of Liberty being incorrectly scaled. Even knowing the original resolution,
the secret images recovered by comparison methods lose a
significant amount of detail compared to ARDIS. Figure 4
reveals the limitations of diffusion-based methods (such as
CRoSS and DiffStega), which are highly sensitive to prompts.
With imperfectly designed prompts, the generated stego im


Table 2: Generalization evaluation results.



**Blind**
**Method** **Venue** **Rec.**



**COCO** ~~**Avg.**~~
Stego Resecret **RRE** %

SSIM _↑_ LPIPS _↓_ PSNR _↑_ SSIM _↑_ LPIPS _↓_ _↓_



PSNR _↑_ SSIM _↑_ LPIPS _↓_ PSNR _↑_ SSIM _↑_ LPIPS _↓_
ISN CVPR’21 _×_ 42.76 0.9873 0.0008 26.65 0.7954 0.2549 49.36
HiNet ICCV’21 _×_ 37.22 0.9556 0.0026 26.67 0.7975 0.2540 49.36
StegFormer AAAI’24 _×_ 41.99 **0.9869** 0.0008 26.51 0.7846 0.2549 49.36
AIS ICML’25 _×_ 42.03 0.9254 0.0004 25.42 0.7022 0.4054 49.36
**ARDIS** - ✓ **42.65** **0.9869** **0.0002** **28.70** **0.8415** **0.1115** **0**


Table 3: Domain-specific evaluation results.The resolutions of the
secret image are from 225 _×_ 225 to 3452 _×_ 3452.



**Blind**
**Method** **Venue** **Rec.**



**stego260** ~~**Avg.**~~
Stego Resecret **RRE** %

SSIM _↑_ LPIPS _↓_ PSNR _↑_ SSIM _↑_ LPIPS _↓_ _↓_



PSNR _↑_ SSIM _↑_ LPIPS _↓_ PSNR _↑_ SSIM _↑_ LPIPS _↓_
ISN CVPR’21 _×_ 46.62 0.9939 0.0006 30.87 0.8792 0.2153 62.83
HiNet ICCV’21 _×_ 41.05 0.9776 0.0011 30.98 0.8828 0.2172 62.83
CRoSS NeurIPS’23 _×_ - - - 22.58 0.7308 0.2567 36.70
StegFormer AAAI’24 _×_ 46.52 0.9930 0.0005 30.66 0.8758 0.2169 62.83
DiffStega IJCAI’24 _×_ - - - 24.67 0.7621 0.2110 36.70
AIS ICML’25 _×_ 44.36 0.9456 0.0004 29.48 0.8175 0.3009 62.83
**ARDIS** - ✓ **48.01** **0.9954** **0.0001** **32.89** **0.9018** **0.1091** **0**



ages often exhibit obvious semantic distortions and unnatural
traces. More critically, during the recovery stage, while the
images generated by these methods may appear visually realistic, they actually contain textures completely unrelated to
the original secret image. In contrast, ARDIS generates highquality stego images while ensuring pixel-level consistency
between the recovered results and the original secret image.
**Security analysis.** The anti-steganalysis ability is a important metric for evaluating the security of DIS methods. We
assess the security of each method by exploring the number of leaked samples an attacker needs to effectively detect
stego images[Weng _et al._, 2019]. A detection accuracy closer
to 50% indicates higher security. We train and test SRNet

[Boroumand _et al._, 2018] using cover / stego image pairs generated on the COCO dataset by our method or other comparison methods. As shown in Figure 5, our method maintains
superior security even with an increase in leaked samples.



100
90
80
70
60
50



**ISN**
**HiNet**



**StegFormer**



**AIS**
**ARDIS**



50 100 150 200
Number of target training samples


Figure 5: Steganalysis accuracy by SRNet. The fact that the curve
remains close to 50% despite the increasing number of leaked samples demonstrates the high security of the method.


**4.3** **Ablation Study**

To valid the effectiveness of each component in ARDIS, we
conduct ablation experiments on COCO dataset. Results are
shown in Table 4 and Fig. 6.
**Effectiveness of FDA.** FDA is essential to prevent information loss. Without it (#3), the secret image fis naively resampled before hiding, causing irreversible high-frequency loss.
Lacking deterministic detail guidance, the reconstructor produces results with noticeable artifacts or washed-out details,
as illustrated in Fig. 6.
**Effectiveness of LGIR.** LGIR utilize the decoupled latent for
continuous and accurate reconstruction. As shown in Table 4,
simply employing FDA without LGIR (#2) resulted in a performance improvement of only 0.19db compared to the baseline (#2). This indicates that standard resampling operators



Secret image patch Resecret w/o FDA Resecret


Figure 6: Impact of latent guidance on detail reconstruction. Without the FDA (“w/o FDA”), the reconstruction fails to resolve highfrequency textures, leading to over-smoothed edges and chromatic
aberrations.


cannot effectively integrate the decoupled high-frequency latent. In contrast, introducing LGIR (#4) yields a 1.84 dB gain
in recovery PSNR, which underscores the necessity of LGIR.


Table 4: Ablation experiments of different components


**COCO**

**Variant** **FDA** **LGIR** Stego Resecret

PSNR _↑_ SSIM _↑_ LPIPS _↓_ PSNR _↑_ SSIM _↑_ LPIPS _↓_
#1 _×_ _×_ 42.35 0.9863 0.0003 27.18 0.8070 0.1654
#2 ✓ _×_ 42.59 **0.9872** **0.0002** 27.37 0.8108 0.1579
#3 _×_ ✓ 40.48 0.9797 0.0004 28.27 0.8299 0.1276
#4 ✓ ✓ **42.65** 0.9869 **0.0002** **28.70** **0.8415** **0.1115**


**5** **Conclusion**


In this paper, we proposed **ARDIS**, the first framework to
enable arbitrary-resolution deep image steganography. This
work breaks the long-standing fixed-resolution constraint inherent in current DIS paradigms. Through the frequency decoupling architecture, ARDIS achieves the decoupled embedding of global structure and fine-grained detail during the
hiding stage, guaranteeing the effective preservation of highfrequency information. Meanwhile, via the latent-guided implicit reconstructor, it ensures faithful and determinative detail restoration in the revealing stage. Furthermore, robust
blind recovery is realized through the implicit resolution coding strategy. Experimental results demonstrate that ARDIS
significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.


**References**

[Agustsson and Timofte, 2017] Eirikur Agustsson and Radu
Timofte. Ntire 2017 challenge on single image superresolution: Dataset and study. In _Proceedings of the IEEE_
_conference on computer vision and pattern recognition_
_workshops_, pages 126–135, 2017.

[AISegment.cn, 2019] AISegment.cn. Matting human
[datasets. https://github.com/aisegmentcn/matting](https://github.com/aisegmentcn/matting_human_datasets) ~~h~~ uman
[datasets, 2019.](https://github.com/aisegmentcn/matting_human_datasets)

[Baluja, 2017] Shumeet Baluja. Hiding images in plain
sight: Deep steganography. _Advances in neural informa-_
_tion processing systems_, 30, 2017.

[Baluja, 2019] Shumeet Baluja. Hiding images within images. _IEEE transactions on pattern analysis and machine_
_intelligence_, 42(7):1685–1697, 2019.

[Banerjee, 2022] Sourav Banerjee. Animal image dataset (90 different animals). [https:](https://www.kaggle.com/datasets/iamsouravbanerjee/animal-image-dataset-90-different-animals)
[//www.kaggle.com/datasets/iamsouravbanerjee/](https://www.kaggle.com/datasets/iamsouravbanerjee/animal-image-dataset-90-different-animals)
[animal-image-dataset-90-different-animals, 2022.](https://www.kaggle.com/datasets/iamsouravbanerjee/animal-image-dataset-90-different-animals)

[Boroumand _et al._, 2018] Mehdi Boroumand, Mo Chen, and
Jessica Fridrich. Deep residual network for steganalysis of
digital images. _IEEE Transactions on Information Foren-_
_sics and Security_, 14(5):1181–1193, 2018.

[Chen _et al._, 2021] Yinbo Chen, Sifei Liu, and Xiaolong
Wang. Learning continuous image representation with
local implicit image function. In _Proceedings of the_
_IEEE/CVF conference on computer vision and pattern_
_recognition_, pages 8628–8638, 2021.

[Dinh _et al._, 2014] Laurent Dinh, David Krueger, and
Yoshua Bengio. Nice: Non-linear independent components estimation. _arXiv preprint arXiv:1410.8516_, 2014.

[Dinh _et al._, 2016] Laurent Dinh, Jascha Sohl-Dickstein, and
Samy Bengio. Density estimation using real nvp. _arXiv_
_preprint arXiv:1605.08803_, 2016.

[Duan _et al._, 2019] Xintao Duan, Kai Jia, Baoxia Li, Daidou
Guo, En Zhang, and Chuan Qin. Reversible image
steganography scheme based on a u-net structure. _Ieee_
_Access_, 7:9314–9323, 2019.

[Duan _et al._, 2024] Delin Duan, Shuyuan Shen, Songsen Yu,
Yibo Yuan, Qidong Zhou, Haojie Lv, and Huanjie Lin.
Densejin: Dense depth image steganography model with
joint invertible and noninvertible mechanisms. _IEEE_
_Transactions on Circuits and Systems for Video Technol-_
_ogy_, 2024.

[Hayes and Danezis, 2017] Jamie Hayes and George
Danezis. Generating steganographic images via adversarial training. _Advances in neural information processing_
_systems_, 30, 2017.

[Ho _et al._, 2020a] Jonathan Ho, Ajay Jain, and Pieter
Abbeel. Denoising diffusion probabilistic models.
_Advances in neural information processing systems_,
33:6840–6851, 2020.

[Ho _et al._, 2020b] Jonathan Ho, Ajay Jain, and Pieter
Abbeel. Denoising diffusion probabilistic models.



_Advances in neural information processing systems_,
33:6840–6851, 2020.


[Jing _et al._, 2021] Junpeng Jing, Xin Deng, Mai Xu, Jianyi
Wang, and Zhenyu Guan. Hinet: Deep image hiding by
invertible network. In _Proceedings of the IEEE/CVF in-_
_ternational conference on computer vision_, pages 4733–
4742, 2021.


[Ke _et al._, 2024] Xiao Ke, Huanqi Wu, and Wenzhong Guo.
Stegformer: Rebuilding the glory of autoencoder-based
steganography. In _Proceedings of the AAAI Conference_
_on Artificial Intelligence_, volume 38, pages 2723–2731,
2024.


[Li _et al._, 2022] Lei Li, Jingzhu Tang, Ming Chen, Shijie
Zhao, Junlin Li, and Li Zhang. Multi-patch learning: looking more pixels in the training phase. In _European Confer-_
_ence on Computer Vision_, pages 549–560. Springer, 2022.


[Li _et al._, 2024] Fengyong Li, Yang Sheng, Kui Wu, Chuan
Qin, and Xinpeng Zhang. Lidinet: A lightweight deep invertible network for image-in-image steganography. _IEEE_
_Transactions on Information Forensics and Security_, 2024.


[Lin _et al._, 2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr
Doll´ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In _European conference on com-_
_puter vision_, pages 740–755. Springer, 2014.


[Liu _et al._, 2025] Hao Liu, Fengyong Li, Chuan Qin, and
Xinpeng Zhang. Fearless of noise: Robust image-inimage hiding using dual-tree complex wavelet transform
and state space model. _IEEE Transactions on Circuits and_
_Systems for Video Technology_, 2025.


[Lu _et al._, 2021] Shao-Ping Lu, Rong Wang, Tao Zhong,
and Paul L Rosin. Large-capacity image steganography
based on invertible neural networks. In _Proceedings of_
_the IEEE/CVF conference on computer vision and pattern_
_recognition_, pages 10816–10825, 2021.


[Luo _et al._, 2024] Ting Luo, Yuhang Zhou, Zhouyan He,
Gangyi Jiang, Haiyong Xu, Shuren Qi, and Yushu Zhang.
Stegmamba: Distortion-free immune-cover for multiimage steganography with state space model. _IEEE Trans-_
_actions on Circuits and Systems for Video Technology_,
2024.


[Rahim _et al._, 2018] Rafia Rahim, Shahroz Nadeem, et al.
End-to-end trained cnn encoder-decoder networks for image steganography. In _Proceedings of the European con-_
_ference on computer vision (ECCV) workshops_, pages 0–0,
2018.


[Song _et al._, 2020] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. _arXiv_
_preprint arXiv:2010.02502_, 2020.


[van der Ouderaa and Worrall, 2019] Tycho FA van der
Ouderaa and Daniel E Worrall. Reversible gans for
memory-efficient image-to-image translation. In _Proceed-_
_ings of the IEEE/CVF Conference on Computer Vision_
_and Pattern Recognition_, pages 4720–4728, 2019.


[Wang _et al._, 2025] Jiannian Wang, Yao Lu, and Guangming
Lu. Sshr: More secure generative steganography with
high-quality revealed secret images. In _Forty-second In-_
_ternational Conference on Machine Learning_, 2025.

[Wani _et al._, 2022] Pratik Wani, Anuja Nanaware, Sneha
Shirode, Aishwarya Suram, and Archana Jadhav. Secret
communication using multi-image steganography for military purposes. _International Journal of Advanced Re-_
_search in Science, Communication and Technology_, 2,
2022.

[Weng _et al._, 2019] Xinyu Weng, Yongzhi Li, Lu Chi, and
Yadong Mu. High-capacity convolutional video steganography with temporal residual modeling. In _Proceedings_
_of the 2019 on international conference on multimedia re-_
_trieval_, pages 87–95, 2019.

[Xu _et al._, 2022] Youmin Xu, Chong Mou, Yujie Hu, Jingfen
Xie, and Jian Zhang. Robust invertible image steganography. In _Proceedings of the IEEE/CVF conference on com-_
_puter vision and pattern recognition_, pages 7875–7884,
2022.

[Yang _et al._, 2024] Yiwei Yang, Zheyuan Liu, Jun Jia,
Zhongpai Gao, Yunhao Li, Wei Sun, Xiaohong Liu, and
Guangtao Zhai. Diffstega: towards universal training-free
coverless image steganography with diffusion models. In
_Proceedings of the Thirty-Third International Joint Con-_
_ference on Artificial Intelligence_, pages 1579–1587, 2024.

[Yu _et al._, 2023] Jiwen Yu, Xuanyu Zhang, Youmin Xu, and
Jian Zhang. Cross: Diffusion model makes controllable,
robust and secure image steganography. _Advances in_
_Neural Information Processing Systems_, 36:80730–80743,
2023.

[Yu, 2020] Chong Yu. Attention based data hiding with generative adversarial networks. In _Proceedings of the AAAI_
_conference on artificial intelligence_, volume 34, pages
1120–1128, 2020.

[Zhang _et al._, 2020] Chaoning Zhang, Philipp Benz, Adil
Karjauv, Geng Sun, and In So Kweon. Udh: Universal
deep hiding for steganography, watermarking, and light
field messaging. _Advances in Neural Information Process-_
_ing Systems_, 33:10223–10234, 2020.

[Zhang _et al._, 2024a] Xuanyu Zhang, Runyi Li, Jiwen Yu,
Youmin Xu, Weiqi Li, and Jian Zhang. Editguard: Versatile image watermarking for tamper localization and copyright protection. In _Proceedings of the IEEE/CVF confer-_
_ence on computer vision and pattern recognition_, pages
11964–11974, 2024.

[Zhang _et al._, 2024b] Yunming Zhang, Dengpan Ye, Caiyun
Xie, Long Tang, Xin Liao, Ziyi Liu, Chuanxi Chen, and
Jiacheng Deng. Dual defense: Adversarial, traceable,
and invisible robust watermarking against face swapping.
_IEEE Transactions on Information Forensics and Security_,
19:4628–4641, 2024.

[Zhang _et al._, 2025] Xuanyu Zhang, Zecheng Tang, Zhipei
Xu, Runyi Li, Youmin Xu, Bin Chen, Feng Gao, and Jian
Zhang. Omniguard: Hybrid manipulation localization via



augmented versatile deep image watermarking. In _Pro-_
_ceedings of the Computer Vision and Pattern Recognition_
_Conference_, pages 3008–3018, 2025.

[Zhou _et al._, 2025] Junchao Zhou, Yao Lu, Jie Wen, and
Guangming Lu. Efficient and separate authentication image steganography network. In _Forty-second International_
_Conference on Machine Learning_, 2025.


