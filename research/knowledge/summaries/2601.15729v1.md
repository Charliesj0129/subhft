# DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving

Rui Yang, Lei Zheng, Ruoyu Yao, and Jun Ma



_**Abstract**_ **— Diffusion models have emerged as a powerful**
**approach for multimodal motion planning in autonomous driv-**
**ing. However, their practical deployment is typically hindered**
**by the inherent difficulty in enforcing vehicle dynamics and**
**a critical reliance on accurate predictions of other agents,**
**making them prone to safety issues under uncertain interac-**
**tions. To address these limitations, we introduce DualShield,**
**a planning and control framework that leverages Hamilton-**
**Jacobi (HJ) reachability value functions in a dual capacity.**
**First, the value functions act as proactive guidance, steering**
**the diffusion denoising process towards safe and dynamically**
**feasible regions. Second, they form a reactive safety shield using**
**control barrier-value functions (CBVFs) to modify the executed**
**actions and ensure safety. This dual mechanism preserves**
**the rich exploration capabilities of diffusion models while**
**providing principled safety assurance under uncertain and even**
**adversarial interactions. Simulations in challenging unprotected**
**U-turn scenarios demonstrate that DualShield significantly**
**improves both safety and task efficiency compared to leading**
**methods from different planning paradigms under uncertainty.**


I. INTRODUCTION


The central challenge in autonomous driving is not merely
to navigate efficiently, but to proactively handle complex
interactions with unpredictable human drivers [1], [2]. This
reality introduces a fundamental tension: on one hand, vehicles require the exploratory power of multimodal motion
planning to act decisively, preventing behavioral freezing in
complex scenarios [3]. On the other hand, they must adhere
to strict, formal safety guarantees, even when faced with
worst-case adversarial behaviors [4], [5]. Therefore, developing a framework that unifies the flexibility of multimodal
planning techniques with the non-negotiable assurance of
formal safety is paramount for building truly trustworthy
autonomous systems.
In pursuit of this goal, two primary research directions
have emerged. The first centers on optimization-based planners, exemplified by model predictive control (MPC). While
valued for its receding horizon scheme and explicit handling
of system dynamics and constraints [6], [7], traditional
gradient-based MPC struggles in real-world driving scenarios characterized by non-differentiable objective functions
and non-convex constraints, often converging to suboptimal
local minima [8]. To address this issue, sampling-based
approaches like model predictive path integral (MPPI) have
gained traction [9], [10]. By optimizing through stochastic


Rui Yang, Lei Zheng, Ruoyu Yao, and Jun Ma are with the Robotics and
Autonomous Systems Thrust, The Hong Kong University of Science and
Technology (Guangzhou), Guangzhou 511453, China (e-mail: _{_ ryang253,
lzheng135, ryang092 _}_ @connect.hkust-gz.edu.cn; jun.ma@ust.hk).



Fig. 1. Overview of the DualShield framework. The model-based
diffusion generates candidate trajectories in a receding horizon scheme,
leveraging a pre-computed HJ value function in a dual capacity: it proactively guides the denoising process away from high-risk regions, and serves
as the final shield by forming a reactive CBVF-QP to filter the executed
controls.


sampling, MPPI can better handle non-convex problems.
Nevertheless, it suffers from fundamental limitations in both
safety and exploration. Its conventional reliance on soft
penalties provides only fragile safety assurance. Even when
augmented with formal safety layers [11], [12], its core
exploration mechanism based on local perturbations remains
a performance bottleneck, resulting in high sensitivity to
initialization [13], [14].
To address these exploration limitations, a second
paradigm leverages generative models, particularly diffusion
models [15]–[18], for global exploration. Unlike local perturbations of MPPI, diffusion models learn a multimodal
trajectory distribution, enabling them to excel in highly nonconvex problems by jointly optimizing discrete decisions and
continuous trajectories [19], [20]. However, most existing
approaches are trained purely from data, failing to explicitly
enforce hard system dynamics or safety constraints [21].
This limitation motivates recent model-based diffusion
approaches, which reintegrate structured model priors into
the denoising process, as the desired trajectory distribution is
explicitly characterized by the objective function, constraints,
and system dynamics [22], [23]. These methods reframe the
denoising process as a dynamics-aware trajectory generation by embedding the model components into the score
function [24]. To address interaction-rich scenarios, a model
predictive diffusion framework has been tailored for highway
merging using Bayesian intent inference [25]. However, these
methods still treat safety primarily through distance-based
soft penalties, a strategy that lacks formal guarantees and is
sensitive to hyperparameter tuning [19], [26], [27].
To achieve provable safety, control barrier function (CBF)


defines a desired safe set as its zero-superlevel set and
provides safety assurance by enforcing its forward invariance

[28]–[30]. Recent works have incorporated CBFs into diffusion frameworks by filtering generated trajectories through
a safety layer in a quadratic programming (QP) formulation

[31] or embedding CBF constraints into the denoising score
function [32]. Nevertheless, designing effective CBFs is nontrivial, and they can be brittle under the profound uncertainty
of interactive human vehicles (HVs) [33]–[35]. To explicitly
account for multi-agent interactions, Hamilton–Jacobi (HJ)
reachability analysis formulates the interaction between the
ego vehicle (EV) and HVs as a zero-sum differential game

[36]. It provides a constructive method for computing the
maximal control invariant set for nonlinear systems. Recent
studies have successfully integrated HJ-based safety analysis
into MPC frameworks as a safety filter [37], [38]. Moreover,
filter-aware planning has been explored to mitigate the performance degradation caused by reactive safety interventions

[39], [40]. Rather than treating safety as a post hoc correction, these methods proactively anticipate filter activations
to balance task performance against potential emergency
maneuvers triggered by rare but critical events.

The strengths of CBF and HJ reachability analysis are
unified within the control barrier-value function (CBVF)
concept [41]. It provides a constructive and computationally
tractable way to derive the maximal safe set while naturally
handling bounded controls and uncertain interactions [42].
This perspective highlights the potential of using HJ value
functions not just as reactive shielding, but also as proactive
guidance for generative planning.

In this work, we present DualShield, a model predictive diffusion framework that realizes this potential. Unlike
existing methods, DualShield reuses HJ value functions
both to proactively guide diffusion-based trajectory generation and to construct a formal safety filter for the executed
control. This dual use of the HJ value function bridges
generative multimodal planning and principled safety in a
unified, computationally tractable framework for interactive
driving. The main contributions of this work are threefold:


1) We propose a unified planning and control framework,
DualShield, that reconciles multimodal exploration
with formal safety assurance. Its core mechanism repurposes HJ value functions for both proactive guidance of the denoising process and reactive shielding at
execution time.
2) We introduce a tractable safety shield for multi-agent
interactions. It is formulated as real-time CBVF-QP
from a reusable, pre-computed pairwise HJ value functions, which apply minimal yet formal safety interventions.
3) We conduct extensive empirical validation in challenging interactive driving scenarios. The results demonstrate that DualShield achieves a superior balance
between safety and high task efficiency under uncertainty, outperforming representative methods from
different planning paradigms.



II. PROBLEM FORMULATION


We consider a multi-agent setting where an EV must
navigate an environment populated by _M_ HVs. Let _x ∈_ _X ⊂_
R _[n]_ and _u ∈_ _U ⊂_ R _[m]_ denote the state and control vectors of
the EV, respectively, where _U_ is a convex set. Similarly, let
_xh ∈_ _Xh ⊂_ R _[n]_ and _uh ∈_ _Uh ⊂_ R _[m]_ be the state and control
vectors of the _h_ -th HV. The EV and HV are governed by the
following control-affine dynamics:


_x_ ˙ = _f_ ( _x_ )+ _g_ ( _x_ ) _u,_ _x_ ˙ _h_ = _fh_ ( _xh_ )+ _gh_ ( _xh_ ) _uh,_ (1)


where _f_, _g_, _fh_, and _gh_ are known continuous functions
characterizing the system dynamics.
Safety of the EV is defined by a requirement to avoid a
failure set _F_ . This set is specified by a Lipschitz continuous
distance function _l_ : _X ×_ _Xh →_ R, such that _F_ = _{_ ( _x,_ _xh_ ) _|_
_l_ ( _x,_ _xh_ ) _≤_ 0 _}_ . The EV must ensure that the system state
remains outside of this failure set for the entire duration of
its operation.
The primary objective is to find an optimal control trajectory _u_ ( _·_ ) over a time horizon [0 _,_ _T_ ] that minimize a
performance-oriented objective functional _J_ perf while ensuring safety. Crucially, this safety assurance must hold against
the set of all plausible behaviors _uh ∈_ _Uh_ for all HVs, which
introduces significant uncertainty. This formally defines a
constrained, differential game-like optimal control problem:


         - _T_
min _J_ perf( _x,_ _u_ ) = (2a)
_u_ ( _·_ ) 0 _[L]_ [ (] _[x][,]_ _[u][,]_ _[x][h]_ [)] _[dt]_ [ +] _[L][T]_ [(] _[x]_ [(] _[T]_ [))]

s.t. _x_ (0) = _x_ [init] _,_ _xh_ (0) = _xh_ [init] _[,]_ (2b)

_x_ ˙ = _f_ ( _x_ )+ _g_ ( _x_ ) _u,_ _u ∈_ _U,_ (2c)
_x_ ˙ _h_ = _fh_ ( _xh_ )+ _gh_ ( _xh_ ) _uh,_ _uh ∈_ _Uh,_ (2d)

_l_ ( _x,_ _xh_ ) _≥_ 0 _,_ _h ∈_ _I_ 0 _[M][−]_ [1] _,_ (2e)

_x ∈_ _X,_ (2f)


where _L_ and _LT_ are the running and terminal cost functions, respectively; and _I_ 0 _[M][−]_ [1] denotes _{_ 0 _,_ 1 _,...,_ _M −_ 1 _}_ .
The trajectory optimization problem (2), characterized by
its potentially non-convex and non-differentiable cost _L_, is
challenging to solve. The primary challenge lies in ensuring safety against the uncertain and potentially adversarial
behaviors of the HVs. This transforms the problem from a
standard optimal control task into a differential game, where
the EV must find a strategy that is robust to the actions of
all other HVs.


III. METHODOLOGY


_A. Hamilton-Jacobi Reachability Analysis_


To ensure safety, we employ HJ reachability analysis.
This method computes the backward reachable set (BRS) of
the failure set _F_ by solving a zero-sum differential game.
Compared to many forward reachability methods that assume
open-loop behaviors, BRS computation in a game-theoretic
setting provides tighter safety guarantees by accounting for
the optimal worst-case closed-loop responses of the HVs. It
is able to systematically handle nonlinear dynamics, making
it particularly suitable for safe interactive driving [38].


We formulate the safety problem in a relative reference
frame centered at the EV and aligned with its body frame.
This formulation allows the computed BRS to be reused
across different dynamic scenarios. Although computationally intensive, the BRS can be pre-computed offline for
efficient real-time lookup. Let _xr_ be the relative state. It is
straightforward to verify that the resulting relative dynamics
also preserve a control-affine structure:


_x_ ˙ _r_ = _fr_ ( _xr,_ _u,_ _uh_ ) = _f_ 0( _xr_ )+ _GA_ ( _xr_ ) _u_ + _GB_ ( _xr_ ) _uh,_ (3)


where _f_ 0( _xr_ ) is the drift vector, and _GA_ and _GB_ are the
control-input matrices for the EV and HV, respectively.
The failure set in this frame can be equivalently denoted
as _Fr_ = _{xr | lr_ ( _xr_ ) _≤_ 0 _}_, where _lr_ is the distance between the
EV and HV in relative coordinates. Then, the payoff function
for the EV in this safety game is defined as _J_ ( _xr,_ _u,_ _uh_ ) =
min _τ∈_ [ _t,Thj_ ] _lr_ ( _xr_ ( _τ_ )), capturing the minimum distance from
time _t_ to _Thj_ . We compute the optimal control of the EV to
maximize this cost function with the worst-case maneuvers
of the HV. This gives the value function as


_V_ ( _xr_ ) = sup inf _J_ ( _xr,_ _u,_ _uh_ ) _._ (4)
_u∈U_ _uh∈Uh_


This value function can be computed using dynamic programming (DP), resulting in the final value Hamilton-JacobiIssacs variational inequality (HJI-VI) [43]:

min _{lr_ ( _xr_ ) _−V_ ( _xr_ ) _,_ _[∂]_ (5a)

_∂t_ _[V]_ [(] _[x][r]_ [)+] _[H]_ [(] _[x][r][,]_ [∇] _[V]_ [(] _[x][r]_ [))] _[}]_ [ =][ 0] _[,]_

_V_ ( _xr_ ( _Thj_ )) = _lr_ ( _xr_ ( _Th j_ )) _,_ for _t ∈_ [0 _,_ _Th j_ ] _,_ (5b)


where ∇ _V_ ( _xr_ ) = _∂_ _[∂]_ _x_ _[V]_ [(] _[x][r]_ [)][, and] _[ H]_ [ is the Hamiltonian:]

_H_ ( _xr,_ _[∂]_ inf ∇ _V_ ( _xr_ ) _fr_ ( _xr,_ _u,_ _uh_ ) _._ (6)

_∂_ _x_ [) =][ sup] _u∈U_ _uh∈Uh_

The BRS is given as a sublevel set of the value function:


_B_ ( _xr_ ) = _{xr | V_ ( _xr_ ) _≤_ 0 _}._ (7)


It represents the set of states from which the EV cannot
prevent a future collision against the worst-case maneuvers
of the HV. Correspondingly, the set of provably safe states
is the complement, defined as _S_ ( _xr_ ) = _{xr | V_ ( _xr_ ) _≥_ 0 _}_ . The
value function _V_ ( _xr_ ) thus serves as a formal safety certificate.


_B. Model-Based Diffusion_


We employ a model-based diffusion model to address nondifferentiable objectives, leveraging its strong multimodal
exploration capabilities to navigate complex interactive scenarios and avoid local optima. We formulate the problem in
discrete time for clarity of exposition and ease of implementation. To ensure dynamic constraints are inherently satisfied,
the diffusion process operates over the control sequence
**u** = _{u_ 0: _T_ _−_ 1 _}_ over a finite horizon _N_, with a sampling period
_dt_ = _T_ _/N_ . The corresponding state sequence **x** = _{x_ 1: _N}_ is
then obtained by rolling out this control sequence from an
initial state _x_ 0 using the discretized dynamics derived from
(2c).
We cast the trajectory optimization problem as sampling
from a target distribution _p_ [(][0][)] ( **u** ) over control sequences.



This distribution is designed such that the probability of any
control sequence **u** is determined by the cost of the full stateaction trajectory **y** = _{_ **x** _,_ **u** _}_ . Here, the probability is defined
in a Gibbs distribution form:


_p_ [(][0][)] ( **u** ) ∝ exp ( _−J_ ( **y** ) _/λ_ ) _,_ where **x** = Rollout( **u** _,_ _x_ 0) _._ (8)


The total objective function _J_ ( **y** ) incorporates both performance objectives and soft constraints. In our formulation, this cost corresponds to the discrete-time form of the
objective (2a) and state constraint penalties (2f). A key
advantage of this formulation is that it circumvents the need
to sample from the Dirac delta distribution of dynamically
feasible trajectories, since feasibility is guaranteed by the
deterministic rollout adhering to dynamics constraint (2c).
Our diffusion model consists of a standard _forward pro-_
_cess_, which progressively perturbs an initial control sequence
**u** [(][0][)] into isotropic Gaussian noises:

**u** [(] _[i]_ [)] _∼_ _N_ ( _[√]_ _α_ ¯ _i_ **u** [(][0][)] _,_ ~~�~~ 1 _−_ _α_ ¯ _i I_ ) _,_ (9)


where ¯ _αi_ = ∏ _[i]_ _k_ =1 _[α][k]_ [ with a predefined noise schedule] _[ α][k][ ≥]_ [0,]
and _I_ is an identity matrix.
The corresponding _backward process_ then reverses this
procedure, aiming to reconstruct _p_ [(][0][)] ( **u** ) from noises. This is
achieved by estimating the score function ∇ **u** ( _i_ ) log _p_ [(] _[i]_ [)] ( **u** [(] _[i]_ [)] ),
which guides the sampling towards high-likelihood regions
of the target distribution over _Nd_ denoising steps. A single
reverse step is then formulated as:



Then, the score function ∇ **u** ( _i_ ) log _p_ [(] _[i]_ [)] ( **u** [(] _[i]_ [)] ) is estimated as
follows:

_√_
_α_ ~~¯~~ _i_

∇ **u** ( _i_ ) log _p_ [(] _[i]_ [)] ( **u** [(] _[i]_ [)] ) _≈−_ 1 **[u]** _−_ [(] _[i]_ _α_ [)] ¯ _i_ + 1 _−_ _α_ ¯ _i_ **u** ¯ _,_ (12)


where the weighted mean of the optimal control sequences
**u** ¯ is defined by:


**u** ¯ ( _U_ [(] _[i]_ [)] ) = [∑] **[u]** _[∈][U]_ [(] _[i]_ [)] **[u]** _[ p]_ [(][0][)][(] **[u]** [)] (13)

∑ **u** _∈U_ ( _i_ ) _p_ [(][0][)] ( **u** ) _[.]_


Here, the weight _p_ [(][0][)] ( **u** ) for each control sequence **u** is
computed according to the target distribution (8).



1
**u** [(] _[i][−]_ [1][)] = ~~_√_~~
~~_α_~~ _i_




- **u** [(] _[i]_ [)] +(1 _−_ _α_ ¯ _i_ ) ∇ **u** ( _i_ ) log _p_ [(] _[i]_ [)] ( **u** [(] _[i]_ [)] ) _._ (10)



In contrast to model-free paradigms that learn a neural
network to approximate the score function, we adopt a
model-based approach that computes it on-the-fly [22]. This
allows the planner to be highly adaptive to environmental
changes without requiring retraining. Specifically, to estimate
the score via Monte Carlo approximation, we sample a set
of _Nm_ candidate clean sequences _U_ [(] _[i]_ [)] = _{_ **u** [ _k_ ] _}_ _[N]_ _k_ = _[m]_ 0 _[−]_ [1] from the
distribution:



**u** [ _k_ ] _∼_ _N_ ( ~~_√_~~ **[u]** [(] _[i]_ [)]



_I_ ) _._ (11)
_α_ ¯ _i_



~~_√_~~ **[u]** [(] _[i]_ [)] _,_ [1] _[−]_ _[α]_ [¯] _[i]_
_α_ ~~¯~~ _i_ _α_ ¯ _i_


_C. The DualShield Framework_


Our proposed method, DualShield, unifies generative,
multimodal diffusion planning with HJ safety certificate,
consisting of two core components operating in synergy: a
proactive, safety-guided diffusion planner that generates safe
nominal trajectories, and a reactive, verifiable safety shield
that certifies the executed control actions.

_1) Proactive Safety Guidance in Diffusion Planning_
The uncertain and interactive nature of multi-agent driving
often renders the safe portion of the state space sparse and
complex. Standard sampling procedure in model-based diffusion can therefore be inefficient. To address this, we propose
to embed safety awareness into the trajectory generation
process directly.
The key idea is to guide the denoising process using
a safety-aware objective functional _J_ ( **y** ). We augment the
performance objective _J_ perf with a safety-guided term derived
from the HJ value function:



**Algorithm 1:** The DualShield Algorithm

**Input:** Current state _xk_, relative state _xr_, HJ value
function _V_
**Param:** Sample number _Nm_, normal denoising steps
_Nd_, warm-start denoising steps _Nws_
**Persistent:** Previous control sequence ˆ **u** _←_ **0**


**1 if** _t_ = 0 **then**

**2** Initialize noisy controls **u** [(] _[N]_ [)] _∼_ _N_ ( **0** _,_ **I** );

**3** _N_ start _←_ _Nd_ ;


**4 else**

**5** Warm-start **u** [(] _[I][ws]_ [)] from ˆ **u** via forward process (9);

**6** _N_ start _←_ _Nws_ ;



**7 for** _i_ = _Nstart_ **to** 1 **do**



**8** Sample _Nm_ sequences _{_ **u** [ _k_ ] _}_ _[N]_ _k_ = _[m]_ 0 _[−]_ [1] from (11);



**9** Compute weights _{p_ [(] _k_ [0][)] _[}]_ _k_ _[N]_ = _[m]_ 0 _[−]_ [1] for all candidates
using safety-guided score (14) and (8);



**10** Estimate the sequence ¯ **u** via (13);

**11** Perform one reverse step to get **u** [(] _[i][−]_ [1][)] using (10),
(12), and (13) ;

**12 u** nom _←_ **u** [(][0][)] ;

**13** Compute control _u_ safe by solving CBVF-QP (15);

**14** Execute control _u_ safe on the EV;

**15** Store ˆ **u** _←_ **u** nom for next time step;


achieve this by considering the worst-case instantaneous
effect of the HV control inputs. By expanding the time
derivative of _V_ ( _xr_ ) using the control-affine relative dynamics (3) and minimizing over all admissible _uh ∈_ _Uh_, we obtain
the following robust CBVF constraint:

_L_ _f_ 0 _V_ ( _xr_ )+ _LGAV_ ( _xr_ ) _u_ + min _uh∈Uh_ [ _LGBV_ ( _xr_ ) _uh_ ] _≥−α_ ( _V_ ( _xr_ ))

where _L f_ _V_ := ∇ _V · f_ is the Lie derivative. This inequality
defines a half-space of the safe control _u_ for the current
relative state _xr_ with respect to the _h_ -th HV.
To ensure feasibility in extreme scenarios, we relax the
safety constraint using a non-negative slack variable _ε_ penalized by a large weight _cε_ . This CBVF-QP problem takes the
first step nominal control _u_ nom from the generated sequence
**u** nom, and computes the safe control _u_ safe by minimizing the
deviation from _u_ nom subject to the safety constraints:

_u_ safe = argmin _∥u_ _−_ _u_ nom _∥_ [2] + _cε ·_ _ε_ [2]
_u∈U,ε≥_ 0



_J_ ( **y** ) = _J_ perf( **y** )+ _λs_



_N−_ 1
## ∑ L ( V min,k ), (14)

_k_ =0



where _L_ ( _V_ min _,k_ ) = _γ_ max( _−V_ min _,k,_ 0) _, γ >_ 0 _,_ is a penalty
function that discourages trajectories from entering unsafe regions _B_ ( _xr_ ). The term _V_ min _,k_ = min _h∈I_ 0 _M−_ 1 _V_ ( _xr,k_ ) represents
the minimum HJ value over all surrounding HVs, where _xr,k_
is the relative state at time step _k_ .
By incorporating this safety-guided objective function into
the iterative denoising procedure, the diffusion planner is
naturally steered towards safer regions of the trajectory
space. This process yields a nominal control sequence that
explores toward safe, dynamically feasible behaviors.

_2) Receding Horizon Planning with Safety Shielding_
We adopt a receding horizon planning scheme to deploy
the model-based diffusion model in dynamic environments.
To maintain computational tractability, the implementation
incorporates a warm-start strategy.
After an initial planning step with backward denoising
process from a Gaussian prior, each subsequent planning
cycle is initialized by adding a limited number of noise steps
to the previously computed control sequence in the forward
process (9). This warm-start procedure seeds the sampler
with prior solution information to accelerate convergence,
reducing the required number of denoising iterations in
practice, i.e., _Nws < Nd_ . However, even with this efficient
planning scheme, the proactive safety guidance serves as a
soft penalty. The planner may still generate trajectories that
trade a degree of safety for higher performance.
To provide principled safety, we introduce a reactive safety
shield. This shield constitutes the second, critical use of
our pre-computed HJ value function. We repurpose _V_ ( _xr_ )
as a CBVF. The core principle is to enforce the forward
invariance of the safe set _S_ = _{xr |_ _V_ ( _xr_ ) _≥_ 0 _}_ by ensuring that
the condition, _V_ [˙] ( _xr_ ) _≥−α_ ( _V_ ( _xr_ )), is satisfied at all times.
Here, _α_ ( _·_ ) is a class- _K_ function [29].
Enforcing this condition in an interactive setting requires
robustness against the uncertain actions of the HVs. We



s.t. _LGAV_ ( _xr_ ) _·_ _u ≥−L_ _f_ 0 _V_ ( _xr_ ) _−_ _α_ ( _V_ ( _xr_ ))

_−_ min [ _LGBV_ ( _xr_ ) _·_ _uh_ ] _−_ _ε,_ _∀_ _h ∈_ _I_ 0 _[M][−]_ [1] _._
_uh∈Uh_



(15)



The integration of proactive guidance and reactive certification constitutes the DualShield algorithm, which is
detailed in Alg. 1. This synergy ensures high-performance,
multimodal exploration while providing principled safety
assurance in a unified and computationally tractable manner.


IV. SIMULATION AND RESULTS

To validate the effectiveness of our proposed
DualShield framework, we design challenging interactive


driving scenarios and conduct a comprehensive comparative
analysis against the baselines.

_A. Task: Unprotected Interactive U-Turn Under Uncertainty_


The EV is required to conduct a U-turn before merging
into the main lane. This task is challenging as it requires
navigating a non-convex space while handling significant
interaction uncertainty from oncoming HVs.

_B. Experimental Setup_


_1) Vehicle and Environment Modeling_
Let the state vector of the EV be _x_ = [ _px, py,_ _θ_ _,_ _v_ ] _[T]_ and the
control vector be _u_ = [ _w,_ _a_ ] _[T]_, where _w_ is the yaw rate and _a_
is the longitudinal acceleration. Similarly, the state vector of
the HV is _xh_ = [ _px,h, py,h,_ _θh,_ _vh_ ] _[T]_ with control vector _uh_ =

[ _wh,_ _ah_ ] _[T]_ defined analogously. Their world-frame dynamics
are as follows:


_p_ ˙ _x_ = _v_ cos( _θ_ ) _,_ _p_ ˙ _y_ = _v_ sin( _θ_ ) _,_ _θ_ ˙ = _w,_ _v_ ˙ = _a,_

_p_ ˙ _x,h_ = _vh_ cos( _θh_ ) _,_ _p_ ˙ _y,h_ = _vh_ sin( _θh_ ) _,_ _θ_ ˙ _h_ = _wh,_ _v_ ˙ _h_ = _ah._

We denote the relative state as _xr_ = [ _px,r, py,r,_ _φr,_ _v,_ _vh_ ] _[T]_ in
the body frame of EV, where _px,r, py,r_ denote the relative
position of the HV, _φr_ = _θh −_ _θ_ denotes relative orientation,
and _v,_ _vh_ are absolute speeds of the EV and HV, respectively.
The transformation from world to body frame is given by:

    - _px,r_    -    - cos( _θ_ ) sin( _θ_ )�� _px,h −_ _px_    
=

_py,r_ _−_ sin( _θ_ ) cos( _θ_ ) _py,h −_ _py_


By taking the time derivative of each component of _xr_, we
obtain the relative dynamics:




_•_ **Cooperative:** The HV yields to the preceding EV, maintaining a safe following distance using the intelligent
driver model (IDM).

_•_ **Oblivious:** The HV ignores the EV and maintains its
pre-defined lane-following velocity.

_•_ **Adversarial:** The HV accelerates to contest the rightof-way at its max acceleration, creating a worst-case
threat for the EV.


_2) Objective Function and Parameter Setting_
The performance objective, _J_ perf, encodes desirable driving
behaviors, requiring the EV to execute a U-turn from an
initial state _x_ 0 = [2 _,_ 0 _._ 7 _,_ _π,_ 0 _._ 5] _[T]_ to a target driving state _xg_ =

[ _px,g, py,g,_ _θg,_ _vg_ ] _[T]_ = [2 _,_ _−_ 0 _._ 7 _,_ 0 _,_ 0 _._ 5] _[T]_ . It is a weighted sum
over a planning horizon of _N_ steps:



_N−_ 1
## J perf = ∑

_k_ =0




- _w_ goal _J_ goal( _xk_ )+ _w_ reg _J_ reg( _xk,_ _uk_ )� _,_ (16)




- - cos( _θ_ ) sin( _θ_ )
=

_−_ sin( _θ_ ) cos( _θ_ )



�� _px,h −_ _px_
_py,h −_ _py_
































- _w_ _a_


����
_u_



~~����~~
_uh_



















where the goal-tracking cost _J_ goal( _xk_ ) = _∥xk −_ _xg∥_ [2] _Q_ [penal-]
izes the weighted squared error between the state _xk_ and
_xg_, and weighting matrix is _Q_ = diag(0 _,_ 20 _,_ 5 _,_ 1). Notably,
there is no penalty on the longitudinal position _px_, as the
objective is to merge into the target lane and subsequently
engage in lane-keeping, rather than reach a specific waypoint. The non-differentiable regularization cost _J_ reg = _J_ rule +
_J_ boundary + _J_ spin encourages smooth and rule-compliant driving. It consists of three components: _J_ rule = _γ_ turn max(0 _, py_ ) _·_
max(0 _,_ cos( _θ_ )) penalizes driving in the wrong direction;
_J_ boundary = _γb_ (max(0 _, py −_ _y_ max) [2] + max(0 _,_ _y_ min _−_ _py_ ) [2] ) is a
penalty for violating the lateral boundaries at [ _y_ min _,_ _y_ max] =

[ _−_ 1 _._ 5 _,_ 1 _._ 5]; and _J_ spin = _γ_ spin _ω_ [2] exp( _−cvv_ [2] ) penalizes dry
steering behaviors. All weights are empirically tuned for
desired behaviors: _γ_ spin = 1, _cv_ = 5, _γ_ turn = 50, _γb_ = 20, and
_cv_ = 5. The coefficients for the HJ safety term (14) is set to
_γ_ = 10 and _λs_ = 1.


_C. Baselines for Comparison_

To comprehensively validate the superiority of our framework, we benchmark its performance against three baselines,
each meticulously selected to represent a dominant and
distinct planning paradigm:


_•_ **Model-Based Diffusion (MBD) [22]:** As a state-of-theart representative of generative planners, MBD utilizes
a diffusion model for multimodal trajectory generation,
enforcing safety through a distance-based penalty score
function. For a fair comparison, it is configured with the
same receding horizon and warm-start strategy as our
method.

_•_ **Nonlinear MPC (NMPC):** A standard NMPC handles obstacle avoidance with nonlinear constraints using
CasADi and IPOPT solver. Its cost function is configured to be analogous to ours for a fair comparison.

_•_ **DualGuard-MPPI [37]:** This baseline represents the
paradigm of sampling-based planners with strong safety
considerations. It employs the same HJ value function
as a rejection sampler for safe rollouts and as a trigger
for a switching-based safety filter.



_x_ ˙ _r_ =







_−v_ + _vh_ cos( _φr_ )
_vh_ sin( _φr_ )
0
0
0



+







_py,r_ 0
_−px,r_ 0

_−_ 1 0
0 1
0 0



+







0 0
0 0
1 0
0 0
0 1




- _wh_
_ah_



_._




~~�~~ ~~��~~ ~~�~~
_f_ 0( _xr_ )




~~�~~ ~~�~~ - ~~�~~
_GA_ ( _xr_ )




~~�~~ - ~~��~~
_GB_ ( _xr_ )



Simulations are conducted in a 1 : 4 scaled environment
mirroring a real-world intersection. There are two HVs and
20 static obstacles in the setting. The lane width is set to
1 _._ 5m. Both the EV and HVs are modeled with a rectangle
footprint of 1 _._ 0m in length and 0 _._ 4m in width. For safety
analysis, this footprint is approximated by a dual-circle
model, which consists of two circles, each with a radius of
0 _._ 3m. The centers of these circles are located 0 _._ 25m ahead
of and behind the geometric center along its longitudinal
axis. Static obstacles, representing lane dividers, are modeled
as circles with a 0 _._ 1m radius. To enhance computational
efficiency, we treat the EV as a point and inflate the radii
of all other objects accordingly. Additionally, only the three
nearest static obstacles are considered in the safety shield.
For the EV, the angular velocity _ω ∈_ [ _−π/_ 3 _,_ _π/_ 3] rad/s and
acceleration _a ∈_ [ _−_ 1 _,_ 1] m/s [2] ; whereas for all the HVs, _ωh ∈_

[ _−π/_ 18 _,_ _π/_ 18] rad/s and _ah ∈_ [ _−_ 1 _,_ 1] m/s [2] .
We use constant velocity prediction for the planning
methods. However, to model the uncertainty, the HVs are
actually programmed with three distinct interactive patterns,
randomly selected at the start of each trial:


Fig. 2. Visualization of the safety-guided denoising process at different
steps. The planner begins with a cloud of noisy trajectories ( _i_ = 99). As
the process continues, the safety-guided score steers the distribution until it
converges to a high-quality, safe trajectory distribution ( _i_ = 1).


_D. Implementation and Evaluation_


_1) Implementation Details_
The value functions for relative dynamics are precomputed using the hj ~~r~~ eachability toolbox [1], which
implements the methods described in [43]. The distance
function _l_ ( _xr_ ) for failure set _Fr_ is designed as _lr_ ( _xr_ ) =
_xr_ [2] _[−]_ _[r]_ _s_ [2][, where] _[ r][s]_ [is set to 0] _[.]_ [6 and 0] _[.]_ [4 for HVs and static]
obstacles, respectively. We use a 100 _×_ 100 _×_ 64 _×_ 8 _×_ 8 grid
for the 5D relative state ( _px,r, py,r,_ _ψr,_ _v,_ _vh_ ) over the domain

[ _−_ 8 _,_ 8] _×_ [ _−_ 8 _,_ 8] _×_ [0 _,_ 2 _π_ ] _×_ [0 _,_ 4] _×_ [0 _,_ 4] (m, m, rad, m/s, m/s).
_Th j_ is set to 1s. The pre-computation takes approximately
3h on a workstation equipped with 2.60 GHz Intel Xeon
Platinum 8358P CPU.
Our simulation environment is developed in Python, leveraging the JAX library for high-performance numerical computations and automatic differentiation. Key hyperparameters
include _Nd_ = 100 normal denoising steps, _Nws_ = 5 warmstart denoising steps, and a sample size of _Nm_ = 2000. Our
planning horizon is set to _N_ = 50 with a sampling period of
_dt_ = 0 _._ 1s. The total simulation duration is 10s. The penalty
weight in (15) for the slack variable is set to _cε_ = 10 [8] .
To ensure statistical significance, we perform 100 simulation trials. These are structured as 10 trials for each of
the 10 randomly generated scenario configurations. For each
configuration, the initial speeds of HVs are sampled from

[0 _._ 5 _,_ 2 _._ 0] m/s, and its interactive behavior is chosen randomly.

_2) Evaluation Metrics_
We evaluate the performance based on safety, mission
success, and comfort:


_•_ **Safety:** Collision rate _Pc_ (%) and the minimum distance
_lr,min_ (m) between EV and HVs/static obstacles. A value


[1https://github.com/StanfordASL/hj_reachability](https://github.com/StanfordASL/hj_reachability)



TABLE I


PERFORMANCE COMPARISON AMONG DIFFERENT METHODS.


**Method** _Ps ↑_ _Pc ↓_ _lr,min_ (m) _↑_ _Tm_ (s) _↓_ _j_ (m/s [3] ) _↓_ _Tc_ (s) _↓_


MBD [22] 90% 10% 0.16 4.3 3.10 0.41
NMPC 0% 0% 0.28 - 0.10 0.38
DualGuard-MPPI [37] 80% 0% 0.24 7.39 6.40 0.24
**DualShield (Ours)** 100% 0% 0.26 4.7 2.78 0.78


of _lr,min ≤_ 0 indicates a collision.

_•_ **Mission Success:** Success rate _Ps_ (%) and mission
completion time _Tm_ (s). A trial succeeds if the EV
enters and remains in the target lane-keeping state for 5
consecutive steps (defined by lateral error _|py −_ _pg,y| ≤_
0 _._ 2 m, heading error _|θ −_ _θg| ≤_ _π/_ 3, and speed _|v| ≥_
0 _._ 2 m/s). The completion time is recorded at the onset
of this stable period.

_•_ **Comfort:** Average control jerk _j_ (m/s³).

_•_ **Computation Efficiency:** Average computation time _Tc_
(s) per planning step.


_E. Results and Analysis_


_1) Comparative Performance Analysis_
We now present a quantitative comparison of
DualShield against the baseline methods, with results
summarized in Table I. Representative closed-loop trajectory
comparisons are shown in Fig. 3. While MBD achieves a
high success rate (90%), its 10% collision rate underscores
the fundamental risk of relying solely on distance-based soft
collision penalties with inaccurate predictions. When the
adversarial HV1 accelerates and deviates from the simple
constant-velocity prediction, the trajectory of MBD becomes
unsafe, leading to collisions. NMPC fails to complete the
task (0% success), highlighting its vulnerability to local
minima in this highly non-convex planning landscape.
DualGuard-MPPI ensures safety (0% collision) but does so
at a significant cost to performance, exhibiting the longer
average completion time and higher control jerk than our
method. This underscores the performance limitations of
relying on local perturbation-based sampling.
In contrast, DualShield is the only method that
achieves a perfect success rate (100%) while avoiding collisions. It simultaneously attains the shortest completion time
among all safe planners, which indicates the effectiveness of
the proactive guidance of HJ value functions toward safe and
high-performance regions. It accounts for the entire set of
possible future maneuvers from the HVs, including worstcase accelerations. The result demonstrates the robustness
of the DualShield in ensuring safety, even with a simple
constant-velocity model for planning. We acknowledge that
the current implementation is slower than the baselines,
mainly due to the large number of value function queries
performed during sampling and safety shielding. This computational cost can be mitigated through GPU-parallel sampling and a more efficient, batched and just-in-time (JIT)
compiled value-query pipeline. A sequence of snapshots
from a representative trial, presented in Fig. 4, visualizes
this effective interplay between planning and safety.


Fig. 3. Comparison of closed-loop trajectories in a representative scenario
with adversarial HV1 and HV2. (a) MBD: Collides with the HV1 due
to reliance on soft penalties. (b) NMPC: Fails by getting trapped in a
local minimum. (c) DualGuard-MPPI: Ensures safety but results in an
inefficient, hesitant trajectory. (d) DualShield: Achieves a safe and
efficient trajectory by proactively navigating the interaction (see Fig. 4 for
the snapshots of dynamic interaction).


Fig. 4. Snapshots of DualShield executing a tactical U-turn. It first
yields to the adversarial HV1, then accelerates to merge safely behind the
adversarial HV2, ultimately achieving a stable lane-keeping state in the
target lane. This safe maneuver is achieved despite relying on a simple
constant velocity prediction for both HVs, as the underlying reachability
analysis accounts for the full range of their potential actions. The contours
depict the HJ value function relative to the most threatening HV, with the
black line marking the BRT boundary.


_2) Analysis of the Safety-Guided Denoising Process_

To understand how DualShield generates high-quality
trajectories, we visualize the trajectory distribution at different stages of the iterative denoising process within a
single planning cycle, shown in Fig. 2. The planner starts
with a diverse set of noisy candidate sequences sampled
from a Gaussian prior. In the early stages of denoising,
the trajectories are chaotic and explore a wide area of the
state space. As the reverse diffusion process progresses,
the effect of our HJ value guidance becomes apparent. It
effectively penalizes candidate trajectories that would enter
unsafe regions, steering the distribution away from them.
Simultaneously, the goal and regularization terms guide
the candidates toward the desired task goal. This guided
evolution rapidly collapses the distribution from a noisy,
high-entropy state to a low-entropy distribution concentrated
around a safe and dynamically feasible optimal trajectory.



This demonstrates the efficiency of our approach in navigating non-convex optimization landscapes with complex nondifferentiable objective function.

_3) Flexible Multimodal Behaviors under Uncertainty_
Fig. 5 showcases the multimodal planning capability of
DualShield. This ability to select the optimal strategy
from a rich, safety-certificated distribution of behaviors highlights how DualShield unifies discrete strategic reasoning
with continuous trajectory optimization. It leverages the
exploratory power of generative models while anchoring
every decision in principled safety assurance.


V. CONCLUSION
In this paper, we presented DualShield, a unified
planning and control framework that resolves the core
tension between multimodal exploration and formal safety
in dynamic interactive driving. By repurposing HJ value
functions for both proactive guidance and reactive shielding,
DualShield robustly handles uncertain interactions with
principled safety. Our simulation results demonstrate that this
dual-use architecture enables high mission success rates and
efficient trajectories while maintaining safety, a balance that
proved challenging for baseline methods. Looking ahead, a
key research avenue is the online approximation of HJ values
via reinforcement learning, removing the dependency on precomputed values and allowing for greater generalization.
REFERENCES


[1] L. Chen, Y. Li, C. Huang, B. Li, Y. Xing, D. Tian, L. Li, Z. Hu, X. Na,
Z. Li _et al._, “Milestones in autonomous driving and intelligent vehicles: Survey of surveys,” _IEEE Transactions on Intelligent Vehicles_,
vol. 8, no. 2, pp. 1046–1056, 2022.

[2] L. Zheng, R. Yang, Z. Peng, M. Y. Wang, and J. Ma, “Spatiotemporal receding horizon control with proactive interaction towards
autonomous driving in dense traffic,” _IEEE Transactions on Intelligent_
_Vehicles_, vol. 9, no. 11, pp. 6853–6868, 2024.

[3] L. Zheng, R. Yang, M. Yu Wang, and J. Ma, “Barrier-enhanced parallel
homotopic trajectory optimization for safety-critical autonomous driving,” _IEEE Transactions on Intelligent Transportation Systems_, vol. 26,
no. 2, pp. 2169–2186, 2025.

[4] X. Zhang, S. Zeinali, and G. Schildbach, “Interaction-aware traffic
prediction and scenario-based model predictive control for autonomous
vehicles on highways,” _IEEE Transactions on Control Systems Tech-_
_nology_, vol. 33, no. 4, pp. 1235–1245, 2025.

[5] ´A. Carrizosa-Rend´on, V. Puig, and F. Nejjari, “Safe motion planner for
autonomous driving based on LPV MPC and reachability analysis,”
_Control Engineering Practice_, vol. 147, p. 105932, 2024.

[6] E. F. Camacho and C. Bordons, “Constrained model predictive control,” in _Model predictive control_ . Springer, 2007, pp. 177–216.

[7] L. Zheng, R. Yang, Z. Peng, M. Y. Wang, and J. Ma, “Spatiotemporal receding horizon control with proactive interaction towards
autonomous driving in dense traffic,” _IEEE Transactions on Intelligent_
_Vehicles_, 2024.

[8] L. Zheng, R. Yang, Z. Wu, J. Pan, and H. Cheng, “Safe learningbased gradient-free model predictive control based on cross-entropy
method,” _Engineering Applications of Artificial Intelligence_, vol. 110,
p. 104731, 2022.

[9] G. Williams, P. Drews, B. Goldfain, J. M. Rehg, and E. A. Theodorou,
“Information-theoretic model predictive control: Theory and applications to autonomous driving,” _IEEE Transactions on Robotics_, vol. 34,
no. 6, pp. 1603–1622, 2018.

[10] Q. Liu, B. Tian, X. Zhang, J. Lu, and Z. Li, “Sampling-based hierarchical trajectory planning for formation flight,” _IEEE Transactions on_
_Intelligent Transportation Systems_, vol. 26, no. 9, pp. 13 439–13 451,
2025.

[11] J. Yin, C. Dawson, C. Fan, and P. Tsiotras, “Shield model predictive
path integral: A computationally efficient robust mpc method using
control barrier functions,” _IEEE Robotics and Automation Letters_,
vol. 8, no. 11, pp. 7106–7113, 2023.


Fig. 5. Flexible multimodal planning of DualShield in varying multi-agent interactions. (a) When both HVs are cooperative, DualShield plans an
assertive merge. The planner then demonstrates robust adaptation to mixed-intent scenarios: (b) It safely navigates a contested space created by a yielding
HV1 and an adversarial HV2. (c) it adeptly handles the mirrored case with an adversarial HV1 and a yielding HV2. (d) Finally, when both HVs act
adversarially, the planner correctly identifies the high risk and switches to a safe, defensive yielding maneuver, robustly selecting the appropriate behavioral
mode. (The opacity indicates temporal progression, with current states at full opacity and past positions fading progressively.)




[12] J. Yin, Z. Zhang, E. Theodorou, and P. Tsiotras, “Trajectory distribution control for model predictive path integral control using
covariance steering,” in _IEEE International Conference on Robotics_
_and Automation_, 2022, pp. 1478–1484.

[13] E. Trevisan and J. Alonso-Mora, “Biased-MPPI: Informing samplingbased model predictive control by fusing ancillary controllers,” _IEEE_
_Robotics and Automation Letters_, vol. 9, no. 6, pp. 5871–5878, 2024.

[14] I. S. Mohamed, J. Xu, G. S. Sukhatme, and L. Liu, “Toward efficient
MPPI trajectory generation with unscented guidance: U-MPPI control
strategy,” _IEEE Transactions on Robotics_, vol. 41, pp. 1172–1192,
2025.

[15] M. Janner, Y. Du, J. Tenenbaum, and S. Levine, “Planning with
diffusion for flexible behavior synthesis,” in _International Conference_
_on Machine Learning_, 2022, pp. 9902–9915.

[16] Z. Zhong, D. Rempe, D. Xu, Y. Chen, S. Veer, T. Che, B. Ray,
and M. Pavone, “Guided conditional diffusion for controllable traffic simulation,” in _IEEE International Conference on Robotics and_
_Automation_, 2023, pp. 3560–3566.

[17] U. A. Mishra, S. Xue, Y. Chen, and D. Xu, “Generative skill chaining:
Long-horizon skill planning with diffusion models,” in _Conference on_
_Robot Learning_, 2023, pp. 2905–2925.

[18] C. Jiang, A. Cornman, C. Park, B. Sapp, Y. Zhou, D. Anguelov _et al._,
“MotionDiffuser: Controllable multi-agent motion prediction using
diffusion,” in _Proceedings of the IEEE/CVF Conference on Computer_
_Vision and Pattern Recognition_, 2023, pp. 9644–9653.

[19] B. Yang, H. Su, N. Gkanatsios, T.-W. Ke, A. Jain, J. Schneider, and
K. Fragkiadaki, “Diffusion-ES: Gradient-free planning with diffusion
for autonomous and instruction-guided driving,” in _Proceedings of the_
_IEEE/CVF Conference on Computer Vision and Pattern Recognition_,
2024, pp. 15 342–15 353.

[20] R. Yao, Y. Wang, H. Liu, R. Yang, Z. Peng, L. Zhu, and J. Ma,
“Calmm-Drive: Confidence-aware autonomous driving with large multimodal model,” _arXiv preprint arXiv:2412.04209_, 2024.

[21] K. Kondo, A. Tagliabue, X. Cai, C. Tewari, O. Garcia, M. EspitiaAlvarez, and J. P. How, “CGD: Constraint-guided diffusion policies
for uav trajectory planning,” _arXiv preprint arXiv:2405.01758_, 2024.

[22] C. Pan, Z. Yi, G. Shi, and G. Qu, “Model-based diffusion for trajectory
optimization,” _Advances in Neural Information Processing Systems_,
vol. 37, pp. 57 914–57 943, 2024.

[23] W. Jung, U. A. Mishra, N. R. Arachchige, Y. Chen, D. Xu, and
S. Kousik, “Joint model-based model-free diffusion for planning with
constraints,” _arXiv preprint arXiv:2509.08775_, 2025.

[24] V. Kurtz and J. W. Burdick, “Equality constrained diffusion for direct
trajectory optimization,” in _IEEE American Control Conference_, 2025,
pp. 535–540.

[25] J. Knaup, J. D’sa, B. Chalaki, H. N. Mahjoub, E. Moradi-Pari, and
P. Tsiotras, “Dual control for interactive autonomous merging with
model predictive diffusion,” _arXiv preprint arXiv:2502.09918_, 2025.

[26] K. Chen, Y. Luo, M. Zhu, and H. Yang, “Human-like interactive
lane-change modeling based on reward-guided diffusive predictor and
planner,” _IEEE Transactions on Intelligent Transportation Systems_,
2024.

[27] H. Ma, S. Bodmer, A. Carron, M. Zeilinger, and M. Muehlebach,
“Constraint-aware diffusion guidance for robotics: Real-time obstacle
avoidance for autonomous racing,” _arXiv preprint arXiv:2505.13131_,
2025.

[28] A. Agrawal and K. Sreenath, “Discrete control barrier functions



for safety-critical control of discrete systems with application to
bipedal robot navigation.” in _Robotics: Science and Systems_, vol. 13.
Cambridge, MA, USA, 2017, pp. 1–10.

[29] A. D. Ames, S. Coogan, M. Egerstedt, G. Notomista, K. Sreenath,
and P. Tabuada, “Control barrier functions: Theory and applications,”
in _IEEE European Control Conference_, 2019, pp. 3420–3431.

[30] A. D. Ames, J. W. Grizzle, and P. Tabuada, “Control barrier function
based quadratic programs with application to adaptive cruise control,”
in _IEEE Conference on Decision and Control_, 2014, pp. 6271–6278.

[31] D. Chen, R. Zhong, K. Chen, Z. Shang, M. Zhu, and E. Chung,
“Dynamic high-order control barrier functions with diffuser for safetycritical trajectory planning at signal-free intersections,” _IEEE Transac-_
_tions on Intelligent Transportation Systems_, vol. 26, no. 9, pp. 14 011–
14 024, 2025.

[32] K. Mizuta and K. Leung, “Cobl-Diffusion: Diffusion-based conditional
robot planning in dynamic environments using control barrier and lyapunov functions,” in _IEEE/RSJ International Conference on Intelligent_
_Robots and Systems_, 2024, pp. 13 801–13 808.

[33] L. Zhang, S. Han, and S. Grammatico, “Automated lane merging via
game theory and branch model predictive control,” _IEEE Transactions_
_on Control Systems Technology_, vol. 33, no. 4, pp. 1258–1269, 2025.

[34] M. Althoff and S. Magdici, “Set-based prediction of traffic participants
on arbitrary road networks,” _IEEE Transactions on Intelligent Vehicles_,
vol. 1, no. 2, pp. 187–202, 2016.

[35] M. Koschi and M. Althoff, “Set-based prediction of traffic participants considering occlusions and traffic rules,” _IEEE Transactions on_
_Intelligent Vehicles_, vol. 6, no. 2, pp. 249–265, 2020.

[36] X. Wang, K. Leung, and M. Pavone, “Infusing reachability-based
safety into planning and control for multi-agent interactions,” in
_IEEE/RSJ International Conference on Intelligent Robots and Systems_,
2020, pp. 6252–6259.

[37] J. Borquez, L. Raus, Y. U. Ciftci, and S. Bansal, “DualGuard MPPI:
Safe and performant optimal control by combining sampling-based
mpc and Hamilton-Jacobi reachability,” _IEEE Robotics and Automa-_
_tion Letters_, vol. 10, no. 7, pp. 6944–6951, 2025.

[38] K. Leung, E. Schmerling, M. Zhang, M. Chen, J. Talbot, J. C. Gerdes,
and M. Pavone, “On infusing reachability-based safety assurance
within planning frameworks for human-robot vehicle interactions,” _The_
_International Journal of Robotics Research_, vol. 39, no. 10-11, pp.
1326–1345, 2020.

[39] H. Hu, K. Nakamura, and J. F. Fisac, “SHARP: Shielding-aware
robust planning for safe and efficient human-robot interaction,” _IEEE_
_Robotics and Automation Letters_, vol. 7, no. 2, pp. 5591–5598, 2022.

[40] H. Hu, D. Isele, S. Bae, and J. F. Fisac, “Active uncertainty reduction
for safe and efficient interaction planning: A shielding-aware dual
control approach,” _The International Journal of Robotics Research_,
vol. 43, no. 9, pp. 1382–1408, 2024.

[41] J. J. Choi, D. Lee, K. Sreenath, C. J. Tomlin, and S. L. Herbert,
“Robust control barrier–value functions for safety-critical control,” in
_IEEE Conference on Decision and Control_ . IEEE, 2021, pp. 6814–
6821.

[42] S. Tonkens and S. Herbert, “Refining control barrier functions through
Hamilton-Jacobi reachability,” in _IEEE/RSJ International Conference_
_on Intelligent Robots and Systems_, 2022, pp. 13 355–13 362.

[43] S. Bansal, M. Chen, C. Herbert, and C. J. Tomlin, “Hamilton-Jacobi
Reachability: A brief overview and a toolbox,” in _IEEE Conference_
_on Decision and Control_, 2017, pp. 2241–2250.


