## ENHANCED CONVERGENCE IN P-BIT BASED SIMULATED ANNEALING WITH PARTIAL DEACTIVATION FOR LARGE-SCALE COMBINATORIAL OPTIMIZATION PROBLEMS

A PREPRINT


Naoya Onizawa [1] and Takahiro Hanyu [1]


1Research Institute of Electrical Communication, Tohoku University, Sendai, 980-8577, Japan


**ABSTRACT**


This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins
with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus
obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the
pSA operation as the primary contributor to these disruptive oscillations. To address this challenge,
we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python
simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On
the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut
value from 0.8% to 98.4% on average in comparison with the conventional pSA.


**Introduction**


In recent years, a new device model known as the probabilistic bit, or p-bit, has been proposed Camsari et al. [2017].
Unlike traditional bits which can only exist in a state of 0 or 1, a p-bit can exist in a range of states between 0 and 1,
each state has a certain probability of occurring. The p-bit is a versatile computational model that can be implemented
in software Pervaiz et al. [2017] or emerging probabilistic devices, such as Magnetoresistive Random Access Memory
(MRAM) Borders et al. [2019]. Furthermore, it can be approximated by digital circuits, such as Field-Programmable
Gate Arrays (FPGAs) Pervaiz et al. [2019], Smithson et al. [2019], Sutton et al. [2020], Aadit et al. [2022a]. This
probabilistic nature makes p-bits a useful tool in solving certain types of problems that require a degree of randomness
or uncertainty. The output state of a p-bit is represented as follows:


                  -                  -                  - [�]
_σi_ ( _t_ + 1) = sgn _ri_ ( _t_ ) + tanh _Ii_ ( _t_ + 1) _,_ (1)


where _σi_ ( _t_ + 1) _∈{−_ 1 _,_ 1 _}_ is a binary output signal, _Ii_ ( _t_ + 1) is a real-valued input signal, and _ri_ ( _t_ ) _∈{−_ 1 : 1 _}_ is a
random signal.


The utilization of p-bits is notably effective in the development of a specific neural network variant, the Boltzmann
machine Hinton et al. [1984]. This model is particularly well-adapted for tasks that require invertible logic Onizawa
et al. [2020], where inputs and outputs can be interchanged. Moreover, it has significant applications in Bayesian
inference Kaiser et al. [2022], parallel tempering Grimaldi et al. [2022], Gibbs sampling Aadit et al. [2022b], and
simulated annealing (SA) Camsari et al. [2019].


SA is a stochastic optimization technique widely used for addressing combinatorial optimization problems Kirkpatrick
et al. [1983], Johnson et al. [1981]. Its applications span diverse real-world scenarios, including solving the maximum
cut (MAX-CUT) problem in network analysis Mykleburst [2015], optimizing communication systems Elmitwalli et al.

[2023], and enhancing various machine learning algorithms Park et al. [2021].


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Combinatorial optimization problems can often be represented by Ising models, which are mathematical representations of networks or graphs. These problems are often categorized as NP-hard Reiter and Johnson [2012], meaning
that the time required to find the optimal solution tends to grow exponentially with the size of the problem, making
them computationally challenging to solve. The goal of simulated annealing in this context is to minimize the ‘energy’
of the Ising model, where ‘energy’ is a metaphor for the objective or cost function of the optimization problem. The
global minimum energy state corresponds to the optimal solution to the combinatorial optimization problem.


Diverse enhancements and adaptations of SA, including parallel tempering and stochastic simulated annealing (SSA),
have been devised to improve efficiency in solving combinatorial optimization problems Earl and Deem [2005],
Onizawa et al. [2022 (to appear]. Additionally, hardware implementations of SA have been explored for rapidly
addressing large-scale combinatorial optimization challenges Aramon et al. [2019], Gyoten et al. [2018], Shin et al.

[2023].


More advanced computational methods such as quantum annealing (QA) Kadowaki and Nishimori [1998], Boixo et al.

[2014] have been developed, with expectations of faster processing times compared to SA Neven [2016]. However, despite its potential, the realization of quantum annealing is currently restricted due to limitations in device performance.
Large-scale problems remain challenging to solve using quantum annealing methods Zick et al. [2015], Yarkoni et al.

[2022].


In addition to simulated annealing, various other algorithms have been developed for solving Ising models. These
include coherent Ising machines Wang et al. [2013], simulated bifurcation Goto et al. [2019], and coupled oscillation
networks Dutta et al. [2021].


Simulated annealing that utilizes p-bits (pSA) is grounded in a probabilistic computing paradigm, which enables its
implementation on classical computers. This theoretical framework positions pSA as a potential tool for efficiently
solving large-scale problems.


A potential advantage of pSA is its ability to update nodes in parallel, as opposed to the serial updating method of
traditional SA. This means that multiple nodes in the network can be updated simultaneously rather than one at a time,
which could potentially lead to a faster convergence to the global minimum energy state, speeding up the process
of finding the optimal solution. Preliminary studies have demonstrated that pSA can effectively solve small-scale
problems Camsari et al. [2019]. On the other hand, the efficacy of pSA appears to diminish as the scale of the problem
increases.


Simulation studies have indicated that as the size of the problems increases, particularly in the cases of graph isomorphism and MAX-CUT problems, the effectiveness of finding solutions using pSA significantly diminishes Onizawa
et al. [2022 (to appear].


One of the challenges is that the energy of the Ising model does not decrease as expected and remains high, indicating
that pSA struggles to find optimal or near-optimal solutions for these larger problems.


In pSA, the exact reasons behind this limitation remain unclear and are yet to be understood.


The initial part of this article will involve a detailed analysis of the issues encountered with pSA. This will involve
using simulation techniques to study the behavior of the p-bits in detail, with the aim to identify the root cause of
the aforementioned problems. The analysis identifies that the failure to lower the energy of the Ising model, which is
an issue encountered during the optimization process, stems from oscillations occurring among the p-bits. This issue
arises because pSA operates as a feedback system, where the output at one stage becomes the input for the next stage,
causing the oscillations to occur and impede the reduction of energy. Based on the insights gained from the analysis,
two new pSA algorithms are introduced: time average pSA (TApSA) and stalled pSA (SpSA). These algorithms aim
to counteract the oscillations based on partial deactivation of p-bits, thereby overcoming the main issue identified with
the current pSA process. These newly proposed algorithms are then put to the test through simulations conducted
using Python. The simulations are applied to solve maximum cut (MAX-CUT) problems Burer et al. [2001], which
are typical examples of combinatorial optimization problems. The simulation results demonstrate that the newly
proposed pSA algorithms significantly outperform both the conventional pSA algorithm and traditional SA algorithms
This implies that these new algorithms may provide a more effective method for solving combinatorial optimization
problems, especially for larger problem sizes where traditional methods struggle.


2


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 1: Simulated annealing based on p-bit (pSA). p-bits (left) probabilistically operates based on Eq. (1). A
combinatorial optimization problem is represented by an Ising model that corresponds to an energy (Hamiltonian).
Based on an Ising model, each p-bit is biased with _h_ and is connected with other p-bits with weights _J_ (right top).
During the simulated annealing process, an pseudo inverse temperature _I_ 0 is gradually increased to reach the global
minimum energy ( _Hmin_ ). pSA attempts to lower the energy of the Ising model by changing the p-bit states _σi_ . If the
energy reaches the global minimum energy _σi_ are a solution of the combinatorial optimization problem (right bottom).


**Methods**


**Problem identification of pSA**


A combinatorial optimization problem is represented using an Ising model that represents an energy. The energy is
represented by Hamiltonian that is defined as follows:



_hiσi −_  
_i_ _i<j_



_H_ ( _σ_ ) = _−_ 


_Jijσiσj,_ (2)

_i<j_



where _σi ∈{−_ 1 _,_ 1 _}_ is a binary state, _h_ are biases for p-bits, and _J_ are weights between p-bits. Depending on
combinatorial optimization problems, different _h_ and _J_ are assigned. Simulated annealing attempts to reach the global
minimum energy of Eq. (2) by changing the states _σi_ . An algorithm of chancing _σi_ is different depending on SA
algorithms Kirkpatrick et al. [1983], Camsari et al. [2019], Gyoten et al. [2018], Onizawa et al. [2022 (to appear].


pSA Camsari et al. [2019] is illustrated in Fig. 1. In pSA, each p-bit is biased with _h_ and is connected with other p-bits
with weights _J_ . The input of p-bit _Ii_ ( _t_ + 1) is calculated using the outputs of other p-bits that is defined as follows:











 _,_ (3)



_Ii_ ( _t_ + 1) = _I_ 0



 _hi_ + 


_Jij · σj_ ( _t_ )

_j_



where _I_ 0 is a pseudo inverse temperature used to control the simulated annealing. During the simulated annealing
process, _I_ 0 is gradually increased in attempt to lower the energy of the Ising model. When _I_ 0 is small, _σi_ can be easily


3


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 2: A five-node maximum cut (MAX-CUT) problem with edge weights of _−_ 1 and +1. MAX-CUT problem is
a typical combinatorial optimization problem. The line cuts the edges to divide the graph into two groups while the
sum of the edge weights is maximized. The graph is divided into Group A (nodes 1, 3, and 4) and Group B (nodes 2
and 5), with a sum of edge weights equal to 4.


Figure 3: Issue of pSA. pSA is simulated by Python with G1 that is a MAX-CUT problem of the G-set benchmark.
During the simulated annealing process, the pseudo inverse temperature _I_ 0 is increased to control pSA (a). A mean of
all the p-bits states is changed between ‘-1’ and ‘+1’ at every cycle (b). Because of this oscillation, the energy starts
to increase after the oscillation, although the energy is expected to be lower to the global minimum energy (c).


flipped between ‘-1’ and ‘+1’ to search for many possible solutions of the combinatorial optimization problem. When
_I_ 0 is large, _σi_ can be stabilized in attempt to reach the global minimum energy. _σi_ can be found as the solution of the
combinatorial optimization problem at the global minimum energy.


Let us explain an issue of pSA using a simulated result of a maximum-cut (MAX-CUT) problem that is a typical
combinatorial optimization problem Burer et al. [2001] (Fig. 2). The MAX-CUT problem aims to partition a graph
into two groups in such a way that the sum of the weights of the edges crossing between the two groups is maximized.
This process involves ‘cutting’ the graph into two separate sections, hence the term ‘MAX-CUT’. A five-node MAXCUT problem with edge weights of _−_ 1 and +1 is illustrated (Fig. 2). The black circle illustrates a spin state of ‘+1’,
while the white circuit illustrates a spin state of ‘-1’. In the graph, the weight associated with each edge, which can be
either -1 or +1, is symbolized by the variable _J_ . This variable is crucial in the MAX-CUT problem as it determines the
optimal partition of the graph. During the simulated annealing process, the spin states are flipped to lower the energy.
The goal is to find the optimal solution, which corresponds to the minimum energy state. After the process, the graph
is divided into Group A (nodes 1, 3, and 4) and Group B (nodes 2 and 5), with a sum of edge weights equal to 4.


pSA with the G1 problem is simulated to identify and understand the current issue of pSA. The pSA algorithm is
executed using Python 3.11 on Apple M1 Ultra with 128 GB memory. G1 is a specific combinatorial optimization
challenge called the MAX-CUT problem from the G-set benchmark Ye [1999]. The G1 graph consists of 800 nodes
and 19,176 edges that are randomly interconnected. To manage the simulated annealing process of pSA, the pseudo inverse temperature _I_ 0 is gradually increased over time from _I_ 0 _min_ to _I_ 0 _max_, following the formula _I_ 0( _t_ +1) = _I_ 0( _t_ ) _/β_,
where _β_ is 0.995, _I_ 0 _min_ is 0.0149, and _I_ 0 _max_ =1.49 (Fig. 3(a)). A method of determining these hyperparameters will
be explained in the last subsection. During the simulated annealing process, all the p-bit states _σi_ start to oscillate
between ‘-1’ and ‘+1’. The average value of all the p-bit states is changed between ‘-1’ and ‘+1’ at every cycle (Fig. 3


4


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


(b)). An unexpected issue arises due to this oscillation: the energy starts to increase rather than decrease towards a
global minimum (Fig. 3 (c)). This suggests that pSA is not reaching the optimal solution, as we would typically expect
the energy to minimize in a successful simulated annealing process.


**Proposed algorithms based on partial deactivation of p-bits**


**SA based on time average p-bit (TApSA)**


In this article, two new pSA algorithms with nonlinear functions are introduced, which partially deactivates p-bits to
mitigate the oscillations. The first algorithm is SA based on time average p-bit (TApSA). The TApSA algorithm draws
its inspiration from stochastic simulated annealing (SSA) Onizawa et al. [2022 (to appear]. SSA approximates the
behavior of p-bits using a method called stochastic computing, which is particularly suited for simulated annealing
processes. Stochastic computing is a computational approach where values are represented as the frequencies (time
averages) of 1s in bit streams Gaines [1969], Brown and Card [2001]. This allows for the efficient operation of time
series computations in a way that is hardware efficient in terms of physical area usage Gaudet and Gross [2019]. The
use of stochastic computing has been successfully applied in a range of computational applications, such as in lowdensity parity-check decoders, image processing, digital filters, and deep neural networks Gaudet and Rapley [2003],
Li et al. [2014], Liu and Parhi [2016], Ardakani et al. [2017]. The SSA approach approximates the tanh function
(Eq. (1)), a key component of the pSA operation, using a saturated updown counter, which results in an operation that
calculates tanh in a time series manner. Contrary to pSA, SSA has been shown to be capable of effectively solving
large-scale combinatorial optimization problems. This suggests that the new TApSA algorithm, which is inspired by
SSA, could potentially address the limitations identified in traditional pSA when dealing with large problem sizes.


Based on the previously discussed explanations, the time average operation is a key element to solve the issue of pSA.
The proposed TApSA incorporates a time-average operation into the pSA algorithm. This operation, which is added
to Eq. (3) of pSA, is defined as follows:


_TIi_ ( _t_ + 1) = _hi_ +                  - _Jij · σj_ ( _t_ ) _,_ (4a)


_j_



_,_ (4b)



_α−_ 1




_TIi_ ( _t_ + 1 _−_ _i_ )

_i_ =0







_Ii_ ( _t_ + 1) = _I_ 0




1

_α_



where _TIi_ ( _t_ + 1) represents a temporary value used for the time averaging operation and the variable _α_ is the size
of the time window over which _TIi_ ( _t_ + 1) is averaged. _Ii_ ( _t_ + 1) is the input for the p-bit, as defined in Eq. (1) that
is also used in TApSA. The set of equations in Eq. (4b) is responsible for calculating the time average of the p-bit
input signal. This operation effectively smooths out the signal over a certain time window, which helps to reduce
random fluctuations or ‘noise’ in the signal. Another consequence of this time-averaging operation is that it highlights
or emphasizes the lower frequency components of the signal while simultaneously reducing or attenuating the higher
frequency components.


**SA based on stalled p-bit (SpSA)**


The second algorithm is simulated annealing based on stalled p-bit (SpSA). SpSA takes inspiration from the sparse
random signals used in invertible logic operations Onizawa et al. [2021]. Invertible logic is an application of pbits, which permits bidirectional operations of any function. Sparse random signals are applied in such a way that
they probabilistically halt, or "stall," the addition of random signals to the invertible logic operations, subsequently
reducing error rates.


The SpSA algorithm employs a similar approach, where it probabilistically stalls the behavior of p-bits. Specifically,
in SpSA, the input of a p-bit, represented as _Ii_ ( _t_ ), is probabilistically stalled and maintains the same value _Ii_ ( _t_ ) from
the previous time step. The equation for SpSA as mentioned above is:



_Ii_ ( _t_ + 1) =




- _Ii_ ( _t_ ) _,_ with probability of getting stalled _p_




 _I_ 0 _hi_ + [�]




    - (5)
_j_ _[J][ij][ ·][ σ][j]_ [(] _[t]_ [)] _._ with probability(1 _−_ _p_ )



In this equation, the input of the p-bit at time t+1, _Ii_ ( _t_ + 1), can either be stalled (i.e., be the same as the input at
time t, _Ii_ ( _t_ )), with a probability _p_, or take on a new value with a probability of (1 _−_ _p_ ). This approach is a significant
deviation from traditional pSA, where Eq. (3) is replaced by Eq. (5) in SpSA.


5


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Graph # nodes Structure Weights ( _J_ ) # edges Best known value
G1 800 random +1 19176 11624
G6 800 random +1, -1 19176 2178
G11 800 troidal +1, -1 1600 564
G14 800 planar +1 4694 3064
G18 800 planar +1, -1 4694 992
G22 2000 random +1 19990 13359
G34 2000 troidal +1, -1 4000 1384
G38 2000 planar +1 11779 7688
G39 2000 planar +1, -1 11778 2408
G47 1000 random +1 9990 6657
G48 3000 troidal +1, -1 6000 6000
G54 1000 random +1 5916 3852
G55 5000 random +1 12498 10299
G56 5000 random +1, -1 12498 4017
G58 5000 planar +1 29570 19293
K2000 2000 full +1, -1 1999000 33337
Table 1: Summary of MAX-CUT benchmarks used for evaluating simulated annealing algorithms, including TApSA,
SpSA, and traditional SA and pSA. The Gxx graphs are part of the G-set benchmark Ye [1999], and K2000 is a fullyconnected graph benchmark Inagaki et al. [2016].


Algorithm Equations
pSA Camsari et al. [2019] Eqs. (1) and (3)
TApSA (proposed) Eqs. (1) and (4b)
SpSA (proposed) Eqs. (1) and (5)
Table 2: Summary of the determined hyperparameters for pSA, TApSA, and SpSA. In the simulated annealing process,
all the p-bit states are updated using these equations in parallel in attempt to reach the global minimum energy of an
Ising model.


**MAX-CUT problems and annealing parameters for evaluation**


The proposed TApSA and SpSA algorithms are evaluated in MAX-CUT problems using Python 3.11 on Apple M1
Ultra with 128 GB memory. Two MAX-CUT benchmarks, namely G-set and K2000, are used for these simulations
(Table 1). The G-set includes Gxx graphs that vary in node sizes and edge connections Ye [1999]. On the other hand,
K2000 represents a fully-connected graph with edge weights of either ‘-1’ or ‘+1’ Inagaki et al. [2016]. Before the
simulated annealing process begins, _J_ of the Ising model is assigned based on the graph weights.


Performance of the proposed TApSA and SpSA algorithms is compared with the traditional pSA. The annealing algorithms are outlined in Table 2. In these simulated annealing algorithms, a crucial factor is the manipulation of the
pseudo inverse temperature, a value which has significant implications on annealing to explore the solution space.
During the simulated annealing process, the pseudo inverse temperature _I_ 0 is gradually increased over time from the
initial value _I_ 0 _min_ to the maximum value _I_ 0 _max_, following the formula _I_ 0( _t_ + 1) = _I_ 0( _t_ ) _/β_ (Table 3). The hyperparameters for the simulated annealing processes, such as _I_ 0 _min_, _I_ 0 _max_, and _β_, are not arbitrarily selected. Rather,
they are determined in accordance with a specific statistical method, which is designed to optimize the performance
of the simulated annealing algorithm (SSA) Onizawa et al. [2023]. In addition to these, a traditional SA algorithm, a



Parameter Value
_si_ ~~�~~ ( _n −_ 1) _·_




~~�~~



_si_ ~~�~~ ( _n −_ 1) _·_ Var( _Ji,_ :)

_I_ 0 _min_ ~~_γ_~~



_I_ 0 _min_ mean( ~~_γ_~~ _si_ )

_I_ 0 _max_ mean( ~~_δ_~~ _si_ )




~~�~~ ( _cycle_ ~~1~~ _−_ 1 [)]



_β_




~~�~~ _I_ 0 _min_
_I_ 0 _max_



Table 3: Statistically determined hyperparameters for pSA, TApSA, and SpSA. A pseudo inverse temperature is
gradually increased over time from _I_ 0 _min_ to _I_ 0 _max_, following the formula _I_ 0( _t_ + 1) = _I_ 0( _t_ ) _/β_ . _γ_ = 0 _._ 1 and _δ_ = 10
are used in this article.


6


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 4: Simulation analysis of TApSA on the G1 graph with different window size _α_ . The mean values of all the
p-bit states are oscillated between ‘-1’ and ‘+1’ in case of _α_ of two and three (top of a and b), resulting in the energy
increase of the Ising model instead of decrease (bottom of a and b). When _α_ is four, no oscillation occurs and hence
the energy goes down to the global minimum energy (c). TApSA can solve the oscillation issue of pSA.


well-established method for optimization problems, is also implemented for the sake of performance comparison Mykleburst [2015]. In the traditional SA algorithm, the annealing temperature _T_ is managed in a slightly different manner:
the temperature is gradually decreased at each cycle by a factor of ∆ _IT_, following the equation _T ←_ 1 _/_ (1 _/T_ + ∆ _IT_ ).
In this experiment, the initial temperature is set to 1, and the final temperature is set to 1/1000.


All of the simulated annealing algorithms, including TApSA, SpSA, pSA, and traditional SA, are simulated for a total
of 1,000 cycles each. This number of cycles allows the annealing system ample opportunity to explore the solution
space and converge to a solution. Due to the inherent randomness in these probabilistic algorithms, the evaluation
is not based on a single trial. Instead, to get a more accurate understanding of their performance, 100 separate trials
are executed for each algorithm. The outcomes of these trials are then used to calculate the minimum, average,
and maximum cut values of the MAX-CUT problems, providing a comprehensive assessment of the algorithms’
performance.


**Results**


**Simulation analysis of TApSA**


The TApSA algorithm is simulated on the G1 graph with varying window size _α_ (Fig. 4). During the annealing
process, the pseudo inverse temperature _I_ 0 is gradually increased over time for 1,000 cycles from _I_ 0 _min_ = 0 _._ 0149
to _I_ 0 _max_ = 1 _._ 49, following the formula _I_ 0( _t_ + 1) = _I_ 0( _t_ ) _/_ 0 _._ 995. _α_ is incrementally increased from two to four
to observe the corresponding changes in the behavior of TApSA. Note that when _α_ equals to one, TApSA operates
exactly the same as pSA. Increasing _α_ can make signals of p-bits smoother. For _α_ = 2, the mean of all the p-bit
states oscillates between ‘-1’ and ‘+1’. This oscillatory pattern implies that the algorithm alternates between two
distinct states throughout its execution. This behavior, however, does not lead to the energy of the system decreasing
towards the global minimum. Instead, it causes an increase in the energy level. Similarly, when _α_ is increased to
three, the oscillation persists, but its start cycle is delayed in comparison to when _α_ = 2. Despite this delayed onset
of oscillation, the energy of the Ising model still increases, failing to converge to the global minimum. However, a
significant change in behavior is observed when _α_ is increased to four. In this case, no oscillation is observed in the
mean of the p-bit states. This allows the energy of the Ising model to decrease steadily, eventually reaching the global
minimum. Thus, for this specific graph and set of conditions, an _α_ value of four appears to facilitate the effective
optimization, leading the annealing system towards the global minimum energy state.


7


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 5: Normalized cut values using the TApSA algorithm on the G1, G11, G58 and K2000 MAX-CUT problems
by varying the windows size _α_ from one to ten. This window size _α_ plays a key role in determining the quality of
the solution and can control the behavior of the TApSA algorithm. When _α_ is increased to a specific value, the cut
values can be closer to the best-known values because of no oscillation. The peak of the normalized mean cut value is
obtained with different _α_ depending on the graph.


Parameter G1 G11 G58 K2000
_si_ 6.69 1.99 3.22 44.7
_I_ 0 _min_ 0.0149 0.0501 0.0311 0.00224
_I_ 0 _max_ 1.49 5.01 3.11 0.224
_β_ 0.995 0.995 0.995 0.995
Table 4: Summary of hyperparameters to control _I_ 0 for pSA, TApSA, and SpSA on the G1, G11, G58, K2000
benchmarks. The number of cycles is 1,000.


Next, the TApSA algorithm is simulated to evaluate the normalized cut value on the G1, G11, G58, and K2000 MAXCUT problems by varying the windows size _α_ from one to ten (Fig. 5). By varying the window size, the behavior
of the TApSA algorithm and the resulting cut values are influenced. To evaluate the performance, the normalized
cut values are calculated using the minimum, mean and maximum cut value divided by the best-known value for
each benchmark graph. This normalization process allows for fair comparisons across different graph structures and
scales. The parameters to control the pseudo inverse temperature _I_ 0 are summarized in Table 4. These parameters are
determined based on Table 3.


As _α_ is increased to a specific value, the cut values tend to get closer to the best-known values due to the elimination of
oscillation in the algorithm. However, when _α_ surpasses this optimal value, the normalized cut value starts to decrease
slightly as _α_ continues to increase. This suggests that while increasing _α_ can improve performance up to a point, overly


8


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 6: Simulation analysis of SpSA on the G58 graph with different probabilities of getting stalled on p-bits _p_ . The
mean values of all the p-bit states are oscillated between ‘-1’ and ‘+1’ in case of _p_ of 0.1 and 0.3 (top of a and b),
resulting in the increase of energy instead of decrease (bottom of a and b). When _p_ is 0.5, no oscillation occurs and
hence the energy goes down to the global minimum energy (c). SpSA can also solve the oscillation issue of pSA.


large window sizes may have a detrimental effect. Interestingly, the specific value of _α_ that yields the peak normalized
mean cut values varies depending on the graph. This indicates that the optimal window size is not universal but instead
depends on the particular characteristics of the graph being analyzed. The source of these differing optimal _α_ values
can be traced to the weights present in the respective graphs, as listed in Table 1. For instance, G1 and G58 only
contain weights of ‘+1’, while G11 and K2000 contain both ‘-1’ and ‘+1’ weights. This imbalance in weights can lead
to strong oscillations in the algorithm. Large _α_ values can help to mitigate these oscillations, effectively smoothing
the search through the solution space and improving its ability to find the global minimum.


**Simulation analysis of SpSA**


The G58 graph is used to evaluate the SpSA algorithm, considering varying probabilities of p-bits getting stalled,
denoted as _p_ (Fig. 6). The parameter _p_ is systematically incremented from 0.1 to 0.5 in order to thoroughly understand
how changes in _p_ impact the behavior and effectiveness of the SpSA algorithm. When _p_ equals zero, there is no
discernible difference in how SpSA and the pSA algorithm function. When _p_ is 0.1, the average of all p-bit states
starts to oscillate, alternating between ‘-1’ and ‘+1’. This oscillation mirrors the behavior observed in the TApSA
algorithm with small _α_, leading to an increase in the energy level of the system, which usually signifies a less optimal
solution. When _p_ rises to 0.3, though the oscillation continues, its magnitude is diminished compared to the scenario
where _p_ = 0 _._ 1. The most significant change in behavior of the SpSA algorithm is observed when _p_ reaches 0.5. In this
situation, the oscillation of the average p-bit states ceases completely. The absence of oscillation allows the energy
of the Ising model to decrease steadily. As the energy reduces, the energy moves closer to the most optimal solution,
ultimately achieving the global minimum, which represents the best possible solution.


Next, the SpSA algorithm is simulated to evaluate the normalized cut value on the G1, G11, G58, and K2000 MAXCUT problems by varying the probability of p-bits getting stalled _p_ from 0 to 0.9 (Fig. 7). As _p_ is increased to a
specific value, the cut values tend to get closer to the best-known values due to the elimination of oscillation as well
as TApSA. When _p_ surpasses this optimal value, the normalized cut value starts to decrease slightly as _p_ continues to
increase. The specific value of _p_ that yields the peak normalized mean cut values varies depending on the graph.


Based on the simulated results of TApSA and SpSA, increasing _α_ exhibits the similar effect to increasing _p_ in terms
of eliminating the oscillation, which is crucial for effective optimization. In both TApSA and SpSA, there appears to
be an optimal value of _α_ and _p_, respectively, which yields the best performance in terms of the normalized cut value.


9


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 7: Normalized cut values using the SpSA algorithm on the G1, G11, G58 and K2000 MAX-CUT problems by
varying the stalled probability _p_ from 0 to 0.9. When _p_ is increased to a specific value, the cut values can be closer to
the best-known values because of no oscillation as well as SpSA.


However, this optimal value is not universal and depends on the specifics of the graph. Moreover, surpassing these
optimal values can actually lead to a decrease in performance.


**Performance comparisons**


A comparative analysis of the cut values on the G1 graph are conducted for three different simulated annealing algorithms: pSA, TApSA, and SpSA (Fig. 8). To assess the effectiveness of these algorithms in finding cut values,
simulations involving 1,000 cycles are performed for each, and these are repeated 100 times. The repetition of these
simulations leads to the collection of a substantial amount of data, enabling a robust evaluation of the minimum, mean,
and maximum cut values. All cut values using pSA are found to be zero, an intriguing outcome attributable to the
oscillation that is observed during the annealing process. This suggests that the pSA algorithm is unstable under these
conditions, leading to a failure to produce any viable cut values. In the case of the TApSA and SpSA algorithms, they
are simulated with the most advantageous parameters, namely _α_ = 4 and _p_ = 0 _._ 6, respectively. The choice of these
specific values is determined on previous experiments and analysis, which demonstrated superior performance. When
comparing the results, it is shown that both TApSA and SpSA outperform pSA, achieving near-optimal solutions. This
is largely due to the elimination of oscillations observed in the pSA algorithm, made possible by the design of the
TApSA and SpSA algorithms.


Furthermore, a comparison is also conducted between the proposed algorithms (TApSA and SpSA) and the traditional
SA method, specifically using the G-set and K2000 benchmarks. The detailed results of this comparison are summarized in Table 5. The pSA algorithm is found to consistently fail to lower the energy of the Ising model, leading to
particular patterns in the mean cut values. When the weight values of the graphs are solely ‘+1’, the mean cut values


10


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 8: Cut values obtained using simulated annealing on the G1 graph for 100 trials. The conventional pSA causes
all 0 values due to the oscillation (a). In contrast, TApSA with _α_ = 4 and SpSA with _p_ = 0 _._ 6 can reduce the energy
of the Ising model, which results in good cut values that are closer to the best-known values (b and c).


Graph SA Kirkpatrick et al. [1983] pSA Camsari et al. [2019] TApSA (proposed) SpSA (proposed)
~~Mean cut value~~ ~~Mean cut value~~ ~~Mean cut value~~ ~~Window size~~ ~~Mean cut value~~ ~~Probabilit~~
_α_ getting stal
G1 10757.91 0 11574.69 4 11567.89 0.6
G6 1270.88 173.48 2150.49 2 2151.23 0.1
G11 336.72 6.18 542.7 3 543.78 0.5
G14 2801.84 0 3035.74 3 3034.78 0.5
G18 591.5 -49.79 968.31 2 968.94 0.1
G22 11161.58 0 13277.55 3 13271.27 0.5
G34 469.22 -29.62 1331.22 2 1335.72 0.5
G38 6638.96 0 7617.3 3 7610.48 0.5
G39 854.57 -489.49 2343.52 2 2349.57 0.2
G47 5851.46 0 6623.31 3 6618.35 0.6
G48 3563.94 3057.22 5867.16 2 5897 0.1
G54 3479.42 0 3815.16 3 3811.77 0.5
G55 6968.09 0.03 10184.66 2 10193.41 0.2
G56 696.99 -185.22 3900.35 2 3912.14 0.1
G58 15787.85 0 19108.08 3 19096.28 0.5
K2000 11369.62 -4889.64 32812.64 2 32860.58 0.1
Table 5: Comparisons of mean cut values in the MAX-CUT benchmarks. On the 16 benchmarks from 800 to 5,000
nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with
the conventional pSA.


turns out to be 0. Conversely, when the weight values are either ‘-1’ or ‘+1’, the mean cut values are negative. On
the 16 benchmarks, the normalized mean cut value of pSA is only 0.8% on average. The traditional SA algorithm,
on the other hand, delivers better cut values compared to pSA. However, it is worth noting that these values are still
significantly off from the best-known values, where the normalized mean cut value is 44.4% on average. Remarkably,
the proposed algorithms, TApSA and SpSA, demonstrate substantial superiority over both pSA and traditional SA.
TApSA and SpSA achieve the normalized mean cut value of 98.3% and 98.4% on average, respectively, in all 16
benchmarks used in this study. This underlines the effectiveness of these proposed methods and their potential for
practical applications in solving similar optimization problems.


**Discussion**


In this article, we have critically examined the limitations of the simulated annealing using probabilistic bits (pSA)
algorithm, specifically with large-scale combinatorial optimization problems such as the maximum cut (MAX-CUT)
problem. Our detailed analysis has identified disruptive oscillations as the root cause of energy stagnation in the pSA
process. To mitigate this, we have proposed and rigorously tested two novel algorithms, time average pSA (TApSA)


11


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 9: The simulation duration for TApSA and SpSA was assessed by varying the parameters _α_ and _p_, respectively,
across 1,000 cycles (as shown in figures a and b). This evaluation includes the total time spent on the simulations over
the number of cycles, incorporating the time required for tuning the parameters _α_ or _p_ (c).


and stalled pSA (SpSA). The results suggest significant performance improvements over traditional methods (SA and
pSA), highlighting the potential of our proposed algorithms in effectively tackling large-scale optimization tasks.


Stochastic simulated annealing (SSA) is another p-bit-based simulated annealing that outperforms pSA and SA in
several combinatorial optimization problems Onizawa et al. [2022 (to appear]. SSA is implemented using digital hardware because the tanh function is approximated using stochastic computing. In terms of energy consumption, TApSA
and SpSA can reduce energy consumption than SSA because of the nature of their implementation. When the p-bit is
implemented using an emerging device, the energy consumption can be 10 times smaller than that implemented using
a traditional digital circuit Borders et al. [2019]. In addition, the p-bit is a single device, while it can be approximated
using several hundreds of transistors in digital implementation, resulting in a more compact hardware implementation.
In the future, large-scale p-bit-based simulated annealing, TApSA and SpSA could gain in terms of energy and area
consumption in comparison with SSA.


In terms of computation cost, TApSA and SpSA require extra computation for nonlinear functions in comparison with
pSA.


In Fig. 9(a), the simulation time for TApSA is plotted against the parameter _α_, while Fig. 9(b) illustrates the simulation
time for SpSA as a function of _p_, with both scenarios considering 1,000 cycles for solving problems G1, K2000, and
G58. It is observed that TApSA’s simulation time remains relatively constant regardless of variations in _α_, across the
same number of cycles. In contrast, SpSA exhibits longer simulation times at smaller values of _α_, as opposed to shorter
times at larger _p_ values. This consistent behavior is further detailed in Fig. 9(c), which shows the total simulation time,
inclusive of the duration spent tuning _α_ or _p_ . Prior to the annealing process, parameter tuning for TApSA and SpSA
involves adjusting _α_ or _p_ over 100 cycles to identify the optimal parameter settings. When compared to pSA, it is
noteworthy that the additional computational costs associated with TApSA and SpSA are less significant at higher
cycle counts.


From another point of view, it would be preferable to realize new emerging devices that mimic these algorithms for
future implementation.


To determine if pSA induces oscillation in optimization problems other than MAX-CUT, a 100-spin graph isomorphism (GI) problem is employed. This problem involves ascertaining the isomorphism of two 10-node graphs. GI
problems are inherently more complex than MAX-CUT problems, primarily due to the presence of non-zero values of
_h_ in GI, in contrast to the all-zero values of _h_ in MAX-CUT. Previous literature Onizawa et al. [2022 (to appear] noted
that pSA failed to converge in GI problems with more than 25 spins, though it did not explicitly address the oscillation
of p-bit states. To further explore this issue, both pSA and TApSA are applied to the 100-spin GI problem over 1,000
cycles as shown in Fig. 10. The result shows that pSA, similar to its performance in MAX-CUT problems, is unable
to reduce energy due to p-bit state oscillation. On the other hand, TApSA effectively resolves this oscillation issue,
achieving a reduction in energy to the global minimum. These findings suggest that while TApSA shows promise
in addressing oscillation issues in various algorithms, a more detailed analysis in other contexts is planned for future
work


The performance of the newly proposed TApSA algorithm is benchmarked against other notable methods, specifically
the GPU-based asynchronous parallel algorithm Cook et al. [2019] and the coherent Ising machine (CIM) Wang et al.

[2013], with details presented in Table 6. This comparison uses normalized mean cut values, calculated by dividing the
mean cut value by the best-known value for each problem. The GPU-based approach evaluates mean cut values over
1,000 annealing steps. Conversely, the performance data for CIM, sourced from the literature Yavorsky et al. [2019],
is based on simulations using SimCIM Tiunov et al. [2019] for a substantially longer duration of 50,000 annealing


12


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Figure 10: In the context of a 100-spin graph isomorphism (GI) problem, which involves determining if two 10-node
graphs are isomorphic, distinct performance characteristics of pSA and TApSA with _α_ = 10 are observed. In case
(a), pSA struggles to minimize energy due to oscillations in p-bit states, a challenge similarly noted in the MAX-CUT
problem. Conversely, TApSA effectively addresses this oscillation issue, as shown in case (b), leading to a significant
reduction in energy that can reach the global minimum.


Benchmark GPU Cook et al. [2019] SimCIM Yavorsky et al. [2019] TApSA
G22 N/A 99.6% 99.4%
G39 N/A 97.9% 97.3%
G47 99.4% N/A 99.5%
G54 97.7% N/A 99.0%
K2000 N/A 99.6% 98.4%
Table 6: Comparisons of normalized mean cut values obtained in this research with those reported in related works
Cook et al. [2019], Yavorsky et al. [2019]. In this comparison, both the GPU-based approach and TApSA are configured to perform 1,000 annealing steps. In contrast, the SimCIM approach, as referenced in the literature, requires
a significantly higher number of annealing steps, totaling 50,000. This disparity in the number of annealing steps
highlights the efficiency differences among these methods.


steps. In comparison with the GPU-based method, TApSA achieves comparable normalized mean cut values. While
TApSA’s performance is marginally lower than CIM, it shows potential for improvement with an increased number of
annealing steps.


Initially, p-bits are modeled with uniform random signals, where _ri_ ( _t_ ) _∈{−_ 1 : 1 _}_, as outlined in Eq. (1). To explore
the impact of random signals on performance, this study introduces random signals derived from a Poisson distribution
for the p-bits. Specifically, the random signal _ri_ ( _t_ ) = 1 _/λ · X −_ 1 is generated according to the Poisson probability
formula _P_ ( _X_ = _k_ ) = _e_ _[−][λ]_ _λ_ _[k]_ _/k_ !, with _λ_ set to 10. A comparison of normalized mean cut values, using both uniform


13


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


_ri_ ( _t_ ) pSA TApSA SpSA
Uniform 0.828% 98.3% 98.4%
Poisson 3.94% 97.9% 97.9%
Table 7: Normalized mean cut values on average for all 16 benchmarks with different random signals.


random and Poisson distribution-based signals, is presented in Table 7. The results indicate that the type of random
signals has a negligible effect on the performance of all three algorithms under study.


P-bits have found application in various domains, one of which includes Gibbs sampling Aadit et al. [2022b]. A key
distinction between Gibbs sampling and pSA lies in the approach to node updates: Gibbs sampling typically operates
serially, while pSA updates nodes in parallel. It is important to note that although extended versions of Gibbs sampling,
such as chromatic Gibbs sampling, have the capability to operate in parallel Aadit et al. [2022a], the scope of their
applications is relatively limited. Simulation results have shown that pSA faces an oscillation issue due to its parallel
update mechanism, a problem which the proposed algorithms aim to address. However, applying techniques based on
TApSA and SpSA to Gibbs sampling, which inherently operates serially, presents a significant challenge. Exploring a
Gibbs sampling method that incorporates the proposed techniques is an intriguing direction for future research.


In conclusion, our research has broadened the understanding of the pSA process and has led to the development of
more effective algorithms for complex optimization tasks. The proposed TApSA and SpSA algorithms offer promising
avenues for overcoming the limitations of the traditional pSA approach and could be crucial for future progress in
combinatorial optimization.


**Data availability**


All data generated or analyzed during this study are included in this published article. The Python codes are available
at https://github.com/nonizawa/pSA.


**References**


Kerem Camsari, Rafatul Faria, Brian Sutton, and Supriyo Datta. Stochastic p-bits for invertible logic. _Physical Review_
_X_, 7, July 2017. doi: 10.1103/PhysRevX.7.031014.


Ahmed Zeeshan Pervaiz, Lakshmi Anirudh Ghantasala, Kerem Yunus Camsari, and Supriyo Datta. Hardware
emulation of stochastic p-bits for invertible logic. _Scientific Reports_, 7(1):10994, 2017. doi: 10.1038/
s41598-017-11011-8. URL `https://doi.org/10.1038/s41598-017-11011-8` .


William A. Borders, Ahmed Z. Pervaiz, Shunsuke Fukami, Kerem Y. Camsari, Hideo Ohno, and Supriyo Datta.
Integer factorization using stochastic magnetic tunnel junctions. _Nature_, 573(7774):390–393, 2019. doi: 10.1038/
s41586-019-1557-9. URL `https://doi.org/10.1038/s41586-019-1557-9` .


A. Z. Pervaiz, B. M. Sutton, L. A. Ghantasala, and K. Y. Camsari. Weighted _p_ -bits for FPGA implementation of
probabilistic circuits. _IEEE Transactions on Neural Networks and Learning Systems_, 30(6):1920–1926, June 2019.
ISSN 2162-2388. doi: 10.1109/TNNLS.2018.2874565.


S. C. Smithson, N. Onizawa, B. H. Meyer, W. J. Gross, and T. Hanyu. Efficient CMOS invertible logic using stochastic
computing. _IEEE Transactions on Circuits and Systems I: Regular Papers_, 66(6):2263–2274, June 2019. ISSN
1549-8328. doi: 10.1109/TCSI.2018.2889732.


Brian Sutton, Rafatul Faria, Lakshmi Anirudh Ghantasala, Risi Jaiswal, Kerem Yunus Camsari, and Supriyo Datta.
Autonomous probabilistic coprocessing with petaflips per second. _IEEE Access_, 8:157238–157252, 2020. doi:
10.1109/ACCESS.2020.3018682.


Navid Anjum Aadit, Andrea Grimaldi, Giovanni Finocchio, and Kerem Y. Camsari. Physics-inspired ising computing
with ring oscillator activated p-bits. In _2022 IEEE 22nd International Conference on Nanotechnology (NANO)_,
pages 393–396, 2022a. doi: 10.1109/NANO54668.2022.9928681.


G. E. Hinton, T. J. Sejnowski, and D. H. Ackley. Boltzmann machines: Constraint satisfaction networks that learn.
Technical Report CMU-CS-84-119, Department of Computer Science, Carnegie-Mellon University, 1984.


N. Onizawa, S. C. Smithson, B. H. Meyer, W. J. Gross, and T. Hanyu. In-hardware training chip based on cmos
invertible logic for machine learning. _IEEE Transactions on Circuits and Systems I: Regular Papers_, 67(5):1541–
1550, May 2020. ISSN 1558-0806. doi: 10.1109/TCSI.2019.2960383.


14


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Jan Kaiser, William A. Borders, Kerem Y. Camsari, Shunsuke Fukami, Hideo Ohno, and Supriyo Datta. Hardwareaware in situ learning based on stochastic magnetic tunnel junctions. _Phys. Rev. Appl._, 17:014016, Jan 2022.
doi: 10.1103/PhysRevApplied.17.014016. URL `https://link.aps.org/doi/10.1103/PhysRevApplied.`
`17.014016` .


Andrea Grimaldi, Luis Sánchez-Tejerina, Navid Anjum Aadit, Stefano Chiappini, Mario Carpentieri, Kerem Camsari,
and Giovanni Finocchio. Spintronics-compatible approach to solving maximum-satisfiability problems with probabilistic computing, invertible logic, and parallel tempering. _Phys. Rev. Appl._, 17:024052, Feb 2022. doi: 10.1103/
PhysRevApplied.17.024052. URL `https://link.aps.org/doi/10.1103/PhysRevApplied.17.024052` .


Navid Anjum Aadit, Andrea Grimaldi, Mario Carpentieri, Luke Theogarajan, John M. Martinis, Giovanni Finocchio, and Kerem Y. Camsari. Massively parallel probabilistic computing with sparse ising machines. _Nature_
_Electronics_, 5(7):460–468, 2022b. doi: 10.1038/s41928-022-00774-2. URL `https://doi.org/10.1038/`
`s41928-022-00774-2` .


Kerem Yunus Camsari, Brian M. Sutton, and Supriyo Datta. p-bits for probabilistic spin logic. _Applied Physics_
_Reviews_, 6:011305, 2019.


Scott Kirkpatrick, Charles D Gelatt Jr, and Mario P Vecchi. Optimization by simulated annealing. _Science_, 220(4598):
671–680, 1983.


David S Johnson, Cecilia R Aragon, Lyle A McGeoch, and Carla Schevon. Optimization by simulated annealing:
An experimental evaluation; part ii, graph coloring and number partitioning. _Operations Research_, 39(3):378–406,
1981.


Tor Mykleburst. Solving maximum cut problems by simulated annealing. _CoRR_, arXiv:1505.03068, 2015. URL
`https://arxiv.org/abs/1505.03068` .


Eslam Elmitwalli, Zeljko Ignjatovic, and Selçuk Köse. Utilizing multi-body interactions in a CMOS-based ising
machine for LDPC decoding. _IEEE Transactions on Circuits and Systems I: Regular Papers_, pages 1–11, 2023.
doi: 10.1109/TCSI.2023.3322325.


Hyeon-Kyu Park, Jae-Hyeok Lee, Jehyun Lee, and Sang-Koog Kim. Optimizing machine learning models for
granular ndfeb magnets by very fast simulated annealing. _Scientific Reports_, 11(1):3792, 2021. doi: 10.1038/
s41598-021-83315-9. URL `https://doi.org/10.1038/s41598-021-83315-9` .


Edna E. Reiter and Clayton Matthew Johnson. _Limits of Computation: An Introduction to the Undecidable and the_
_Intractable_ . Chapman and Hall/CRC, 2012. ISBN 1439882061.


David J. Earl and Michael W. Deem. Parallel tempering: Theory, applications, and new perspectives. _Phys. Chem._
_Chem. Phys._, 7:3910–3916, 2005. doi: 10.1039/B509983H. URL `http://dx.doi.org/10.1039/B509983H` .


Naoya Onizawa, Kota Katsuki, Duckgyu Shin, Warren J. Gross, and Takahiro Hanyu. Fast-converging simulated
annealing for Ising models based on integral stochastic computing. _IEEE Transactions on Neural Networks and_
_Learning Systems_, pages 1–7, 2022 (to appear). doi: 10.1109/TNNLS.2022.3159713.


Maliheh Aramon, Gili Rosenberg, Elisabetta Valiante, Toshiyuki Miyazawa, Hirotaka Tamura, and Helmut G. Katzgraber. Physics-inspired optimization for quadratic unconstrained problems using a digital annealer. _Frontiers in_
_Physics_, 7, 2019. ISSN 2296-424X. doi: 10.3389/fphy.2019.00048. URL `https://www.frontiersin.org/`
`articles/10.3389/fphy.2019.00048` .


Hidenori Gyoten, Masayuki Hiromoto, and Takashi Sato. Enhancing the solution quality of hardware ising-model
solver via parallel tempering. In _Proceedings of the International Conference on Computer-Aided Design_, ICCAD
’18, New York, NY, USA, 2018. Association for Computing Machinery. ISBN 9781450359504. doi: 10.1145/
3240765.3240806. URL `https://doi.org/10.1145/3240765.3240806` .


Duckgyu Shin, Naoya Onizawa, Warren J. Gross, and Takahiro Hanyu. Memory-efficient fpga implementation of
stochastic simulated annealing. _IEEE Journal on Emerging and Selected Topics in Circuits and Systems_, 13(1):
108–118, 2023. doi: 10.1109/JETCAS.2023.3243260.


Tadashi Kadowaki and Hidetoshi Nishimori. Quantum annealing in the transverse ising model. _Physical Review E_, 58
(5):5355–5363, 1998.


Sergio Boixo, Troels F. Rønnow, Sergei V. Isakov, Zhihui Wang, David Wecker, Daniel A. Lidar, John M. Martinis,
and Matthias Troyer. Evidence for quantum annealing with more than one hundred qubits. _Nature Physics_, 10(3):
218–224, 2014. doi: 10.1038/nphys2900. URL `https://doi.org/10.1038/nphys2900` .


Hartmut Neven. When can quantum annealing win?, Jan. 2016. URL `https://ai.googleblog.com/2015/12/`
`when-can-quantum-annealing-win.html` .


15


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


Kenneth M. Zick, Omar Shehab, and Matthew French. Experimental quantum annealing: case study involving the
graph isomorphism problem. _Scientific Reports_, 5(1):11168, 2015. doi: 10.1038/srep11168. URL `https://doi.`
`org/10.1038/srep11168` .


Sheir Yarkoni, Elena Raponi, Thomas Bäck, and Sebastian Schmitt. Quantum annealing for industry applications:
introduction and review. _Reports on Progress in Physics_, 85(10):104001, sep 2022. doi: 10.1088/1361-6633/
ac8c54. URL `https://doi.org/10.1088%2F1361-6633%2Fac8c54` .


Zhe Wang, Alireza Marandi, Kai Wen, Robert L. Byer, and Yoshihisa Yamamoto. Coherent ising machine based on
degenerate optical parametric oscillators. _Phys. Rev. A_, 88:063853, Dec 2013. doi: 10.1103/PhysRevA.88.063853.
URL `https://link.aps.org/doi/10.1103/PhysRevA.88.063853` .


Hayato Goto, Kosuke Tatsumura, and Alexander R. Dixon. Combinatorial optimization by simulating adiabatic bifurcations in nonlinear Hamiltonian systems. _Science Advances_, 5(4):eaav2372, 2019. doi: 10.1126/sciadv.aav2372.
URL `https://www.science.org/doi/abs/10.1126/sciadv.aav2372` .


S. Dutta, A. Khanna, A. S. Assoa, H. Paik, D. G. Schlom, Z. Toroczkai, A. Raychowdhury, and S. Datta. An Ising
Hamiltonian solver based on coupled stochastic phase-transition nano-oscillators. _Nature Electronics_, 4(7):502–
512, 2021. doi: 10.1038/s41928-021-00616-7. URL `https://doi.org/10.1038/s41928-021-00616-7` .


Samuel Burer, Renato D. C. Monteiro, and Yin Zhang. Rank-two relaxation heuristics for MAX-CUT and other binary
quadratic programs. _SIAM Journal on Optimization_, 12(2):503–521, 2001.


Y. Ye. Computational optimization laboratory, 1999. URL `http://web.stanford.edu/~yyye/Col.htm` .


B. R. Gaines. Stochastic computing systems. _Adv. Inf. Syst. Sci. Plenum_, 2(2):37–172, 1969. ISSN 0018-9340. doi:
10.1109/12.954505.


B. D. Brown and H. C. Card. Stochastic neural computation. I. computational elements. _IEEE Transactions on_
_Computers_, 50(9):891–905, Sep. 2001. ISSN 0018-9340. doi: 10.1109/12.954505.


Vincent C. Gaudet and Warren J. Gross. _Stochastic Computing: Techniques and Applications_ . Springer International
Publishing, 2019.


V. C. Gaudet and A. C. Rapley. Iterative decoding using stochastic computation. _Electronics Letters_, 39(3):299 – 301,
Feb. 2003. ISSN 0013-5194. doi: 10.1049/el:20030217.


P. Li, D. J. Lilja, W. Qian, K. Bazargan, and M. D. Riedel. Computation on stochastic bit streams digital image
processing case studies. _IEEE Transactions on Very Large Scale Integration (VLSI) Systems_, 22(3):449–462, Mar.
2014. ISSN 1063-8210. doi: 10.1109/.2013.2247429.


Y. Liu and K. K. Parhi. Architectures for recursive digital filters using stochastic computing. _IEEE Transactions on_
_Signal Processing_, 64(14):3705–3718, July 2016. ISSN 1053-587X. doi: 10.1109/TSP.2016.2552513.


A. Ardakani, F. Leduc-Primeau, N. Onizawa, T. Hanyu, and W. J. Gross. VLSI implementation of deep neural network
using integral stochastic computing. _IEEE Transactions on Very Large Scale Integration (VLSI) Systems_, 25(10):
2588–2599, Oct. 2017. ISSN 1063-8210. doi: 10.1109/TVLSI.2017.2654298.


Naoya Onizawa, Makoto Kato, Hitoshi Yamagata, Koji Yano, Seiichi Shin, Hiroyuki Fujita, and Takahiro Hanyu.
Sparse random signals for fast convergence on invertible logic. _IEEE Access_, 9:62890–62898, 2021. doi: 10.1109/
ACCESS.2021.3072048.


Takahiro Inagaki, Yoshitaka Haribara, Kensuke Igarashi, Tomohiro Sonobe, Shuhei Tamate, Toshimori Honjo, Alireza
Marandi, Peter L McMahon, Takeshi Umeki, Kohei Enbutsu, and et al. A coherent ising machine for 2000-node
optimization problems. _Science_, 354(6312):603–606, 2016.


Naoya Onizawa, Kyo Kuroki, Duckgyu Shin, and Takahiro Hanyu. Local energy distribution based hyperparameter
determination for stochastic simulated annealing, 2023.


Chase Cook, Hengyang Zhao, Takashi Sato, Masayuki Hiromoto, and Sheldon X.-D. Tan. GPU-based ising computing
for solving max-cut combinatorial optimization problems. _Integration_, 69:335–344, 2019. ISSN 0167-9260. doi:
https://doi.org/10.1016/j.vlsi.2019.07.003. URL `https://www.sciencedirect.com/science/article/pii/`
`S0167926019301348` .


A. Yavorsky, L. A. Markovich, E. A. Polyakov, and A. N. Rubtsov. Highly parallel algorithm for the ising ground state
searching problem, 2019.


Egor S. Tiunov, Alexander E. Ulanov, and A. I. Lvovsky. Annealing by simulating the coherent ising machine.
_Optics Express_, 27(7):10288, mar 2019. doi: 10.1364/oe.27.010288. URL `https://doi.org/10.1364%2Foe.`
`27.010288` .


16


Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial
Optimization Problems A PREPRINT


**Acknowledgments**


This work was supported in part by JST CREST Grant Number JPMJCR19K3, and JSPS KAKENHI Grant Number
JP21H03404.


**Author contributions statement**


N. O. conducted and analyzed the experiments. T. H. discussed the experiment. All authors reviewed the manuscript.


**Additional information**


Competing financial interests: The authors declare no competing financial interests.


17


