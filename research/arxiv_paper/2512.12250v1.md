# Stochastic Volatility Modelling with LSTM Networks: A Hybrid Approach for S&P 500 Index Volatility Forecasting

#### Anna Perekhodko [1] and Robert Ślepaczuk [2]

1
University of Warsaw, Faculty of Economic Sciences„ Ul. Długa 44/50, 00-241 Warsaw,
Poland, email: anna.perekhodkoa@gmail.com
2University of Warsaw, Faculty of Economic Sciences„ Department of Quantitative Finance and
Machine Learning„ Quantitative Finance Research Group, Ul. Długa 44/50, 00-241 Warsaw,
Poland„ ORCID: `[https://orcid.org/0000-0001-5227-2014](https://orcid.org/0000-0001-5227-2014)`, Corresponding author:
rslepaczuk@wne.uw.edu.pl


**Abstract**


Accurate volatility forecasting is essential in various domains, including banking,
investment, and risk management, as expectations about future market movements
directly influence current decision-making. This study proposes a hybrid modeling
framework that integrates a Stochastic Volatility model with a Long Short-Term
Memory neural network. The SV model contributes statistical precision and the
ability to capture latent volatility dynamics, particularly in response to unforeseen
events, while the LSTM network enhances the model’s ability to detect complex,
nonlinear patterns in financial time series. The forecasting is conducted using daily
data from the S&P 500 index, covering the period from January 1, 1998, to December
31, 2024. A rolling window approach is employed to train the model and generate
one-step-ahead volatility forecasts. The performance of the hybrid SV-LSTM model
is evaluated through both statistical testing and investment simulations. Results
show that the hybrid approach outperforms both the standalone SV and LSTM
models. These findings contribute to the ongoing development of volatility modeling techniques and provide a robust foundation for enhancing risk assessment and
strategic investment planning in the context of the S&P 500.


_**Keywords:**_ Stochastic Volatility, LSTM, Hybrid Models, Financial Forecasting,
S&P 500, Quantile Prediction


_**JEL Codes:**_ C4, C14, C45, C52, C53, C58, G13, G17

### **1 Introduction**


The demand for accurate volatility forecasts reflects their central role in risk management,
asset pricing, and portfolio optimization. Financial market participants rely on these


All code and supplementary materials used in this paper are openly accessible via GitHub:
`[https://github.com/aperekhodko/sv_lstm_hybrid_model](https://github.com/aperekhodko/sv_lstm_hybrid_model)` .


1


forecasts to guide investment strategies and assess risk exposure. While models such as
GARCH and SV capture the stochastic nature of volatility, incorporating LSTM networks
can enhance predictions by identifying non-linear patterns. This study addresses a gap in
financial forecasting research by proposing a hybrid SV-LSTM model that leverages both
the statistical strengths of SV and the pattern-recognition capacity of LSTM.
The objective is to assess whether incorporating latent volatility estimates from an SV
model as an additional input enhances the predictive performance of the LSTM model
compared to their standalone applications.
The main focus of the forecast was chosen to be the volatility of the S&P 500 index,
a well-established measure of market fluctuations.
The research conducted in this paper is guided by the following central hypotheses:


  - H1: The inclusion of stochastic volatility forecasts for day t+1 enhances the predictive accuracy of the LSTM model.


  - H2: Augmenting the input data of the LSTM model with external information
beyond historical returns improves its forecasting performance.


  - H3: The hybrid SV-LSTM model delivers enhanced volatility forecasts compared to
the standalone SV model.


In addition to the main hypotheses, the following secondary research questions are investigated:


  - RQ1: Increasing the dimensionality of inputs from the SV model further improves
the predictive performance of the hybrid model.


  - RQ2: The preprocessing and transformation of input data have a significant effect
on the performance of the SV-LSTM model.


  - RQ3: The decreased sequence of the input data into the LSTM model improves the
SV-LSTM prediction accuracy.


The data used is daily close price for the S&P 500 index, covering the period from
January 1, 1998, to December 31, 2024, obtained from the YahooFinance.
The methodology employed in this thesis involves a combination of stochastic volatility modeling, LSTM networks and statistical testing. The SV model is used to generate
volatility forecasts, which are then incorporated as inputs to the LSTM model. Additionally, benchmarks, including standalone LSTM and SV models, are introduced to compare the performance of the hybrid SV-LSTM model. The Wilcoxon Signed-Rank and
Diebold-Mariano Tests are used to statistically evaluate the significance of the differences
in predictive performance between the models.
This study contributes to financial modeling by examining the combination of a statistical SV model as input to a machine learning LSTM model. It is the first to investigate
the impact of incorporating SV predictions of latent volatility into the LSTM architecture.
This hybrid approach captures both latent stochastic processes and nonlinear dependencies in financial time series, improving the model’s ability to reflect unpredictable market
dynamics. The step-by-step framework, supported by sensitivity analysis and statistical
testing, bridges the gap between deep learning techniques and traditional econometric approaches. Practically, the study demonstrates relevance through a simulated investment


2


strategy, highlighting potential improvements in portfolio risk management, dynamic asset allocation, and algorithmic trading, and offering tools for more adaptive and resilient
investment strategies in volatile markets.
The structure of the thesis is as follows: The second chapter provides a review of
literature on both classical volatility models and hybrid financial forecasting. The third
chapter presents the dataset used, preprocessing techniques and error metrics. The fourth
chapter outlines the methodology for three models involved in the model development:
SV model, LSTM and hybrid SV-LSTM. The fifth chapter compares the models’ performance using statistical tests, while the sixth chapter explores the robustness of the results
through sensitivity analysis. Finally, the seventh chapter summarizes the key findings,
discusses their implications, and reflects on the achievement of the research objectives.

### **2 Literature Review**


The early development of financial econometric models was founded on the assumption
of constant volatility, which was most notably formalized in the seminal work of Black
and Scholes (1973). Their option pricing model introduced a cornerstone framework
that assumed volatility to be constant over time, providing analytical tractability and
laying the foundation for modern financial derivatives pricing. However, when confronted
with empirical evidence from financial markets and clustering behavior, this simplifying
assumption soon revealed substantial limitation.
The assumption of constant volatility was first formally challenged by Engle (1982),
who introduced the Autoregressive Conditional Heteroskedasticity (ARCH) model. This
framework allowed volatility to evolve as a function of past squared returns, capturing the
fact of volatility clustering observed in asset returns. Based on this idea, Bollerslev (1986)
extended the model into the Generalized Autoregressive Conditional Heteroskedasticity
(GARCH) specification, which incorporated both lagged squared returns and past conditional variances, thereby improving the model’s flexibility and empirical performance.
Despite the empirical success of ARCH-type models, Engle (2001) later critically examined their explanatory power, acknowledging that although these models effectively
capture volatility clustering, they are insufficient in explaining the underlying sources of
volatility dynamics. Nelson (1991) further argued that ARCH models impose parameter
restrictions that are often violated by estimated coefficients, potentially unduly restricting
the dynamics of the conditional variance process. These critiques motivated the development of alternative approaches where volatility is modeled as an unobserved, latent
process.
One such approach is the Stochastic Volatility (SV) model introduced by Taylor (1982)
and Taylor (1986), which treats volatility as a latent stochastic process rather than a
deterministic function of past returns, as in GARCH. This model offers greater flexibility
in capturing nonlinear behavior, though estimation remains challenging. Building upon
the stochastic volatility framework, Heston (1993) introduced a continuous-time model
that incorporated stochastic variance into the option pricing formula. The Heston model
extended the tractability of Black-Scholes by deriving a closed-form solution for option
prices while allowing for mean-reverting stochastic volatility and, particularly, allowing
correlation between volatility and asset returns—an essential feature for capturing the socalled leverage effect. Further advancements were made by Kim, Shephard, et al. (1998),
addressing computational challenges in SV models employing Markov Chain Monte Carlo
(MCMC) methods. These methods enabled efficient Bayesian estimation without direct


3


likelihood evaluation by introducing strong tools for filtering, diagnostic checking, and
formal model comparison. The superiority of SV models over GARCH-type models was
further demonstrated by Yu (2002) in an empirical study on the volatility of New Zealand
stock market data.
The SV model was criticized for failing to reflect long-term dependencies in volatility
dynamics despite its benefits. To address this limitation, Breidt et al. (1998) introduced
the Long Memory Stochastic Volatility model, incorporating an Autoregressive Fractionally Integrated Moving Average (ARFIMA) process into the standard stochastic volatility
framework. Kilic (2011) further contributed to this discussion by proposing the Smooth
Transition FIGARCH model, which accounts for both long memory and nonlinear dynamics in conditional variance.
Recurrent neural networks (RNNs) have become very effective tools for volatility forecasting in recent years. One particularly effective model is the Long Short-Term Memory
(LSTM) network, introduced by Hochreiter and Schmidhuber (1997). LSTM networks
consist of multiple layers and adjust their weights based on observed loss between predicted
and actual values. The application of LSTMs in financial volatility forecasting gained traction with Bahadori and Lipton (2019), who demonstrated that LSTMs provided accurate
forecasts for the S&P 500 index, supported by backtesting evidence. This line of research
was extended by Bucci (2020), who validated the usability of neural networks for forecasting the logarithm of realized volatility while incorporating macroeconomic determinants.
LSTM and Nonlinear Autoregressive with Exogenous Inputs (NARX) neural networks
emerged as the best-performing models in this study.
Further empirical validation was provided by Michańków et al. (2022) in forecasting
BTC and S&P 500 index volatility. Grudniewicz and Slepaczuk (2023) expanded this
research by comparing multiple machine learning approaches in algorithmic investment
strategies. Their study evaluated models including Neural Networks, K-Nearest Neighbors, Regression Trees, Random Forests, Naïve Bayes Classifiers, Bayesian Generalized
Linear Models, Support Vector Machines, and Linear Support Vector Machines, with
Bayesian Generalized Linear Models and Linear SVMs exhibiting the best predictive performance.
The incorporation of LSTM models into hybrid volatility modeling techniques has
been powered by their success. Kim and Won (2018) proposed an LSTM-GARCH hybrid
model applied to the volatility of the KOSPI 200 stock index, with the EGARCH-LSTM
variant yielding the best performance. Roszyk and Ślepaczuk (2024) further explored this
hybrid approach by incorporating the VIX index as an additional input in the GARCHLSTM model. Meanwhile, Nguyen et al. (2019) extended LSTM applications to the SV
framework, addressing the short-term memory limitations of SV models and demonstrating strong performance in forecasting weekly index data for S&P 500 and ASX 200 using
the Blocking Pseudo Method and Importance Sampling Squared algorithm.
Pursuing this trajectory, the current thesis suggests a distinctive enhancement to the
SV framework by combining it with LSTM. Specifically, the aim is to simulate the joint
posterior distribution of the SV parameters using MCMC methods. This approach will
generate MCMC draws to produce one-step-ahead predictions ( _t_ + 1) of returns and
volatilities. These outputs will then be integrated into an LSTM architecture, leveraging
its capacity to model long-term dependencies and nonlinear dynamics. By combining SV’s
stochastic flexibility with LSTM’s predictive power, this hybrid model seeks to address the
limitations of standalone SV models, such as their short-term memory bias and improve
forecasting accuracy for financial time series. By providing a comprehensive framework for


4


volatility modeling and prediction, this contribution attempts to narrow the gap between
the empirical adaptability of machine learning and the theoretical robustness of stochastic
volatility.

### **3 Data and Methodology**

#### **3.1 Data Inputs**


For the modeling of S&P 500 index volatility, the dataset consisted of daily closing prices
obtained from Yahoo Finance, spanning January 1, 1998, to December 31, 2024. This
period spanned across multiple economic cycles, including the dot-com bubble, the 2008
financial crisis, and the post-COVID market recovery, providing a rich basis for volatility
analysis. From these closing prices, daily log returns were calculated to normalize price
movements and facilitate comparisons across time. The log return at time _t_ was computed
as:




  - _Pt_
_rt_ = ln

_Pt−_ 1




_,_ (1)



where _Pt_ denoted the closing price of the S&P 500 index on day _t_ and _Pt−_ 1 on day
_t−_ 1. This transformation was preferred in financial analyses because it converted absolute
price changes into relative terms, mitigating the impact of scale and enabling stationarity
in the return series, a critical assumption for volatility modeling.
Table 1 summarized the descriptive statistics of the close prices and log returns over
the 27-year period, offering insights into their distributional properties. The close prices
exhibited a mean of 2044.98, significantly higher than the median of 1432.73, which suggested a right-skewed distribution. This discrepancy indicated that extremely high values
pulled the mean upward. The standard deviation of 1220.20 reinforced this observation,
reflecting substantial variability in daily prices and pointing to the volatile nature of the
S&P 500 over the sample period. The minimum price of 676.53, observed during the
2008–2009 financial crisis, and the maximum of 6090.27, likely from late 2024, further
highlighted the dataset’s wide range. A skewness of 1.3333 confirmed the positive skew,
while a kurtosis of 0.8033 indicated a distribution flatter than a normal curve, suggesting
fewer extreme deviations than expected under normality.
In contrast, the log returns displayed a mean of 0.000265 and a median of 0.000633,
with the closeness of these central measures suggesting a more symmetric distribution
than the close prices. However, the standard deviation of 0.012225 underscored significant
day-to-day fluctuations, consistent with the high volatility typical of equity indices. The
minimum log return of -0.127652 and the maximum of 0.109572, illustrated the potential
for extreme movements. A negative skewness of -0.3822 indicated a slight leftward tilt,
implying more frequent small negative returns than large positive ones—a common feature
in financial time series. The kurtosis of 9.8617 was notably high, signaling a leptokurtic
distribution with fat tails. This excess kurtosis suggested a higher-than-normal probability
of extreme events, such as market crashes or rapid rallies, which was critical for volatility
modeling as it underscored the need for models capable of capturing these tail risks.


5


Table 1: Descriptive Statistics for S&P 500 Close Prices and Log Returns (January 1,
1998 – January 1, 2025)


**Statistic** **Close Prices** **Log Returns**


Mean 2044.98 0.000265


Median 1432.73 0.000633


Std Dev 1220.20 0.012225


Min 676.53 -0.127652


Max 6090.27 0.109572


Skewness 1.3333 -0.3822


Kurtosis 0.8033 9.8617


Note: The following table presents the descriptive statistics of the S&P 500 Index’s closing prices and their corresponding
log returns. A key observation is the relatively smaller distance between the mean and median in the distribution of log
returns compared to that of the closing prices. This suggests that the distribution of log returns is more symmetric and
potentially closer to a normal distribution. In contrast, the closing prices exhibit greater skewness

#### **3.2 Estimation of Volatility**


In this study, the forecasting target was established as the rolling historical volatility,
which was computed over a window of _N_ = 21 days, approximating one trading month.
This choice of window length was selected to strike a balance between capturing shortterm market dynamics and providing a stable estimate of volatility, a common practice
in financial time series analysis. The rolling volatility was estimated using the unbiased
standard deviation formula:



_t_

 
( _ri −_ _r_ ¯ _t_ ) [2] _,_ (2)

_i_ = _t−N_ +1



_σt_ =




~~�~~

~~�~~ - 1

_N −_ 1



where _σt_ is the rolling volatility at time _t_, _N_ is the window size over which volatility is
calculated. The denominator _N −_ 1 in the volatility formula provides an unbiased estimate
of the standard deviation. Meanwhile, _ri_ represents the logarithmic return at time _i_ and
_r_ ¯ _t_ is the rolling mean of the logarithmic returns within the window, given by:



_r_ ¯ _t_ = [1]

_N_



_t_

 
_ri._ (3)

_i_ = _t−N_ +1



Here, ¯ _rt_ serves as the average return over the window, ensuring that deviations ( _ri_ _−r_ ¯ _t_ )
measure fluctuations around the mean.
This approach ensured that the volatility measure reflected recent market conditions
while accounting for the sample variance’s degrees of freedom, enhancing its statistical
robustness. The 21-day window was particularly suitable for the S&P 500, as it aligned
with monthly trading cycles and captured key volatility clustering patterns observed in
the log returns, such as those during the 2008 financial crisis and the 2020 COVID-19
market turmoil, which can be observed in more detail in Figure 1. This rolling historical
volatility served as the benchmark for evaluating the predictive accuracy of the Stochastic
Volatility (SV), LSTM, and Hybrid SV-LSTM models, as detailed in subsequent sections.


6


Figure 1: S&P 500 21-Day Rolling Volatility Over Time (1998–2025)


Note: The figure provides the time-series of rolling volatility over time for the time frame from January 1998 to December
2024.

#### **3.3 Data Preprocessing**


For the LSTM model, data preprocessing involved scaling the log returns to ensure numerical stability and compatibility with the neural network’s optimization process. The
Min-Max normalization formula was applied as follows:


_Xt −_ min( _X_ )
_Xt_ [scaled] = max( _X_ ) _−_ min( _X_ ) _[·]_ [ (1] _[ −]_ [10] _[−]_ [11][) + 10] _[−]_ [11] _[,]_ (4)

Where _X_ denotes the set of log return values within each rolling window segment.
The small constant 10 _[−]_ [11] was incorporated to prevent division-by-zero issues and ensure
that the scaled values ranged between 10 _[−]_ [11] and 1. The max( _X_ ) and min( _X_ ) reflected
the maximum and minimum values from each respective dataset.
To safeguard against data leakage scaling was performed in two distinct steps. First,
the training and validation sets were scaled together to establish a consistent range for
model tuning. Then, the training set alone was scaled separately, ensuring that the
maximum and minimum values used for scaling did not incorporate information from the
test set. After predictions were generated, the scalers applied to the test data were stored
and utilized to inverse-transform the predicted values back to their original scale, enabling
a direct and meaningful comparison with the actual rolling volatility.
In contrast, the SV model required no scaling, as it operated directly on the raw log
returns, leveraging its statistical framework to model volatility through latent processes.
This preprocessing strategy ensured that each model received appropriately prepared
inputs tailored to its methodological requirements, maintaining consistency across the
analysis.

#### **3.4 Evaluation Metrics**


The choice of error metrics was crucial, serving both as objective functions for model
training and as benchmarks for evaluating performance across the SV, LSTM, and Hybrid SV-LSTM models. Three widely used metrics: Mean Squared Error (MSE), Mean


7


Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) were selected for
their complementary strengths in capturing different dimensions of forecast accuracy, well
suited to volatility prediction.


**Mean Squared Error (MSE)**


The Mean Squared Error (MSE) quantified the average squared difference between the
actual rolling volatility values and the predicted values. It was calculated as:



MSE = [1]

_n_



_n_


( _yi −_ _y_ ˆ _i_ ) [2] _,_ (5)

_i_ =1



where _yi_ represented the actual volatility, ˆ _yi_ denoted the predicted volatility, and _n_
was the number of observations in each rolling window.


**Mean Absolute Error (MAE)**


The Mean Absolute Error (MAE) measured the average magnitude of errors between
actual and predicted volatility, irrespective of their direction. It was defined as:



MAE = [1]

_n_



_n_

- _|yi −_ _y_ ˆ _i|,_ (6)


_i_ =1



**Mean Absolute Percentage Error (MAPE)**


The Mean Absolute Percentage Error (MAPE) assessed the error relative to the actual
volatility, expressing it as a percentage. It was computed as:



_×_ 100 _,_ (7)
����



MAPE = [1]

_n_



_n_



_i_ =1



_yi −_ _y_ ˆ _i_
���� _yi_



The combination of MSE, MAE, and MAPE was deliberate, reflecting their ability to
address distinct facets of volatility prediction.

#### **3.5 Modeling Framework**


This study aimed to forecast the one-day-ahead ( _t_ + 1) volatility of the S&P 500 index.
To achieve this goal, three models were explored: the Stochastic Volatility (SV) model,
the Long Short-Term Memory (LSTM) neural network and a Hybrid SV-LSTM model
that combined elements of both approaches.
Each model utilized the dataset described in Section 3.1 and implemented a rolling
window methodology to capture the time-varying nature of financial volatility over the
period from January 1, 1998, to January 1, 2025. Table 2 provides a summary of the
inputs, time frames, and outputs for each model.


8


Table 2: Summary of Models, Inputs, and Outputs


**Model** **Inputs** **Period** **Output**
SV Log returns 1998–2025 Latent volatility at _t_ + 1
LSTM Log returns, 21-day 2000–2025 Rolling volatility at _t_ + 1
historical volatility



Hybrid SV-LSTM SV volatility at _t_ + 1, log
returns, 21-day historical
volatility



2000–2025 Rolling volatility at _t_ + 1



Note: The table provides a summary of each model used in the study, detailing their respective input variables, the period
over which the input data is drawn, and the specific output of the model.


The SV model represents a statistical approach in which volatility is modeled as a
latent stochastic process driven by the log returns of the S&P 500 index. This model
was selected for its flexibility in capturing time-varying volatility and heavy-tailed distributions typical in financial data. The complete historical dataset from 1998 to 2025
was used, with a rolling window of 504 trading days (approximately 2 years). For each
step, the window was moved forward by one trading day to produce a new one-step-ahead
forecast, thus adapting to changes in the data over time.
In contrast, the LSTM model adopted a deep learning approach, known for its capacity
to learn long-range and nonlinear patterns in sequential data. The model used data from
2000 to 2025 and was fed with the log returns and the 21-day rolling historical volatility
as inputs. Its objective was to forecast the same rolling volatility for day ( _t_ + 1).
To accommodate the training requirements of neural networks, a multi-year rolling
window approach was used, as illustrated on Figure 2):


  - Each window comprised 11 years of training data (approximately 2772 trading days),
3 years of validation data (756 trading days), and 1 year of test data (252 trading
days).


  - After each test period, the window shifted forward by one year (252 trading days),
creating 11 overlapping windows across the 25-year dataset.


This setup ensured the model was trained on extensive historical data, validated for
generalization, and tested on out-of-sample periods — closely resembling real-world forecasting settings.


9


Figure 2: Schematic of the rolling window methodology used for LSTM and Hybrid models


Note: The scheme illustrates the division of data into training, validating, and testing sets for the LSTM model. Each
window contains 11 years of training data, 3 years of validation data, and 1 year of test data. The window moves forward by
one year at a time, and the model is refitted at each step. As a result, the out-of-sample data comprises the test segments
from 11 consecutive windows, collectively forming the final test set. Predictions were generated for the next day ( _t_ + 1) in
each case.


The Hybrid SV-LSTM model was constructed to integrate the statistical accuracy of
the SV model with the learning capacity of the LSTM. It combined three inputs: the
SV model’s latent volatility prediction for _t_ + 1, the log returns, and the 21-day rolling
historical volatility. Like the LSTM model, it used data from 2000 to 2025 and followed the
same rolling window structure. By incorporating SV predictions as an additional input,
the model was designed to enrich the LSTM’s feature space with statistically derived
volatility signals.

### **4 Model Development**

#### **4.1 Stochastic Volatility Model**


First introduced by Taylor [1982, 1986], the SV model diverges from traditional deterministic volatility models, such as the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) framework [Bollerslev, 1986], by treating volatility as a latent stochastic
process rather than a deterministic function of past observations. This approach offers
greater flexibility in capturing empirical features of financial returns, such as volatility
clustering, mean reversion, and the leverage effect, making it preferable to GARCH for
this study, especially given evidence of its superior performance in modeling complex
volatility dynamics.


**4.1.1** **Model Selection**


In the Stochastic Volatility (SV) framework, asset returns are modeled as conditionally
normally distributed with a time-varying variance driven by a latent log-volatility process,
as implemented in the `stochvol` package (Kastner, 2016). The mathematical formulation
is expressed through the following state-space equations:


  - **Return Equation:**
_yt | ht ∼_ _N_ (0 _, e_ _[h][t]_ ) (8)


10


where _yt_ is the observed return at time _t_, _ht_ is the latent log-volatility, and _e_ _[h][t]_ gives
the variance at time _t_ .


- **Latent Volatility Process:**


_ht | ht−_ 1 _, µ, ϕ, ση ∼_ _N_             - _µ_ + _ϕ_ ( _ht−_ 1 _−_ _µ_ ) _, ση_ [2]             - (9)


where _ht_ is the log-volatility at time _t_, _ht−_ 1 is its value at the previous time step,
_µ_ is the long-term mean of the log-volatility, _ϕ_ is the persistence parameter, and
_ση_ is the volatility of the volatility process. This equation models the evolution of
log-volatility over time, where the process exhibits mean-reverting behavior and can
experience random shocks due to volatility clustering.




- **Initial Condition:**




     - _ση_ [2]
_h_ 0 _| µ, ϕ, ση ∼_ _N_ _µ,_
1 _−_ _ϕ_ [2]




(10)



where _h_ 0 is the initial log-volatility, _µ_ is the long-term mean, _ϕ_ is the persistence
parameter, and _ση_ is the volatility of the volatility process. This equation specifies
the distribution of the initial value of log-volatility, ensuring that it is consistent
with the subsequent evolution of volatility dynamics.


The stochastic specification allows volatility to evolve randomly over time while exhibiting mean-reverting behavior, a well-documented characteristic of financial markets
(Engle & Patton, 2001). This feature distinguishes the SV model from GARCH models and enhances its suitability for capturing the intricate volatility patterns observed in
real-world data.


**4.1.2** **Prior Parametrization and Sampling**


The SV model hinges on three key parameters: _µ_, the long-term mean of log-volatility;
_ϕ_, the persistence of the volatility process; and _ση_, the volatility of the volatility process,
each of which requires careful parametrization and estimation. In this study, we adopt a
data-driven approach by employing weakly informative default priors, as inspired by Kim
et al. (1998), rather than imposing strong prior distributions, ensuring flexibility across
forecasting windows and leveraging priors well-calibrated for general financial time series.
Specifically, the priors are set independently for each parameter within the `stochvol`
package (Kastner, 2016), relying on posterior distributions for inference to reflect the
underlying data dynamics. Parameter estimation is conducted using Markov Chain Monte
Carlo (MCMC) sampling via the Metropolis-Hastings algorithm, implemented efficiently
in the `stochvol` package. This method iteratively samples from the posterior distributions
of the latent log-volatility _ht_ and the parameters _µ_, _ϕ_, and _ση_, utilizing the package’s
ancillarity-sufficiency interweaving strategy (ASIS) to enhance mixing and convergence
(Kastner & Frühwirth-Schnatter, 2014). The sampling process runs for 1,000 iterations,
with a 200-iteration burn-in period discarded to ensure the chain stabilizes, providing
reliable estimates for volatility forecasting.


**4.1.3** **SV Model Results**


The stochastic volatility (SV) model has been implemented to generate one-day-ahead
median volatility forecasts for the S&P 500, spanning February 1, 1997, to January 1,


11


2025, using a rolling window approach with a training period of 504 days, equivalent
to two years of trading data. At this interim stage, the model produces predictions
_√_
representing the median of the predictive distribution for _e_ _[h][t]_ [+1], where _ht_ +1 denotes the

latent log-volatility at time ( _t_ + 1), derived from the posterior draws of the volatility
process as outlined in Subsection 4.1.1.
Focusing on January 24, 2014, to December 30, 2024, Figure 3 compares these forecasts
to the two-year rolling historical volatility, revealing that SV estimates capture key trends,
such as the 2020 spike and early 2022 fluctuations, but exhibit more noise than the
smoother benchmark.


Figure 3: SV Model Forecasts vs. 21-Day Rolling Historical Volatility


Note: The figure shows the predicted latent volatility for day _t_ + 1, generated by the Stochastic Volatility model, plotted
against the 21-day historical rolling volatility for the period from January 2014 to December 2024.


Table 3 summarizes the error metrics. The MAPE of 18.12% reflects moderate accuracy, influenced by the model’s sensitivity to short-term noise, while the MSE of 9 _×_ 10 _[−]_ [6]

and MAE of 1 _._ 717 _×_ 10 _[−]_ [3] indicate small absolute errors.


Table 3: Comparative Error Metrics: SV Model vs. 21-Day Rolling Historical Volatility
on Period January 2014 - December 2024


**Metric** **Value**
Mean Absolute Percentage Error (MAPE) 18.12%
Mean Squared Error (MSE) 9 _×_ 10 _[−]_ [6]

Mean Absolute Error (MAE) 1 _._ 717 _×_ 10 _[−]_ [3]


Note: The table presents the accuracy metrics calculated for the out-of-sample predictions of the Stochastic Volatility model
for day _t_ + 1, covering the period from January 2014 to December 2024.


12


#### **4.2 LSTM Model**

**4.2.1** **Model Selection and Parameterization**


The Long Short-Term Memory (LSTM) model, originally proposed by Hochreiter and
Schmidhuber (1997), was selected for its adeptness at time series forecasting, particularly
in capturing long-term dependencies and adapting to volatile shocks prevalent in financial
market volatility, such as that of the S&P 500. Unlike traditional recurrent neural networks (RNNs), which struggle with vanishing gradients and retaining distant information,
the LSTM’s architecture leverages memory cells and three key gates- forget, input, and
output to regulate information flow effectively.
The forget gate in an LSTM, defined as _ft_ = _σ_ ( _Uf · xt_ + _Vf · ht−_ 1 + _bf_ ), where _ht−_ 1 is
the previous hidden state, _xt_ is the current input, and _bf_ is the bias vector, uses a sigmoid
activation function to determine how much of the previous cell state _Ct−_ 1 to retain. The
sigmoid outputs values between 0 and 1, and the filtered cell state is computed as


_Ct_ _[′]_ [=] _[ f][t]_ _[·][ C][t][−]_ [1] _[,]_


where _ft_ acts as a retention factor (0 for full forgetting, 1 for full retention).
Meanwhile, the input gate, computed as _it_ = _σ_ ( _Ui_ _·xt_ + _Vi_ _·ht−_ 1 + _bi_ ), decides how much
new information to add to the cell state. It works alongside a candidate state, defined as


_Ct_ [+] [= tanh(] _[U][c]_ _[·][ x][t]_ [+] _[ V][c]_ _[·][ h][t][−]_ [1] [+] _[ b][c]_ [)] _[,]_


which proposes potential updates using a tanh activation (ranging from _−_ 1 to 1). The
cell state is then updated as
_Ct_ = _Ct_ _[′]_ [+] _[ i][t]_ _[·][ C]_ _t_ [+] _[,]_


combining the filtered previous state (from the forget gate) with the gated new information
(from the input gate and candidate state).
The output gate, given by _ot_ = _σ_ ( _Uo · xt_ + _Vo · ht−_ 1 + _bo_ ), shapes the hidden state with
the formula
_ht_ = _ot ·_ tanh( _Ct_ ) _._


The sigmoid _ot_ (0 to 1) filters the tanh-transformed cell state (scaled between _−_ 1 and
1), ensuring relevant volatility patterns are preserved and passed to the next time step
or output layer. This framework operates across training, validation, and test phases,
where the model processes input sequences through these gates to predict one-day-ahead
volatility. During training, a selected loss function is minimized by adjusting parameters
(weights and biases) based on the error between predictions and actual values. This
adjustment uses gradient descent with the update rule


_wt_ = _wt−_ 1 _−_ _η ·_ _[∂L]_

_∂w_ _[,]_



where _η_ is the learning rate, _[∂L]_



where _η_ is the learning rate, _[∂L]_

_∂w_ [is the gradient of the loss with respect to the parameter,]
and the term _η ·_ _[∂L]_ [represents the step size for updates.]



and the term _η ·_ _[∂L]_

_∂w_ [represents the step size for updates.]
To mitigate overfitting, validation loss is monitored in real-time; an increase in validation error despite decreasing training loss signals over-specialization, prompting early
stopping. Data is partitioned into overlapping rolling windows, with training (11 years),
validation (3 years), and test (1 year) sets kept independent, as detailed in Subsection
4.1. Within each window, hyperparameter tuning is conducted using 25 random search



13


combinations. Each combination is tested across three trials, with each trial running for
50 epochs. Early stopping is implemented to halt the training process if the validation loss
does not improve over 5 consecutive iterations. The best model weights, corresponding to
the lowest validation loss, are retained. Additionally, the average validation loss from the
three trials is calculated to ensure robustness and reduce the likelihood of overfitting or
anomalous results.The hyperparameters tuned, listed in Table 4, include the number of
LSTM layers, dense layers, units per layer, learning rate, activation functions, recurrent
dropout, dropout and loss function. Recurrent dropout, applied to recurrent connections,
differs from standard dropout on feedforward layers by stabilizing temporal dependencies,
enhancing the LSTM’s ability to generalize across volatile financial data. The selected
hyperparameter grid as a result of tunning process can be observed in Figure 5.


Table 4: Hyperparameters Tuned for the LSTM Model


**Hyperparameter** **Range**
Number of LSTM Layers 1, 2, 3
Number of Dense Layers 0, 1,2, 3
Units per Layer 32, 64, 128
Learning Rate [10 _[−]_ [4] _,_ 5 _×_ 10 _[−]_ [4] _,_ 10 _[−]_ [3] _,_ 5 _×_ 10 _[−]_ [3] _,_ 10 _[−]_ [2] ]
Activation Function tanh, relu, sigmoid
Recurrent Dropout 0, 0.05, 0.1, 0.15, 0.2
Dropout 0, 0.05, 0.1, 0.15, 0.2
Loss Function MSE, MAE


Note: The table presents the range of hyperparameters selected for tuning the architecture of the LSTM model. A Random
Search approach was employed, consisting of 25 trials, each with 50 epochs and 3 executions per trial. Early stopping was
applied with a patience of 5. The tuning process was conducted across all rolling windows using the training and validation
sets.


Table 5: Selected LSTM Hyperparameter Grid for Rolling Windows 1–11


**Hyperparameter/Window** **1** **2** **3** **4** **5** **6** **7** **8** **9** **10** **11**


Learning Rate 0.005 0.01 0.01 0.01 0.0005 0.01 0.001 0.005 0.01 0.01 0.0005
Loss Function MSE
Number of LSTM Layers 1 1 3 3 2 2 2 1 2 1 1
LSTM Units (Layer 1) 32 64 64 32 64 32 64 32 64 32 128
Activation (Layer 1) tanh sigmoid relu tanh sigmoid sigmoid tanh relu sigmoid relu sigmoid
Recurrent Dropout (L1) 0 0 0.1 0.2 0.05 0.1 0 0 0.05 0.15 0.15
LSTM Units (Layer 2) 64 128 32 128 64 128 128 64 32 64 32
Activation (Layer 2) sigmoid sigmoid tanh tanh tanh sigmoid sigmoid relu sigmoid sigmoid tanh
Recurrent Dropout (L2) 0.15 0.1 0 0.15 0 0.05 0.05 0 0.1 0.1 0.05
LSTM Units (Layer 3) 64 128 32 32 64 32 32 64 128 64 128
Activation (Layer 3) tanh tanh tanh sigmoid tanh tanh sigmoid sigmoid tanh sigmoid relu
Recurrent Dropout (L3) 0 0.15 0 0.2 0.2 0.2 0 0 0.1 0.1 0.15
Use Dropout Layer False
Number of Dense Layers 3 1 2 3 1 0 0 3 3 1 0
Dense Units (Layer 1) 128 32 32 32 128 64 64 32
Activation (Dense 1) tanh relu tanh tanh tanh relu relu relu
Dense Units (Layer 2) 64 64 32 64 32 64 128 32
Activation (Dense 2) sigmoid relu tanh sigmoid tanh relu relu sigmoid
Dense Units (Layer 3) 64 32 64 32 32 64 64
Activation (Dense 3) relu relu tanh relu sigmoid tanh tanh

Note: The table presents the selected hyperparameter configuration for the LSTM model in each rolling window, chosen
after a randomized hyperparameter search. The tuning was performed using the Keras Tuner library with 25 executions
and 3 repeated trials per execution, optimizing for the lowest average validation loss (MSE).


**4.2.2** **LSTM Volatility Forecasting Methodology**


The LSTM volatility forecasting methodology leverages a structured approach to predict
one-day-ahead volatility for the S&P 500, utilizing log returns as inputs and producing


14


volatility quantiles as outputs within a rolling window framework. Once optimal hyperparameters are selected (as detailed in Subsection 4.2.1), the LSTM model is trained
independently within each of the 11 rolling windows, each comprising a training period
of 11 years (2,772 trading days), a validation period of 3 years (756 days), and a test
period of 1 year (252 days). During training, log returns are fed into the model, which
processes them through its gated architecture to forecast the subsequent day’s volatility
( _t_ + 1), with continuous monitoring of validation loss—measured via mean squared error
(MSE)—to ensure generalization to unseen data. An early stopping criterion halts training if the validation loss fails to improve over 10 consecutive epochs within a maximum of
100 epochs per window, retaining the parameters from the epoch with the lowest MSE.
Following training, the model generates out-of-sample volatility predictions for the 252day test period in each window, aggregating these forecasts across all windows to form a
comprehensive set spanning January 1, 2000, to January 1, 2025. This complete forecast
series enables robust evaluation against historical volatility and benchmark models, assessing the LSTM’s effectiveness across diverse market conditions. The detailed workflow
is presented in Algorithm 1.


**Algorithm 1** Volatility Forecasting Pipeline with LSTM and Hyperparameter Optimization

1: **Initialize environment:** import required libraries and load S&P 500 data.
```
   import numpy, pandas, tensorflow, keras, keras_tuner, sklearn
```

`df` _←_ `load_SP500_data()`
2: **Compute log returns and rolling volatility:**



`log_return` _t ←_ log - `CloseClose` _t−t_ 1







`volatility` _t ←_ `RollingStd` ( `log_return` _,_ `window` = 21)
3: **Segment data using a rolling window approach:**
4: **for** each rolling window **do**
5: `train, val, test` _←_ `split_data(df, train=11y, val=3y, test=1y)`
6: `X_train, y_train` _←_ `create_sequences(train, lookback=21)`
7: `X_val, y_val` _←_ `create_sequences(val, lookback=21)`
8: `X_test, y_test, test_dates` _←_ `create_sequences(test, lookback=21)`
9: `scale(X_train, X_val, X_test)`
10: **Define model and hyperparameter space**
11: **Run hyperparameter tuning:**
12: `tuner` _←_ `RandomSearch(build_model, executions_per_trial=3, max_trials=25)`
13: `tuner.search(X_train, y_train, ...)`
14: **Select best model with lowest average validation loss:**
15: `best_model` _←_ `tuner.get_best_models(1)[0]`
16: **Train best model with early stopping:**
17: `early_stop` _←_ `EarlyStopping(patience=5)`
18: `best_model.fit(X_train, y_train, val_data=(X_val, y_val), callbacks=[early_stop])`
19: **Forecast on test data:**
20: `forecast` _←_ `best_model.predict(X_test)`
21: `predictions.append(forecast[0])`
22: **Aggregate results:**
23: `full_forecast` _←_ `concat(predictions)`
24: **Evaluate forecast performance:**

`MSE` = ~~�~~ `mean_squared_error` ( _y_ true _,_ `full_forecast` )

`MAE` = `mean_absolute_error` ( _y_ true _,_ `full_forecast` )
`MAPE` = `mean_absolute_percentage_error` ( _y_ true _,_ `full_forecast` )
25: **Return:** `full_forecast`, `MSE`, `MAE`, `MAPE`


The model was implemented using Python 3.12.6 within Jupyter notebooks on Visual
Studio Code. The software environment included TensorFlow and Keras for model archi

15


tecture and training, with Keras Tuner employed for hyperparameter optimization using
its random search functionality.
The calculations were carried out on a standard consumer-grade laptop equipped with
a multi-core CPU and 16 GB of RAM, without access to dedicated GPU acceleration. As
a result, all computations were carried out on the CPU, which prolonged the processing
time compared to GPU-supported environments.
Due to the repeated training required across rolling windows and the comprehensive
nature of the hyperparameter tuning (performed separately on each training-validation
window split), the tuning process spanned approximately 24 hours in total. Once optimal
parameters were determined, the training of the LSTM model and subsequent forecasting
per window were significantly faster, requiring roughly 15 minutes each. Despite hardware
limitations, the sequential design and use of efficient libraries ensured the feasibility of
model development and evaluation.


**4.2.3** **LSTM Model Results**


The Long Short-Term Memory (LSTM) model predicts S&P 500 21-day rolling historical
volatility for day ( _t_ + 1) from January 24, 2014, to December 30, 2024, using log returns.
Figure 4 compares these out-of-sample forecasts to the 21-day rolling volatility, showing effective trend capture but underestimation of sharp 2020–2022 shifts.


Figure 4: LSTM Predictions vs. 21-Day Rolling Historical Volatility


Note: The figure shows the predicted rolling volatility for day _t_ + 1, provided by LSTM model, plotted against the 21-day
rolling historical volatility for the period from January 2014 to December 2024.


Table 6 lists error metrics: MAPE of 5.29% indicates strong relative accuracy, with
MSE of 7 _._ 09 _×_ 10 _[−]_ [7] and MAE of 4 _._ 80 _×_ 10 _[−]_ [4] showing small absolute errors.

#### **4.3 Hybrid SV-LSTM Model**


The hybrid SV-LSTM model integrates predictions from the Stochastic Volatility (SV)
model as an additional input to the Long Short-Term Memory (LSTM) framework, com

16


Table 6: Comparative Error Metrics: LSTM Model vs. 21-Day Rolling Historical Volatility on Period January 2014 - December 2024


**Metric** **Value**
Mean Absolute Percentage Error (MAPE) 5.29%
Mean Squared Error (MSE) 7 _._ 09 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 4 _._ 80 _×_ 10 _[−]_ [4]


Note: The table presents the accuracy metrics calculated for the out-of-sample predictions of the LSTM model for day _t_ +1,
covering the period from January 2014 to December 2024.


bining the probabilistic strengths of SV with the LSTM’s capacity to capture complex
temporal dependencies. This approach aims to improve the accuracy and robustness of
S&P 500 volatility forecasting beyond the standalone SV and LSTM models, described
in more detail in Sections 4.1 and 4.2, respectively.
By leveraging both stochastic and sequential modeling, the hybrid targets the 21-day
rolling historical volatility for day ( _t_ + 1), evaluated over January 24, 2014, to December
30, 2024.


**4.3.1** **SV-LSTM Model Framework**


The hybrid model utilizes three inputs: log returns, 21-day rolling historical volatility
_√_
and the SV model’s latent volatility output _e_ _[h][t]_ [+1], where _ht_ +1 is the log-volatility from

posterior draws, as mentioned in Section 4.1.
The SV component, trained on log returns from December 1998 to December 2024,
with a 504-day rolling window, generated the prediction of latent estimates for day (t+1)
and is refitted at each timestep. As the SV estimation is based on the past close prices
for the last two years, the prediction for day (t+1) is obtained at the same timestep as we
have the close price for the respective day t. This allowed to fetch the estimates with the
input data for LSTM model for day t, such as log returns and rolling volatility estimates.
Before feeding the data into the model, all inputs undergo preprocessing, including
scaling and segmentation into 21-day sequences, following the procedure detailed in Section 3.3. The hybrid model employs the same LSTM architecture described in Section
4.2 and explores the same hyperparameter space defined in Table 4.
Hyperparameter tuning is performed independently within each rolling window using
a random search strategy over 25 trials, with 3 repetitions per trial to account for training
variability. The results are averaged based on the Mean Squared Error (MSE) to select
the optimal configuration.
Model training and evaluation are conducted across 11 overlapping rolling windows
covering the period from 2000 to 2024. For each window, the model is trained on the most
recent 504 days and generates forecasts for the next day ( _t_ + 1) utilizing the preceding
21-day sequences.


**4.3.2** **SV-LSTM Model Results**


The hybrid SV-LSTM model predicts S&P 500 21-day rolling historical volatility for
day ( _t_ + 1) from January 24, 2014, to December 30, 2024, using out-of-sample data
concatenated from the test segments of the 11 sliding windows. Figure 5 plots these
predictions against the actual 21-day rolling volatility, demonstrating effective capture


17


of overall trends and superior adaptability compared to the standalone LSTM (Section
4.2.3), particularly during the sharp 2020–2022 shifts driven by the COVID-19 pandemic.


Figure 5: SV-LSTM predictions plotted against actual volatility on out-of-sample values


Note: The table presents the accuracy metrics calculated for the out-of-sample predictions of the SV-LSTM model for day
_t_ + 1, covering the period from January 2014 to December 2024.


Table 7 presents the comparative error metrics against the 21-day rolling historical
volatility benchmark. The Mean Absolute Percentage Error (MAPE) of 4.75% indicates
high relative accuracy and reflects the hybrid’s ability to closely track proportional volatility changes. This is supported by a Mean Squared Error (MSE) of 5 _._ 07 _×_ 10 _[−]_ [7] and Mean
Absolute Error (MAE) of 4 _._ 29 _×_ 10 _[−]_ [4] .


Table 7: Comparative Error Metrics: SV-LSTM Model vs. 21-Day Rolling Historical
Volatility on Period January 2014 - December 2024


**Metric** **Value**
Mean Absolute Percentage Error (MAPE) 4.75%
Mean Squared Error (MSE) 5 _._ 07 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 4 _._ 29 _×_ 10 _[−]_ [4]


Note: The table presents the accuracy metrics calculated for the out-of-sample predictions of the SV-LSTM model for day
_t_ + 1, covering the period from January 2014 to December 2024.

### **5 Empirical Results and Benchmark Comparison**

#### **5.1 Benchmark Comparison**


This section synthesizes and compares the performance of all 3 models described previously in subsections 4.1.3, 4.2.3, 4.3.2 of their results of predicting S&P 500 rolling
volatility on out-of-sample values on period from January 2014 until December 2024. The


18


performance metrics along all three models are presented together in the Table 8. As we
can observe, the hybrid SV-LSTM model surpasses the benchmark models along all three
metrics, highlighting the leverage success.


Table 8: Error Metrics for SV, LSTM, and Hybrid SV-LSTM Models vs. 21-Day Rolling
Historical Volatility (January 2014 – December 2024)


**Model** **MAPE (%)** **MSE** **MAE**
SV 18.12 9 _×_ 10 ~~_[−]_~~ ~~[6]~~ 1 _._ 717 _×_ 10 ~~_[−]_~~ ~~[3]~~

LSTM 5.29 7 _._ 09 _×_ 10 _[−]_ [7] 4 _._ 80 _×_ 10 _[−]_ [4]

Hybrid SV-LSTM 4.75 5 _._ 07 _×_ 10 _[−]_ [7] 4 _._ 29 _×_ 10 _[−]_ [4]


Note: The table presents the accuracy metrics calculated for out-of-sample predictions generated by three models: SV,
LSTM, and the hybrid SV-LSTM. These predictions target day _t_ + 1 and cover the period from January 2014 to December
2024.

#### **5.2 Statistical Tests**


The hybrid SV-LSTM model’s performance was compared to LSTM and SV models using
the Wilcoxon Signed-Rank Test and Diebold-Mariano (DM) Test, assessing forecast error
differences ( _et_ = ˆ _yt −_ _yt_ ) between tested models from January 24, 2014, to December 30,
2024.
The Wilcoxon test, firstly proposed by Wilcoxon (1945), checks if two models’ error
distributions are similar without assuming a specific shape, identifying its non-parametric
feature. It tests the null hypothesis ( _H_ 0): the median error is the same for both models,
against the alternative ( _H_ 1): the medians differ. We calculate differences between paired
errors, rank them, and compute a statistic to see if the difference is significant.


_dt_ = _e_ 1 _,t −_ _e_ 2 _,t_ (11)


Where:

   - _dt_ : Difference in errors at time _t_ between two models.

   - _e_ 1 _,t_ : Error of the first model at time _t_, where _e_ 1 _,t_ = ˆ _y_ 1 _,t −_ _yt_ ( _y_ ˆ1 _,t_ is the predicted
value, _yt_ is the actual value).

   - _e_ 2 _,t_ : Error of the second model at time _t_ .
These differences ( _dt_ ) are ranked by their absolute size ( _|dt|_ ), ignoring zeros, and given
their original signs (positive or negative). The test statistic _W_ is the sum of positive
ranks. For many observations (large _n_ ), we standardize _W_ into a _Z_ -score:



_W −_ _[n]_ [(] _[n]_ [+1)]
_Z_ = 4



(12)



4

~~�~~



_n_ ( _n_ +1)(2 _n_ +1)



24



Where:

- _Z_ : Standardized score, compared to a normal distribution to find the p-value.

- _W_ : Sum of ranks for positive _dt_ values.

- _n_ : Number of non-zero differences, 2,500 days from 2014–2024).

- _[n]_ [(] _[n]_ [+1)] : Expected value of _W_ if _H_ 0 is true (no difference).




~~�~~




4 : Expected value of _W_ if _H_ 0 is true (no difference).



_n_ ( _n_ +1)(2 _n_ +1) : Standard deviation of _W_, measuring its variability.

24


19


If _p >_ 0 _._ 05, we cannot reject _H_ 0 that states there is no difference in errors produced
by two models; if _p <_ 0 _._ 05, we reject it, which implies that compared models differ in
their error distribution.
The Diebold-Mariano(DM) test, proposed by Diebold and Mariano (2002), checks
which model forecasts more accurately over time. Its null hypothesis ( _H_ 0) says both
models are equally accurate, while the alternative ( _H_ 1) suggests one is better. We measure
accuracy with a loss function _L_, like squared error ( _L_ ( _e_ ) = _e_ [2] ) for MSE or absolute error
( _L_ ( _e_ ) = _|e|_ ) for MAE, and compute differences:


_dt_ = _L_ ( _e_ 1 _,t_ ) _−_ _L_ ( _e_ 2 _,t_ ) (13)


   - _dt_ : Difference in loss ( squared or absolute errors) at time _t_ .

   - _L_ ( _e_ 1 _,t_ ): Loss for the first model’s error at _t_ .

   - _L_ ( _e_ 2 _,t_ ): Loss for the second model’s error at _t_ .

   - _e_ 1 _,t, e_ 2 _,t_ : Errors as defined above.
Under _H_ 0, the average difference over time should be zero:


_E_ [ _dt_ ] = 0 (14)


- _E_ [ _dt_ ]: Expected (average) loss difference across all _t_ . If true, models have equal accuracy.
For _H_ 1, we test if Model 1 is more accurate than Model 2, expecting:


_E_ [ _dt_ ] _<_ 0 (15)


- _E_ [ _dt_ ] _<_ 0: Average loss difference is negative, meaning errors of the Model 1 are smaller.
The DM statistic is calculated from _dt_, adjusted for time-series patterns, and gives a
p-value. If _p <_ 0 _._ 05, we reject _H_ 0, concluding Model 1 is more accurate. Significance is
checked at _α_ = 0 _._ 05.
Table 9 summarizes the statistical test results for model comparisons over 2014–2024.


Table 9: Statistical Test Results for Model Comparisons on Period January 2014 - December 2024


**Comparison** **Wilcoxon** **Diebold-Mariano**
_W_ **(** _Z_ **)** _p_ **-value** **DM (MSE)** **DM (MAE)** _p_ **-value**
LSTM vs. SV 319,921 (2.75) _<_ 0 _._ 001 -8.94 -27.57 _<_ 0 _._ 001
SV-LSTM vs. LSTM 1,544,740 (1.90) 0.058 -6.86 -5.51 _<_ 0 _._ 001
SV-LSTM vs. SV 266,472 (3.87) _<_ 0 _._ 001 -9.18 -29.14 _<_ 0 _._ 001
Note: The table reports the results of the Wilcoxon signed-rank test and the Diebold-Mariano test used to compare the
forecasting performance of the SV-LSTM model against the LSTM and SV models over the period from December 2014
to January 2024. The Wilcoxon test evaluates the statistical significance of differences in prediction accuracy, while the
Diebold-Mariano test compares forecast errors based on MSE and MAE.


Comparing SV and LSTM, the Wilcoxon test statistic amounted to _W_ = 319 _,_ 921 ( _Z_ =
2 _._ 75 _, p <_ 0 _._ 001), allowing for the rejection of _H_ 0 and indicating a significant difference in
the error distributions between the two models. The Diebold-Mariano (DM) test statistics,
_DM_ = _−_ 8 _._ 94 ( _p <_ 0 _._ 001) for MSE and _DM_ = _−_ 27 _._ 57 ( _p <_ 0 _._ 001) for MAE, also led
to the rejection of _H_ 0. These results identified the superior forecasting accuracy of the
LSTM model compared to the SV model.
For the SV-LSTM vs. LSTM comparison, the Wilcoxon Signed-Rank Test obtained
a statistic of _W_ = 1 _,_ 544 _,_ 740 ( _Z_ = 1 _._ 90, _p_ = 0 _._ 058), driven by a large sample size
( _n ≈_ 2 _,_ 500, 2014–2024). Although _p_ = 0 _._ 058 _>_ 0 _._ 05 is close to the critical value, we


20


fail to reject _H_ 0, indicating no statistically significant difference in the error distributions
( _et_ = ˆ _yt −_ _yt_ ) between the two models. Meanwhile, the Diebold-Mariano (DM) Test for
MSE gives _DM_ = _−_ 6 _._ 86 ( _p <_ 0 _._ 001), and for MAE, _DM_ = _−_ 5 _._ 51 ( _p <_ 0 _._ 001), both
rejecting _H_ 0 and demonstrating SV-LSTM’s better forecasting accuracy, as negative DM
values reflect lower squared and absolute errors for the hybrid model.
For SV-LSTM vs. SV, the Wilcoxon test obtained the test statistics such as _W_ =
266 _,_ 472 ( _Z_ = 3 _._ 87, _p <_ 0 _._ 001), rejecting _H_ 0 and confirming a significant difference
between medians of error distributions. The DM Test further supports this conclusion:
for MSE, _DM_ = _−_ 9 _._ 18 ( _p <_ 0 _._ 001), and for MAE, _DM_ = _−_ 29 _._ 14 ( _p <_ 0 _._ 001), both
rejecting _H_ 0 and indicating SV-LSTM’s better accuracy over the SV model, with large
negative DM statistics underscoring substantial error reductions across both metrics.

### **6 Sensitivity Analysis**


Sensitivity analysis is a crucial step in the analysis of the proposed model as it takes into
account the other settings and propositions that could have been omitted in the base case
scenario, as also provides more insights to the model performance, as well as the areas of
potential improvements and implementations.

#### **6.1 Sequence Length**


A detailed analysis was conducted to investigate how varying the sequence length impacts
the predictive performance of the model. In this context, a sequence length of five past
observations was selected as input data for the hybrid SV-LSTM model, which is designed
to forecast the 21-day rolling historical volatility for the following day (t+1). This specific configuration aims to capture short-term temporal dependencies in the data while
maintaining model efficiency. The predicted values generated by the SV-LSTM model,
plotted alongside the actual observed volatilities, are presented in Figure 6, providing a
visual comparison of the model’s forecasting accuracy under this input setting.
Table 10 presents a comparison of performance metrics between the modified hybrid
model using a sequence length of 5 days and the baseline hybrid model with a sequence
length of 21 days. The results indicate that reducing the sequence length does not lead
to any improvement in the model’s predictive accuracy. In fact, the findings suggest that
a longer input sequence may provide more stable and informative patterns for forecasting
volatility.


Table 10: Error Metrics: Hybrid SV-LSTM with 5-Day Sequence vs. Baseline SV-LSTM
(2014–2024)


**Metric** **5-Day Sequence** **Baseline SV-LSTM**
Mean Absolute Percentage Error (MAPE) 5.47% 4.75%
Mean Squared Error (MSE) 6 _._ 13 _×_ 10 _[−]_ [7] 5 _._ 07 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 4 _._ 82 _×_ 10 _[−]_ [4] 4 _._ 29 _×_ 10 _[−]_ [4]

Note: The table presents the accuracy metrics for out-of-sample predictions generated by the SV-LSTM model using a
5-day input sequence for forecasting day _t_ + 1. These results are compared to those of the baseline hybrid model, which
uses a 21-day input sequence. The evaluation covers the period from January 2014 to December 2024.


Furthermore, another analysis was conducted to examine the influence of prolonging
the input sequence into the SV-LSTM model to 42 days of past data. This analysis


21


Figure 6: SV-LSTM Predictions with the Sequence of 5 Days


Note: The figure shows the predicted rolling volatility for day _t_ + 1, provided by SV-LSTM model with a sequence of 5
days, plotted against the 21-day rolling historical volatility for the period from January 2014 to December 2024.


was aimed at examining the influence of providing more information and fluctuations,
compared to the baseline model with 21 days of past data, suggesting that a longer
period of observations could provide a more accurate forecast for day (t+1). In Figure 7
the predicted values generated by the SV-LSTM model are plotted alongside the actual
observed volatilities, providing a visual comparison of the model’s forecasting accuracy
under this input setting.
Table 10 presents a comparison of performance metrics between the modified hybrid
model using a sequence length of 42 days and the baseline hybrid model with a sequence
length of 21 days. The increased values of the error metrics for the 42-day sequence
variation suggest that the increase in the number of days in the sequence does not improve
the accuracy of the model forecast.


Table 11: Error Metrics: Hybrid SV-LSTM with 42-Day Sequence vs. Baseline SV-LSTM
(2014–2024)


**Metric** **42-Day Sequence** **Baseline SV-LSTM**
Mean Absolute Percentage Error (MAPE) 5.31% 4.75%
Mean Squared Error (MSE) 5 _._ 68 _×_ 10 _[−]_ [7] 5 _._ 07 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 4 _._ 65 _×_ 10 _[−]_ [4] 4 _._ 29 _×_ 10 _[−]_ [4]

Note: The table presents the accuracy metrics for out-of-sample predictions generated by the SV-LSTM model using a
42-day input sequence for forecasting day _t_ + 1. These results are compared to those of the baseline hybrid model, which
uses a 21-day input sequence. The evaluation covers the period from January 2014 to December 2024.


The results of the analysis indicate that the amount of past days used as an input for
forecasting the volatility for day (t+1) for the SV-LSTM model influences the prediction
accuracy. Nevertheless, the findings suggest that the sequence of 21 past observations,
utlized in the baseline model is the optimal one as the error metrics increase for both
options: for increase of sequence to 42 days and decrease of it to 5 days.


22


Figure 7: SV-LSTM Predictions with the Sequence of 42 Days


Note: The figure shows the predicted rolling volatility for day _t_ + 1, provided by SV-LSTM model with a sequence of 42
days, plotted against the 21-day rolling historical volatility for the period from January 2014 to December 2024.

#### **6.2 Data Scaling**


Given the sensitivity of machine learning models to the quality and structure of input
data, an additional analysis was conducted to examine the potential impact of data preprocessing on the performance of the hybrid model. Specifically, this analysis explored
whether applying feature scaling could enhance prediction accuracy. Unlike the baseline hybrid model, where raw data was fed into the LSTM component using MinMax
Scaler, in this modified version, the input data was standardized using a Standard Scaler,
transforming the features to have zero mean and unit variance. The resulting predictions
from the standardized-input hybrid model, plotted alongside the21-day rolling historical
volatility, are presented in Figure 8.
Meanwhile, the corresponding accuracy metrics were computed and are presented in
Table 12, alongside the results of the baseline SV-LSTM model without scaling. As noted,
applying standard scaling to the input data led to a consistent improvement across all
error metrics. Specifically, the Mean Absolute Percentage Error (MAPE) decreased from
4.75% to 4.54%, while the Mean Squared Error (MSE) and Mean Absolute Error (MAE)
improved from 5 _._ 07 _×_ 10 _[−]_ [7] and 4 _._ 29 _×_ 10 _[−]_ [4] to 4 _._ 18 _×_ 10 _[−]_ [7] and 3 _._ 80 _×_ 10 _[−]_ [4], respectively.
These results suggest that standardising the input data positively impacts the predictive
accuracy of the hybrid SV-LSTM model.
Furthermore, another analysis was conducted where the raw input data into the LSTM
model was preprocessed using the RobustScaler transformation technique. The results
were plotted against the actual values of rolling volatility across 2014-2024, as illustrated
in Figure 13.
The corresponding metrics are summarised in Table 12 compares the baseline SVLSTM model without scaling and the alternative utilising RobustScaler. The results
indicate that the change of the scaling approach has improved the results of the SV-LSTM
model for all error metrics. The Mean Absolute Percentage Error (MAPE) decreased from


23


Figure 8: SV-LSTM Model Predictions With Standard Scaler


Note: The figure shows the predicted rolling volatility for day _t_ + 1, provided by SV-LSTM model using a standard scaling
preprocessing approach, plotted against the 21-day rolling historical volatility for the period from January 2014 to December
2024.


Table 12: Error Metrics: SV-LSTM with Standard Scaling vs. Baseline SV-LSTM
(2014–2024)


**Metric** **SV-LSTM with Standard Scaling** **Baseline SV-LSTM**
Mean Absolute Percentage Error (MAPE) 4.54% 4.75%
Mean Squared Error (MSE) 4 _._ 18 _×_ 10 _[−]_ [7] 5 _._ 07 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 3 _._ 80 _×_ 10 _[−]_ [4] 4 _._ 29 _×_ 10 _[−]_ [4]

Note: The table presents the accuracy metrics for out-of-sample predictions generated by the SV-LSTM model, which uses
the StandardScaler approach for data preprocessing to forecast day _t_ +1. These results are compared to those of the baseline
hybrid model, which uses a MinMax scaling method. The evaluation covers the period from January 2014 to December
2024.


4.75% to 4.58%, while the Mean Squared Error (MSE) and Mean Absolute Error (MAE)
improved from 5 _._ 07 _×_ 10 _[−]_ [7] and 4 _._ 29 _×_ 10 _[−]_ [4] to 4 _._ 69 _×_ 10 _[−]_ [7] and 3 _._ 90 _×_ 10 _[−]_ [4], respectively.
Therefore, we can conduct that applying robust scaling in data preprocessing step also
improves the model perfomance, but not that much as standardscaling.


Table 13: Error Metrics: SV-LSTM with Robust Scaling vs. Baseline SV-LSTM
(2014–2024)


**Metric** **SV-LSTM with Robust Scaling** **Baseline SV-LSTM**
Mean Absolute Percentage Error (MAPE) 4.58% 4.75%
Mean Squared Error (MSE) 4 _._ 69 _×_ 10 _[−]_ [7] 5 _._ 07 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 3 _._ 90 _×_ 10 _[−]_ [4] 4 _._ 29 _×_ 10 _[−]_ [4]

Note: The table presents the accuracy metrics for out-of-sample predictions generated by the SV-LSTM model, which uses
the RobustScaler approach for data preprocessing to forecast day _t_ + 1. These results are compared to those of the baseline
hybrid model, which uses a MinMax scaling method. The evaluation covers the period from January 2014 to December
2024.


The consistent improvement across all metrics confirms that the choice of data transformation can significantly influence the performance of deep learning-based volatility


24


Figure 9: SV-LSTM Model Predictions With Robust Scaler


Note: The figure shows the predicted rolling volatility for day _t_ + 1, provided by SV-LSTM model using a robust scaling
preprocessing approach, plotted against the 21-day rolling historical volatility for the period from January 2014 to December
2024.


prediction models.

#### **6.3 Number of Hidden Layers**


The influence of differences in the structure of the LSTM model was also explored in the
sensitivity analysis process. Specifically, the number of hidden layers was fixed in each
scenario, ranging from 1 to 3 layers, and corresponding tuning, training, and forecasting
were performed. Figure 10 represents all of the scenarios plotted against the baseline
model and the actual volatility.
The corresponding metrics are summarized in Table 14, which compares the baseline
SV-LSTM model with the models having between 1 and 3 hidden layers. The results
indicate that fixing the number of hidden layers downgrades the performance of the model,
implying that flexible and dynamic tuning of the number of hidden layers in each rolling
window produces better results.


Table 14: Error Metrics: SV-LSTM with Varying Dense Layers vs. Baseline SV-LSTM
(2014–2024)


**Metric** **1 Dense** **2 Dense** **3 Dense** **Baseline SV-LSTM**
Mean Absolute Percentage Error (MAPE) 5.73% 5.84% 6.40% 4.75%
Mean Squared Error (MSE) 6 _._ 617 _×_ 10 _[−]_ [7] 6 _._ 961 _×_ 10 _[−]_ [7] 8 _._ 112 _×_ 10 _[−]_ [7] 5 _._ 07 _×_ 10 _[−]_ [7]

Mean Absolute Error (MAE) 5 _._ 05 _×_ 10 _[−]_ [4] 5 _._ 24 _×_ 10 _[−]_ [4] 5 _._ 79 _×_ 10 _[−]_ [4] 4 _._ 29 _×_ 10 _[−]_ [4]

Note: The table presents the error metrics for the SV-LSTM model with varying numbers of dense layers (1–3) and compares
them to the baseline SV-LSTM model. The evaluation covers the period from January 2014 to December 2024.


25


Figure 10: SV-LSTM Model Predictions With Varying Hidden Layers


Note: The figure presents the one-day-ahead rolling volatility forecasts generated by the SV-LSTM model with varying
numbers of dense layers (1 to 3), compared against the 21-day rolling realized volatility of the S&P 500 and the predictions
of the baseline model, over the period from January 2014 to December 2024.

### **7 Investment Strategy Simulation**


The selected data consisted of VIX monthly futures contracts, collected from the CBOE
website for the entire testing period, from January 2014 to December 2024. The dataset
included the trade date of each selected monthly future along with the open, high, low,
close, settlement price, daily change, and total volume. For our strategy dataframe,
selected values were the trade date, the respective monthly future symbol, and the close
price.
Furthermore, the settlement dates and settlement values were downloaded for the
entire testing period, again from January 2014 to December 2024. Each of these yearly
datasets included the VIX monthly symbol, expiration date of each contract, and the
close price on the expiration date.
To prepare the data for analysis, we combined the collected VIX futures data with
the settlement dates and prices. We created a ’date to expiry’ column, calculated as the
difference between the expiration date and trade date. We then merged the forecasted
volatility values (both actual smoothed rolling volatility and predicted values from day
t-1) with the dataset. For the investment strategy, we moved the forecasted values by
one day to align with the forecast for day t+1, ensuring that each entry in the dataframe
corresponds to the correct day’s forecast.
The investment strategy is based on a daily comparison between the **forecasted**
**volatility for day** _t_ + 1 and the **actual volatility observed at day** _t_ . The trading rules are defined as follows:


  - **Long Position:** If the forecasted volatility vol [forecast] _t_ +1 is greater than the actual
volatility vol [actual] _t_, a **long signal** is generated (signal = 1). This triggers a **long**
**position in VIX futures**, entered at the close price of day _t_ .


26


  - **Short Position:** If the forecasted volatility vol [forecast] _t_ +1 is less than the actual volatility
vol [actual] _t_, a **short signal** is generated (signal = _−_ 1). This leads to a **short position**
**in VIX futures**, also using the close price of day _t_ .


  - **Position Management:** If the signal remains unchanged from the previous day
(signal _t_ = signal _t−_ 1), the position is maintained. If the signal changes (signal _t ̸_ =
signal _t−_ 1), the current position is **closed**, and a **new position** is opened based on
the updated signal. Transaction costs of **0.1%** are applied at both entry and exit.


To evaluate the effectiveness of the trading strategy, it is compared against two naive
benchmarks:


  - **Long Only VIX Futures:** A strategy that maintains a constant long position
throughout the entire period.


  - **Short Only VIX Futures:** A strategy that maintains a constant short position
throughout the entire period.


The benchmarks ignore any information from volatility forecasts and serve to assess
whether the model adds value beyond simple directional exposure.
For all strategies, a consistent assumption is utilised regarding the switching between
futures contracts: each contract is held until its expiration, at which point the position is
rolled into the next available monthly VIX future with the closest subsequent expiration
date. The expiring position is closed at its official settlement price, therefore reflecting
the return from holding the contract up until maturity. The new position is entered on
the same day, using the close price of the next contract. This approach captures the final
payoff of the expiring future while ensuring a smooth and consistent rollover mechanism
across all strategy implementations.
The strategy begins with an initial capital of $1 _,_ 000. On each trading day, only 25%
of the available capital is allocated to the active position. Consequently, daily returns are
scaled by a factor of 0.25 to reflect this partial investment policy.
The equity lines of the strategies are shown in Figure 11. The Short Only strategy
outperformed all others, reflecting the inherent nature of VIX futures. During the volatile
period at the start of 2020, the equity lines of both the LSTM and Short strategies declined
significantly, while the SV strategy, driven by stochastic signals, gained substantially. It
can be noted that the SV-LSTM strategy closely follows the SV line but with smoother
fluctuations and higher overall equity than the LSTM.
The performance metrics presented in Table 15 for the SV, LSTM, and SV-LSTM
signal strategies indicate a pronounced underperformance. Except for Short Only strategy, both the highest Sharpe ratio of _−_ 0 _._ 46 and the annualised return of _−_ 12 _._ 49% were
recorded for the SV Signal Strategy. These results highlight the necessity for further
investigation into the neural network architectures to enhance the suitability of model
forecasts for signal-based trading applications.
Given that the previous part of the study employed conventional error functions such
as MSE, MAE, and MAPE, a modification to the loss function used during the compilation and training of the hybrid SV-LSTM model was introduced. The aforementioned
error metrics measure discrepancies between forecasted and observed values, emphasising
statistical accuracy rather than the predictive efficacy of the generated investment signals. Consequently, many studies optimise their models for statistical precision at the


27


Figure 11: Equity Lines of Investment Strategy


Note: The figure presents the cumulative equity curves of five investment strategies based on VIX futures trading. The
initial capital for each strategy is $1,000, with 25% allocated to each position daily. Transaction costs of 0.1% are applied
on both entry and exit.


expense of economic profitability, thus neglecting the potential trading performance of
the resulting signals.
To mitigate this limitation, the Mean Absolute Directional Loss (MADL), introduced
by Michańków et al. (2023), was implemented. MADL is computed according to the
following formula:



MADL = [1]

_N_



_N_


( _−_ 1) _×_ sign( _Ri ×_ _R_ [ˆ] _i_ ) _×_ abs( _Ri_ ) _,_ (16)

_i_ =1



where MADL denotes the Mean Absolute Directional Loss, _Ri_ represents the observed
return over interval _i_, _R_ [ˆ] _i_ the predicted return in the same interval, sign( _Ri_ _×R_ [ˆ] _i_ ) is the sign
function returning values ( _−_ 1 _,_ 0 _,_ 1) based on the product _Ri ×_ _R_ [ˆ] _i_, abs( _Ri_ ) the absolute
value of _Ri_, and _N_ the total number of forecasts. This approach explicitly links prediction
direction to financial outcomes, enabling the model to assess whether a forecast would
yield profit or loss, and to what degree.
All model parameters were held constant, with MADL introduced as the sole modification to the training configuration. The updated results revealed, shown in Table 15 that
the SV-LSTM hybrid model, while still marginally underperforming relative to the baseline short-only strategy, exhibited improved coherence between predictive accuracy and
investment performance. This finding suggests that incorporating the MADL loss function positively influences the model’s ability to capture directionally meaningful trading
signals.


28


Table 15: Performance Metrics of Equity Strategies


**Metric** **Short Only** **Long Only** **SV** **SV-LSTM** **LSTM** **SV-LSTM MADL**


Sharpe Ratio 0.54 -0.54 -0.46 -0.56 -0.76 0.53
Calmar Ratio 0.26 -0.17 -0.15 -0.17 -0.20 0.26
Annualized Return (ARC) 10.03% -13.82% -12.49% -14.57% -18.31% 9.92%
Annualized Std Dev (ASD) 22.96% 22.96% 22.89% 23.07% 23.07% 22.95%
Max Drawdown -38.27% -83.35% -83.11% -85.15% -93.37% -38.27%
Total Return 183.02% -80.18% -76.60% -82.00% -88.94% 179.96%


Note: This table presents key performance metrics for all evaluated strategies over the testing period from January 2014 to
December 2024. The Sharpe Ratio and Annual Return (ARC) indicate risk-adjusted and average performance, respectively,
while Annual Standard Deviation (ASD) reflects volatility, Max Drawdown captures the largest peak-to-trough equity
decline, and Calmar Ratio measures risk-adjusted return relative to maximum drawdown.

### **8 Conclusion**


In this study, the hybrid SV-LSTM model was proposed and evaluated alongside benchmark models, namely its standalone components: the LSTM and the SV model.
The methodology of the introduced SV-LSTM model consisted of two parts. Firstly,
predictions for day t+1 were generated by utilizing the statistical SV model, which was
trained on log returns from December 1998 to January 2024 with a 504-day rolling window.
This stage utilized daily close price for the S&P 500 index, covering the period from
January 1, 1998, to December 31, 2024, obtained from Yahoo Finance.
The second stage involved using the latent volatility estimates generated by SV model
as inputs for the LSTM network. Since the SV estimation is based on the closing prices
for the last two years, the prediction for day t+1 is obtained at the same timestep as the
closing price for the respective day t. This allowed the latent estimates to be retrieved and
treated as input data for the LSTM model for day t, along with logarithmic returns and
21-day rolling volatility estimates. In addition, the 21-day rolling volatility estimates were
also set as the target for the LSTM model part. After the process of tuning and training,
the LSTM part of the model produced the prediction for the 21-day rolling volatility of
the S&P 500 for day t+1.
The error metrics demonstrated the superiority of the SV-LSTM model over both the
LSTM and SV models. Additionally, the Diebold-Mariano (DM) test confirmed that the
SV-LSTM model exhibits better predictive accuracy than both benchmark models. Furthermore, the Wilcoxon statistical tests indicated that the distribution of errors between
the SV and SV-LSTM models is significantly different, whereas no significant difference
was found between the SV-LSTM and LSTM models. The lack of the difference between
the error distributions produced by both LSTM and SV-LSTM models can be explained
by the shared LSTM core of prediction forecast as the last part of the model workflow,
demonstrating shared limitations of the LSTM model that remained unresolved, identifying the ground for potential future research.
The investment strategy simulation further validated the practical relevance of the SVLSTM model by assessing its performance on VIX futures data spanning from 2014 to 2024
in a realistic market environment. Given the underperformance of signal strategies based
on models calibrated with conventional error metrics, the incorporation of the MADL
loss function was undertaken. The results indicate that modifying the compilation loss
function enhanced the signal strategy’s performance relative to the original Hybrid SVLSTM model. This outcome underscores the importance of further research into loss
functions that are better optimized for LSTM and other neural network models within


29


applied financial contexts. Collectively, these findings highlight the value of integrating
stochastic signals into neural architectures and suggest that future improvements could
be achieved by refining neural network designs that balance classical statistical accuracy
with practical trading effectiveness.
Exploring the sensitivity of the model to additional manipulations, it was found that
shorter sequences reduce accuracy in opposition to the baseline of 21 days. This suggested
that 21 days offers enough information for better predictability of the model, while the sequence of 5 days limits the amount of information and prevents the model from effectively
learn short-term dynamics. Moreover, the data preprocessing part was also analyzed, and
it was found that both standard and robust scaling improve the model forecast in contrast
to the baseline min-max scaling, suggesting that data preprocessing options for machine
learning models could be further explored.
The main limitation encountered in this work was the high computational cost of
training each model, as every machine learning model underwent hyperparameter tuning
across all rolling windows of training and validation data.
The following conclusions are drawn from the hypothesis testing conducted in this
study:


  - H1: The results show that the inclusion of stochastic volatility forecasts for day t+1
enhances the predictive accuracy of the LSTM model.


  - H2: Augmenting the input data of the LSTM model with external information
beyond historical returns was proven to improve its forecasting performance.


  - H3: The comparative metrics analysis showed that the hybrid SV-LSTM model
delivers enhanced volatility forecasts compared to the standalone SV model.


In addition to the main hypotheses, the following secondary research questions underwent
investigation:


  - RQ1 Increasing the dimensionality of inputs from the SV model further enhances
the predictive performance of the hybrid model.


  - RQ2 The change of data preprocessing scaling from min-max to either standard or
robust scaling improved the performance of the SV-LSTM model.


  - RQ3 The decreased sequence of the input data into the LSTM model was shown to
not leverage the SV-LSTM prediction accuracy.


This study made a contribution to financial modelling by introducing and evaluating
the combination of a statistical SV model as an input into a machine learning LSTM
model. This approach allows the model to capture unpredictable market dynamics by
incorporating the latent stochastic process and nonlinear dependencies in financial time
series. The simulation of investment strategy alongside the sensitivity analysis provided
practical insights into the application of the presented model.
The hybrid SV-ML framework could be expanded in a number of ways in future
studies. One approach involves feeding machine learning models with different outputs
from the stochastic volatility model, such as latent states or predictive densities. Directly
incorporating machine learning into the SV estimation procedure is another promising
approach that could lessen the need for large-scale sampling by substituting effective
approximators for computationally demanding simulations. Adaptability may also be


30


improved by further research into more complex hybrid structures, such as fusing LSTM
with more specialized SV models. Model stability may be increased by standardizing ML
hyperparameters across windows.

### **References**


Bahadori, M. T. and Z. C. Lipton (2019). “Deep Learning for Financial Time Series
Forecasting”. In: _arXiv preprint arXiv:1807.02787_ .
Black, F. and M. Scholes (1973). “The Pricing of Options and Corporate Liabilities”. In:
_Journal of Political Economy_ 81.3, pp. 637–654. doi: `[10.1086/260062](https://doi.org/10.1086/260062)` .
Bollerslev, T. (1986). “Generalized Autoregressive Conditional Heteroskedasticity”. In:
_Journal of Econometrics_ 31.3, pp. 307–327. doi: `[10.1016/0304-4076(86)90063-1](https://doi.org/10.1016/0304-4076(86)90063-1)` .
Breidt, F. Jay, Nuno Crato, and Pedro de Lima (1998). “The Detection and Estimation of
Long Memory in Stochastic Volatility”. In: _Journal of Econometrics_ 83.1-2, pp. 325–
348. doi: `[10.1016/S0304-4076(97)00072-1](https://doi.org/10.1016/S0304-4076(97)00072-1)` .
Bucci, A. (2020). “Realized Volatility Forecasting with Neural Networks”. In: _Journal of_
_Financial Econometrics_ 18.3, pp. 502–531. doi: `[10.1093/jjfinec/nbz009](https://doi.org/10.1093/jjfinec/nbz009)` .
Diebold, F. X. and R. S. Mariano (Jan. 2002). “Comparing Predictive Accuracy”. In: _Jour-_
_nal of Business & Economic Statistics_ 20.1, pp. 134–144. doi: `[10.1198/073500102753410444](https://doi.org/10.1198/073500102753410444)` .
Engle, R. F. (1982). “Autoregressive Conditional Heteroskedasticity with Estimates of
the Variance of United Kingdom Inflation”. In: _Econometrica_ 50.4, pp. 987–1007. doi:
`[10.2307/1912773](https://doi.org/10.2307/1912773)` .

- (2001). “GARCH 101: The Use of ARCH/GARCH Models in Applied Econometrics”.
In: _Journal of Economic Perspectives_ 15.4, pp. 157–168. doi: `[10.1257/jep.15.4.157](https://doi.org/10.1257/jep.15.4.157)` .
Grudniewicz, S. and R. Slepaczuk (2023). “Application of machine learning in algorithmic
investment strategies on global stock markets”. In: _Research in International Business_
_and Finance_ 66.102052. doi: `[10.1016/j.ribaf.2023.102052](https://doi.org/10.1016/j.ribaf.2023.102052)` .
Heston, S. L. (1993). “A Closed-Form Solution for Options with Stochastic Volatility
with Applications to Bond and Currency Options”. In: _Review of Financial Studies_
6.2, pp. 327–343. doi: `[10.1093/rfs/6.2.327](https://doi.org/10.1093/rfs/6.2.327)` .
Hochreiter, S. and J. Schmidhuber (1997). “Long Short-Term Memory”. In: _Neural Com-_
_putation_ 9.8, pp. 1735–1780. doi: `[10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735)` .
Kilic, R. (2011). “Long memory and nonlinearity in conditional variances: A smooth transition FIGARCH model”. In: _Journal of Empirical Finance_ 18.3, pp. 368–378. doi:
`[10.1016/j.jempfin.2011.02.001](https://doi.org/10.1016/j.jempfin.2011.02.001)` .
Kim, H. Y. and C. H. Won (2018). “Forecasting the volatility of stock price index: A hybrid
model integrating LSTM with multiple GARCH-type models”. In: _Expert Systems with_
_Applications_ 103, pp. 25–37. doi: `[10.1016/j.eswa.2018.03.002](https://doi.org/10.1016/j.eswa.2018.03.002)` .
Kim, S., N. Shephard, and S. Chib (1998). “Stochastic Volatility: Likelihood Inference and
Comparison with ARCH Models”. In: _Review of Economic Studies_ 65.3, pp. 361–393.
doi: `[10.1111/1467-937X.00050](https://doi.org/10.1111/1467-937X.00050)` .
Michańków, J., P. Sakowski, and R. Ślepaczuk (2022). “LSTM in Algorithmic Investment
Strategies on BTC and S&P500 Index”. In: _Sensors_ 22.3, p. 917. doi: `[10.3390/](https://doi.org/10.3390/s22030917)`
`[s22030917](https://doi.org/10.3390/s22030917)` .
Michańków, Jakub, Paweł Sakowski, and Robert Ślepaczuk (2023). “Mean Absolute Directional Loss as a New Loss Function for Machine Learning Problems in Algorithmic Investment Strategies”. In: _arXiv preprint arXiv:2309.10546_ abs/2309.10546. url:
`[https://arxiv.org/abs/2309.10546](https://arxiv.org/abs/2309.10546)` .


31


Nelson, D. B. (1991). “Conditional Heteroskedasticity in Asset Returns: A New Approach”.
In: _Econometrica_ 59.2, pp. 347–370. doi: `[10.2307/2938260](https://doi.org/10.2307/2938260)` .
Nguyen, N. et al. (2019). “A long short-term memory stochastic volatility model”. In:
_arXiv preprint arXiv:1906.02884_, p. 120.
Roszyk, K. and R. Ślepaczuk (2024). “The Hybrid Forecast of S&P 500 Volatility ensembled from VIX, GARCH and LSTM models”. In: _arXiv preprint arXiv:2407.16780_ .
Taylor, S. J. (1982). “Financial Returns Modelled by the Product of Two Stochastic
Processes - A Study of Daily Sugar Prices 1961-79”. In: _Time Series Analysis: Theory_
_and Practice_ 1, pp. 203–226.

- (1986). _Modelling Financial Time Series_ . John Wiley & Sons.
Wilcoxon, F. (Dec. 1945). “Individual Comparisons by Ranking Methods”. In: _Biometrics_
_Bulletin_ 1.6, pp. 80–83. doi: `[10.2307/3001968](https://doi.org/10.2307/3001968)` .
Yu, J. (2002). “Forecasting volatility in the New Zealand stock market”. In: _Applied Fi-_
_nancial Economics_ 12.3, pp. 193–202. doi: `[10.1080/09603100110088094](https://doi.org/10.1080/09603100110088094)` .


32


