## **Beyond Hard Writes and Rigid Preservation:** **Soft Recursive Least-Squares for Lifelong LLM Editing**

**Xinyu Wang** [1] _[,]_ [3] _[∗]_, **Sicheng Lyu** [1] _[,]_ [2] _[,]_ [3] _[∗]_, **Yu Gu** [1] _[∗]_, **Jerry Huang** [2] _[,]_ [4], **Peng Lu** [4],
**Yufei Cui** [1] _[,]_ [2], **Xiao-Wen Chang** [1] _[†]_

1McGill University, 2Mila—Quebec AI Institute, 3SimpleWay.AI, 4Universit´e de Montr´eal
_{_ xinyu.wang5, sicheng.lyu, yu.gu4 _}_ @mail.mcgill.ca, chang@cs.mcgill.ca



**Abstract**


Model editing updates a pre-trained LLM with new
facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a _plasticity–stability dilemma_ : locate-thenedit “hard writes” can accumulate interference over
time, while null-space–style “hard preservation”
preserves only what is explicitly constrained, so
past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities
in the many-edits regime.

We propose **RLSEdit**, a recursive least-squares
editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with _soft constraints_, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pretrained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with peredit cost independent of history length and scaling
only with the current edit size. We further provide
deviation bounds and an asymptotic characterization of the adherence–preservation trade-off in the
many-edits regime.

Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming
strong baselines in both edit success and holistic
stability – crucially retaining early edits, and preserving general capabilities on GLUE and held-out
reasoning/code benchmarks.

[Code is available at https://github.com/Euphoria0](https://github.com/Euphoria040201/RLSEdit)
[40201/RLSEdit](https://github.com/Euphoria040201/RLSEdit)


**1** **Introduction**


Despite the large amount of knowledge they store within
their parameters, large language models (LLMs) [Yang


_∗_ Equal contribution.

_†_ Corresponding author.



et al., 2024, OpenAI, 2023, DeepSeek-AI et al., 2025] inevitably contain outdated, incomplete, or incorrect knowledge [De Cao et al., 2021, Mitchell et al., 2022] when
statically deployed without re-training or access to external
knowledge bases. Due to the large computational cost incurred if re-training from scratch, many applications necessitate updating models using _edits_ to a subset of parameters in order to integrate new facts or rules while preserving general model behavior [Meng et al., 2022]. While early
model editors largely focused on single or small-batch updates, practical deployments are inherently sequential: edits
arrive continuously, with the editor remaining reliable after
each edit [Hartvigsen et al., 2023, Gupta et al., 2024].
The many-edits regime presents a dilemma for models. To
remain useful over long streams, they must both memorize
the information in the stream, all the while preserving the
knowledge previously acquired within it. In practice, failures
often manifest as two coupled forms of forgetting:


1. _Retroactive Edit Forgetting_ : Future edits can overwrite
ones applied in the past.


2. _General-Ability Degradation_ : Edits lead to deterioration
of out-of-scope reasoning and language understanding.


Existing sequential editors typically fail for complementary reasons. _Locate-then-edit_ approaches [Meng et al., 2022,
2023] perform _hard writes_, forcing the model to learn the new
associations with little regard for previously contained knowledge and potentially overwriting it. As the number of edits
accumulates, so does the number of overwrites, leading to instability and retroactive forgetting of previously learnt facts.
Conversely, _null-space_ editors [Fang et al., 2025, Sun et al.,
2025] projects updates into a feasible subspace conditioned
on an anchor mapping, preserves associations defined by it.
However, edits are repeatedly applied; maintaining complete
knowledge leads to a growing set of constraints to be satisfied, leading to difficulty in satisfying them all, while loosening them can lead to possible degradation in general abilities
or retention of facts. As a consequence, neither paradigm is
sufficient for repeated or sequential editing.
Alternatively, one can view sequential editing as _online_
_regularized least-squares_ on a layer-wise key-value surrogate [Sayed, 2003]. Each edit contributes a quadratic fitting
term, with preservation achieved through two explicit _devia-_
_tion controllers_ : one accounting for deviation from the ini

tial model, and another penalizing for deviation from a designated _anchor mapping_ . This yields a soft constraint formulation: learning new edits and preserving previous knowledge are optimized within a single objective, avoiding hard
constraints while ensuring long-run stability. From this, we
propose **RLSEdit**, a recursive least-squares editor for long
sequential editing that uses a quadratic objective to admit an
efficient online recursion via the Woodbury identity [Sherman and Morrison, 1950, Woodbury, 1950, Hager, 1989].
RLSEdit scales _independently of the number of prior edits_
and instead with the current edit rank/size, with theoretical deviation bounds and an asymptotic characterization that
highlights the suitability of **RLSEdit** for long streams of edits. To summarize our main contributions, we:

- Motivate **a** **soft-constraint** **long-sequential** **editing**
**framework** by formulating lifelong editing as online
regularized least squares with explicit parameter-deviation
and anchor-deviation controls, systematically interpolating
between the “hard write” and “hard preserve” extremes.

- **Derive a Woodbury-based online update** with per-edit
cost independent of past edit count.

- **Justify stability and preservation of information** by deriving bounds and an asymptotic characterization.

- Provide empirical evidence on Llama-3 [Dubey et al.,
2024] and Qwen2.5 [Yang et al., 2024] after 10K edits to
show **stronger edit success, improved early-edit reten-**
**tion, and better preservation of general capabilities** on
held-out reasoning and code benchmarks.


**2** **Related Work**

We review model editing methods through a _soft versus hard_
_constraint_ lens. We would like to explain how different editing methods balance between **effectively making new edits**
and **preserving previous edits and knowledge**, as well as
explain why long-sequential editing can be challenging. In
particular, we consider **layer-wise input-output pairs**, where
we edit a single linear map in layer _ℓ_ (e.g., an attention projection). Given an input prompt, we run a forward pass and
collect a set of module-level _input-output_ feature pairs ( _**k**_ _,_ _**v**_ )
at selected token positions, where _**k**_ _∈_ R _[d][k]_ is the input activation to the edited map and _**v**_ _∈_ R _[d][v]_ is the corresponding
output activation. For the _t_ -th edit, we stack _ut_ such pairs to
form _**K**_ _t ∈_ R _[u][t][×][d][k]_ and _**V**_ _t ∈_ R _[u][t][×][d][v]_ .
**The Writing and Preservation Trade-off.** The goal of
editing is to perform targeted updates to the model parameters to learn new key-value associations. With soft or no
direct constraint on how this changes the parameters, this can
be expressed as a constrained LS problem:


_**W**_ - _∈_ arg min _∥_ _**KW**_ _−_ _**V**_ _∥_ [2] _F_ s.t. _**K**_ _[⋆]_ _**W**_ = _**V**_ _[⋆]_ _._ (1)
_**W**_


Here ( _**K**_ _,_ _**V**_ ) denotes the current key-value associations contained within the model parameters, and ( _**K**_ _[⋆]_ _,_ _**V**_ _[⋆]_ ) denotes
the edit constraints defined by the new set of edits.
Alternatively, one can attempt to preserve greater amounts
of existing knowledge by restricting updates to a feasible subspace so that performance on a _designated preservation set_



(e.g., an anchor/background mapping) remains unchanged.
This can be expressed as

min∆ _t_ _[∥]_ _**[K]**_ _[t]_ [(] _**[W]**_ _[t][−]_ [1] [+∆] _[t]_ [)] _[−]_ _**[V]**_ _[t][∥]_ _F_ [2] [(+] _[λR]_ [(] _[·]_ [))][ s.t.] _**[ K]**_ [pres] _[,t]_ [∆] _[t]_ [ =0] _[.]_ [ (2)]


This leads to a _soft_ update to fit the model parameters to satisfy the preservation constraints. In ALPHAEDIT [Fang et al.,
2025], _**K**_ pres _,t_ is typically fixed to a chosen anchor/background set, preserving only what is explicitly constrained.
LANGEDIT [Sun et al., 2025] retains the same principle but
updates multilingual preservation statistics online, so that
_**K**_ pres _,t_ (and the induced projector) evolves over time.
**Moving to Longer Edit Streams.** When only a single
batch of edits needs to be applied, existing editing methods
have shown strong performance. However, such settings are
not fully representative of the real-world use cases of LLMs.
Models often exist in environments where they are ideally
deployed for significant periods of time, where the number
of edits that need to be applied repeatedly is large. In such
longer edit streams, existing methods can suffer for a multitude of reasons: hard satisfaction of each batch can induce
growing interference between the incoming edits and prior
knowledge, leading to retroactive forgetting and degradation
in out-of-scope performance, while attempting to preserve
too much prior knowledge can lead to insufficient learning
of new associations.

**Soft Updates with Preservation.** MEMIT [Meng et al.,
2023] uses a soft LS objective over a batch of past and new
associations, but is not formulated as a long-stream sequential
objective. To address the long-edit stream setting, we enforce
_soft_ adherence and preservation within a quadratic objective
that encompasses both hard regimes as limiting cases.

**Beyond Direct Parameter Writes.** Several recent lines
are orthogonal to direct streaming parameter updates.
ANYEDIT [Jiang et al., 2025] broadens the scope of editable knowledge beyond simple factual statements, while
UNKE [Deng et al., 2025] targets unstructured knowledge.
For lifelong settings, WISE [Wang et al., 2024] separates
edited knowledge from pre-trained knowledge via dual memories and routing, and RECIPE [Chen et al., 2024] externalizes updates as retrieval-augmented continuous prompts with
gating. These approaches trade additional components memory/retrieval/prompting) for scalability and locality, and are
complementary to our focus on an efficient, single-objective
streaming parameter editor.


**3** **Methodology**

We present our editing framework in three parts. We first introduce a recursive least-squares (RLS) formulation that adds
up all editing residuals quadratically in the objective function, with penalties over deviation from both the initial model
parameters and anchor mapping (Section 3.1). We then analyze the computational complexity of the resulting updates
and compare them with exisiting sequential editors under a
long-edit stream (Section 3.2). Finally, we provide a unified
perspective by contrasting _soft_ and _hard_ constraint designs.
This shows how existing editors act as special cases of our
formulation (Section 3.3).


**3.1** **A recursive least squares editor**
**Setup** We consider editing a single linear map _**W**_ _∈_ R _[d][k][×][d][v]_
(e.g., a projection matrix in a transformer layer). Each edit
provides a set of key-value constraints ( _**K**_ _t,_ _**V**_ _t_ ) where _**K**_ _t ∈_
R _[u][t][×][d][k]_ and _**V**_ _t ∈_ R _[u][t][×][d][v]_ with _ut_ being the number of contexts collected for the _t_ -th edit. Layer-wise edit adherence
is measured by the residual _∥_ _**K**_ _t_ _**W**_ _−_ _**V**_ _t∥F_ . The goal of our
method is two-fold. First, it should incorporate _all_ edits up to
time _t_ . Second, deviation from the initial weights (i.e. _**W**_ 0)
and from the anchor pairs (e.g. ( _**K**_ 0 _,_ _**V**_ 0)) should be controlled, thus we introduce two regularization terms to enforce
these constraints.


**Regularized Least-Squares Equation**
At time _t_, our objective is to obtain the optimal weight _**W**_ _t_ _[∗]_
that minimizes:

















_**W**_ _t_ _[∗]_ [:= arg min]
_**W**_



_t_

- _∥_ _**K**_ _i_ _**W**_ _−_ _**V**_ _i∥_ [2] _F_

_i_ =1



Figure 1: **The recursive workflow of our RLS-Woodbury editor.**
The process alternates between updating the covariance state via the
Woodbury identity (Phase 1) and updating weights (Phase 2). The
highlighted block shows how we reduce complexity from _O_ - _d_ [3] _k_ - to
_O_ - _d_ [2] _k_ _[u][t]_ - by solving small _ut_ _×ut_ systems.


If we define _**C**_ _t_ as the inverse of _**S**_ _t_ and using Equation (6),

_**C**_ _t_ _[−]_ [1] = _**C**_ _t_ _[−]_ _−_ 1 [1] [+] _**[ K]**_ _t_ _[⊤]_ _**[K]**_ _[t][.]_ (10)


Next, let
_**F**_ _t_ := _**C**_ _t−_ 1 _**K**_ _t_ _[⊤]_ _[∈]_ [R] _[d][k][×][u][t][.]_
By the Sherman-Morrison-Woodbury identity,

_**C**_ _t_ = _**C**_ _t−_ 1 _−_ _**F**_ _t_ ( _**I**_ _ut_ + _**K**_ _t_ _**F**_ _t_ ) _[−]_ [1] _**F**_ _t_ _[⊤][.]_ (11)


A numerically stable and efficient implementation is obtained by a Cholesky factorization _**I**_ _ut_ + _**K**_ _t_ _**F**_ _t_ = _**R**_ _t_ _[⊤]_ _**[R]**_ _[t]_
and triangular solves, avoiding explicit inverses. From Equation (7), a normal-equation manipulation yields the final form
of **RLSEdit** at time step _t_ :

_**W**_ _t_ _[∗]_ [=] _**[ W]**_ _t_ _[ ∗]_ _−_ 1 [+] _**[ C]**_ _[t]_ _**[K]**_ _t_ _[⊤]_   - _**V**_ _t −_ _**K**_ _t_ _**W**_ _t_ _[∗]_ _−_ 1� _,_ (12)

where _**R**_ _t_ := _**V**_ _t −_ _**K**_ _t_ _**W**_ _t_ _[∗]_ _−_ 1 [. As a result, each edit requires]
only (i) updating _**C**_ _t_ via Equation (11), and (ii) updating _**W**_ _t_ _[∗]_
via Equation (12).


**3.2** **Complexity analysis**
We report the per-edit cost at step _t_ . Multiplying _**M**_ _∈_ R _[m][×][n]_
and _**N**_ _∈_ R _[n][×][p]_ costs _O_ ( _mnp_ ), and solving a dense _n × n_
linear system costs _O_ ( _n_ [3] ).


**RLS-Woodbury Updates.**
RLSEdit maintains _**C**_ _t_ = _**S**_ _t_ _[−]_ [1] _∈_ R _[d][k][×][d][k]_ and updates it via
Woodbury using

_**F**_ _t_ = _**C**_ _t−_ 1 _**K**_ _t_ _[⊤]_ _[∈]_ [R] _[d][k][×][u][t][,]_ _**S**_ _t_ = _**I**_ _ut_ + _**K**_ _t_ _**F**_ _t ∈_ R _[u][t][×][u][t]_ _._


The covariance-state update is dominated by forming these
products and solving the resulting _ut × ut_ system, yielding

**(1) Covariance update:** _O_   - _d_ [2] _k_ _[u][t]_   - + _O_   - _u_ [3] _t_   - _._



+ _λ_ [2] _∥_ _**W**_ _−_ _**W**_ 0 _∥_ [2] _F_
+ _µ_ [2] _∥_ _**K**_ 0 _**W**_ _−_ _**V**_ 0 _∥_ [2] _F_ _[,]_



(3)



where _∥_ _**W**_ _−_ _**W**_ 0 _∥_ [2] _F_ [and] _[ ∥]_ _**[K]**_ [0] _**[W]**_ _[ −]_ _**[V]**_ [0] _[∥]_ _F_ [2] [are the regulariza-]
tion terms, _λ_ and _µ_ are hyperparameters.
To find the minimizer, define

_**A**_ _t_ =   - _λ_ _**I**_ _dk_ ; _µ_ _**K**_ 0 _[⊤]_ [;] _**[ K]**_ 1 _[⊤]_ [;] _[ . . .]_ [ ;] _**[ K]**_ _t_ _[⊤]_   - _⊤_ _,_

(4)
_**B**_ _t_ =   - _λ_ _**W**_ 0 _[⊤]_ [;] _[ µ]_ _**[V]**_ 0 _[ ⊤]_ [;] _**[ V]**_ 1 _[ ⊤]_ [;] _[ . . .]_ [ ;] _**[ V]**_ _t_ _[ ⊤]_   - _⊤_ _._


Then we could reformulate Equation (3) to an equivalent
form:
_**W**_ _t_ _[∗]_ [= arg min] _∥_ _**A**_ _t_ _**W**_ _−_ _**B**_ _t∥_ [2] _F_ _[.]_ (5)
_**W**_


To derive a closed form solution to Equation (5), first let



_**S**_ _t_ := _**A**_ _[⊤]_ _t_ _**[A]**_ _[t]_ [=] _[ λ]_ [2] _**[I]**_ [ +] _[ µ]_ [2] _**[K]**_ 0 _[⊤]_ _**[K]**_ [0] [+]



_t_

- _**K**_ _i_ _[⊤]_ _**[K]**_ _[i][,]_ (6)

_i_ =1



_**T**_ _t_ := _**A**_ _[⊤]_ _t_ _**[B]**_ _[t]_ [=] _[ λ]_ [2] _**[W]**_ [0] [+] _[ µ]_ [2] _**[K]**_ 0 _[⊤]_ _**[V]**_ [0] [+]



_t_

- _**K**_ _i_ _[⊤]_ _**[V]**_ _[i][.]_ (7)

_i_ =1



When _λ >_ 0, we have _**A**_ _[⊤]_ _t_ _**[A]**_ _[t]_ _[≻]_ [0][, and Equation (5) admits]
a unique closed-form least-squares solution given by the normal equations _**A**_ _[⊤]_ _t_ _**[A]**_ _[t]_ _**[W]**_ [ =] _**[ A]**_ _t_ _[⊤]_ _**[B]**_ _[t]_ [. Hence, the solution is]
given by
_**W**_ _t_ _[∗]_ [=] _**[ S]**_ _t_ _[−]_ [1] _**T**_ _t._ (8)
By jointly solving the unified objective Equation (5), this
minimizer not only update the current knowledge pairs
( _**K**_ _t,_ _**V**_ _t_ ), but also force the solution close to the original
weights _**W**_ 0 and ensure the anchor mappings _**K**_ 0 _**W**_ _�→_ _**V**_ 0.


**Efficient Recursion via Normal Equations**
Direct computation of Equation (8) requires obtaining the inverse of matrix _**S**_, which is expensive in practice. Therefore, we develop an efficient recursive solution. From Equation (8), the minimizer _**W**_ _t_ _[∗]_ [satisfies]

        - _**A**_ _[⊤]_ _t_ _**[A]**_ _[t]_         - _**W**_ _t_ _[∗]_ [=] _**[ A]**_ _t_ _[⊤]_ _**[B]**_ _[t][.]_ (9)


**Algorithm 1** RLS-Woodbury Editing


**Require:** Initial weight _**W**_ 0; Anchor pair ( _**K**_ 0 _,_ _**V**_ 0); Penalties ( _λ, µ_ ); Edit stream _{_ ( _**K**_ _t,_ _**V**_ _t_ ) _}_ _[T]_ _t_ =1 [.]
**Ensure:** Edited weights _{_ _**W**_ _t}_ _[T]_ _t_ =1 [(optional: states] _[ {]_ _**[C]**_ _[t][}]_ [).]
1: _**S**_ 0 _←_ _λ_ [2] _**I**_ _dk_ + _µ_ [2] _**K**_ 0 _[⊤]_ _**[K]**_ [0]
2: _**S**_ 0 = _**R**_ 0 _[⊤]_ _**[R]**_ [0] _▷_ Cholesky factor _**R**_ 0 upper triangular
3: _**C**_ 0 _←_ _**S**_ 0 _[−]_ [1] _▷_ Via triangular solves using _**R**_ 0
4: _**W**_ 0 _←_ _**W**_ 0 _▷_ Initialize current weight estimate
5: **for** _t_ = 1 _,_ 2 _, . . ., T_ **do**



**(1) Covariance update (Woodbury)**
6: _**F**_ _t ←_ _**C**_ _t−_ 1 _**K**_ _t_ _[⊤]_ _▷_ _**F**_ _t ∈_ R _[d][k][×][u][t]_

7: _**S**_ _t ←_ _**I**_ _ut_ + _**K**_ _t_ _**F**_ _t_ _▷_ _**S**_ _t ∈_ R _[u][t][×][u][t]_

8: _**S**_ _t_ = _**R**_ _t_ _[⊤]_ _**[R]**_ _[t]_ _▷_ Cholesky factor _**R**_ _t_ upper triangular
9: _**Y**_ _t ←_ _**F**_ _t_ _**R**_ _t_ _[−]_ [1] _▷_ Triangular solve: _**Y**_ _t_ = _**F**_ _t_ _**R**_ _t_ _[−]_ [1]
10: _**C**_ _t ←_ _**C**_ _t−_ 1 _−_ _**Y**_ _t_ _**Y**_ _t_ _[⊤]_ _▷_ Update inverse covariance
**(2) Weight update**
11: _**E**_ _t ←_ _**V**_ _t −_ _**K**_ _t_ _**W**_ _t−_ 1 _▷_ Prediction error for edit _t_
12: _**G**_ _t ←_ _**F**_ _t_ _**S**_ _t_ _[−]_ [1] _▷_ Gain matrix, reusing _**S**_ _t_ (via
triangular solves)
13: _**W**_ _t ←_ _**W**_ _t−_ 1 + _**G**_ _t_ _**E**_ _t ▷_ Apply correction to weights
14: **end for**
15: **return** _**W**_ _T_ (and _**C**_ _T_ )


For the weight update, we reuse the same _ut × ut_ solve to
apply the gain _**G**_ _t_ = _**C**_ _t_ _**K**_ _t_ _[⊤]_ _∈_ R _[d][k][×][u][t]_ and update _**W**_ _t_ using the residual _**E**_ _t_ . This step is dominated by the key–value
multiplication against _dv_ outputs, giving

**(2) Weight update:** _O_ ( _dkdvut_ ) + _O_   - _dku_ [2] _t_   - _._


Overall, the per-edit runtime is therefore

**(Per-edit)** _O_      - _d_ [2] _k_ _[u][t]_ [+] _[ d][k][d][v][u][t]_ [+] _[ u]_ [3] _t_      - _,_

which simplifies to _O_ - _d_ [2] _k_ _[u][t]_ [ +] _[ d][k][d][v][u][t]_ - when _ut ≪_ _dk, dv_ .


**Comparison to other sequential editors.**
For a fair long-sequential comparison, we focus on exisiting
sequential editors. ALPHAEDIT introduces _hard preserva-_
_tion_ by projecting the change of weight onto the null space
of a fixed _preserved-knowledge_ set (denoted by _**K**_ 0), i.e., it
applies a projector _**P**_ (e.g., _**P**_ = _I −_ _**QQ**_ _[⊤]_ ) so that the projected update does not affect _**K**_ 0 _W_ . In sequential editing, it
additionally regularizes against disrupting _previously updated_
_knowledge_ represented by ( _**K**_ _p,_ _**V**_ _p_ ). The resulting closedform update can be written as


       -        - _−_ 1
∆ _t_ = _**R**_ _t_ _**K**_ _t_ _[⊤]_ _**[P]**_ _**K**_ _p_ _**K**_ _p_ _[⊤]_ _**[P]**_ [ +] _**[ K]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ _**[P]**_ [ +] _[ I]_ _,_


and the corresponding baseline (e.g., MEMIT in sequential
setting) removes _**P**_ and adds _**K**_ 0 _**K**_ 0 _[⊤]_ [inside the inverse. Let]
_mt−_ 1 denote the number of previously updated pairs accumulated in _**K**_ _p_ and let _ut_ denote the number of pairs in the
current edit ( _**K**_ _t ∈_ R _[u][t][×][d][k]_ ). The dominant cost in ALPHAEDIT is inverting the dense _dk × dk_ matrix _**M**_ _t_ :=
_**K**_ _p_ _**K**_ _p_ _[⊤]_ _**[P]**_ [ +] _**[K]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ _**[P]**_ [ +] _[I]_ [, which costs] _[ O]_ [(] _[d]_ _k_ [3][)][ per edit. Form-]
ing the two Gram terms costs _O_ - _d_ [2] _k_ [(] _[m][t][−]_ [1][ +] _[ u][t]_ [)] �, and the
remaining multiplications are lower order. Hence,

**(Per-edit)** _O_ ( _d_ [3] _k_ [) +] _[ O]_    - _d_ [2] _k_ [(] _[m][t][−]_ [1] [+] _[ u][t]_ [)]    - _._



In contrast, RLSEdit avoids any _O_ ( _d_ [3] _k_ [)][ factorization during]
the edit stream by maintaining _**C**_ _t_ = ( _**A**_ _[⊤]_ _t_ _**[A]**_ _[t]_ [)] _[−]_ [1][ and using a]
Woodbury recursion, requiring only a _ut × ut_ Cholesky per
edit, which depends only on the current edit size _ut_ (typically
_ut ≪_ _dk_ ) and is therefore substantially more efficient in practical long-edit tasks, as shown in Table 2.


**3.3** **Hard versus Soft Constraints**

**(I) Versus locate-then-edit editors.** As reviewed in Section 2, editors such as ROME and MEMIT are one-shot (or
batched) key–value _writes_ : they find a single edited weight
_**W**_ - by fitting a LS objective on a background set while enforcing the new associations exactly.
ROME assumes the pre-trained weight _**W**_ to be a LS fit on
background pairs ( _**K**_ bg _,_ _**V**_ bg) and obtains the edited weight
by imposing the new edit as a hard constraint:


_**W**_ - =arg min _∥_ _**K**_ bg _**W**_ _−_ _**V**_ bg _∥_ [2] _F_ [s.t.] _**[ K]**_ [edit] _**[W]**_ [ =] _**[V]**_ [edit] _[.]_ [ (13)]
_**W**_


MEMIT extends this to batched edits by fitting a single LS
problem on the background pairs together with the new pairs,
but it still outputs one edited weight and is not naturally a
sequential method.


**(II) Versus null-space editors.** Null-space editors (e.g.,
ALPHAEDIT, LANGEDIT) instead enforce _hard_ preservation
of a chosen preservation set. Each increment ∆ _t_ is restricted
to a feasible subspace, and the current edit is fitted inside that
subspace:

min∆ _t_ _∥_ _**K**_ _t_ ( _**W**_ _t−_ 1 + ∆ _t_ ) _−_ _**V**_ _t∥_ [2] _F_ [(+][regularization][)] (14)

s.t. _**K**_ pres _,t_ ∆ _t_ = 0 _⇐⇒_ ∆ _t ∈_ Null( _**K**_ pres _,t_ ) _._


This hard constraint preserves the specified keys, but the feasible subspace can shrink as _t_ grows. The best feasible update
may thus deviate from the unconstrained optimum and limit
long-run edit adherence.


_Remark_ 3.1 _._ Write _**W**_ = _**W**_ + ∆ in Equation (13). Since

[�]
_**K**_ bg _**W**_ _≈_ _**V**_ bg, the ROME update is, up to constants,


min _∥_ _**K**_ bg∆ _∥_ [2] _F_ [s.t.] _**[ K]**_ [edit][∆=] _**[ V]**_ [edit] _[−]_ _**[K]**_ [edit] _**[W]**_ _[,]_
∆


which has a _hard write / soft preserve_ structure: the new association is enforced exactly, while background deviation is
only softly penalized. Null-space editors reverse this: they
preserve the chosen set exactly and fit the current edit softly
inside the feasible subspace.
Our RLS editor keeps, assuming finite _µ_ and _λ_, both sides
_soft_ via a single cumulative objective:



+ _λ_ [2] _∥_ _**W**_ _−_ _**W**_ 0 _∥_ [2] _F_ [+] _[ µ]_ [2] _[ ∥]_ _**[K]**_ [0] _**[W]**_ _[ −]_ _**[V]**_ [0] _[∥]_ _F_ [2] _[.]_


In the limit, our method reduces to these hard-constraint
methods. Letting _µ →∞_ enforces a hard anchor constraint
_**K**_ 0 _**W**_ = _**V**_ 0. More generally, multiplying selected past fitting terms _∥_ _**K**_ _i_ _**W**_ _−_ _**V**_ _i∥_ [2] _F_ [by a factor] _[ ρ][ →∞]_ [recovers hard]



_**W**_ _t_ _[⋆]_ [= arg min]
_**W**_



_t_

- _∥_ _**K**_ _i_ _**W**_ _−_ _**V**_ _i∥_ [2] _F_

_i_ =1



(15)


_In addition, the adaptive spectral variant_

_∥_ _**K**_ 0 ( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][)] _[∥]_ _F_



_λ_ [2] + _µ_ [2] _σ_ min [2] [(] _**[K]**_ [0][) +]



_≤_



_T_



_t_ =1



_∥_ _**K**_ 0 _∥_ 2 _∥_ _**K**_ _t∥_ 2 _∥_ _**R**_ _t∥F_







_t_

- _σ_ min [2] [(] _**[K]**_ _[i]_ [)]


_i_ =1


|Term1<br>108<br>106<br>104|Col2|Col3|Term1<br>109<br>107<br>105|Col5|Col6|
|---|---|---|---|---|---|
|104<br>106<br>108~~ Term1~~<br>||||||
|104<br>106<br>108~~ Term1~~<br>||||||
|104<br>106<br>108~~ Term1~~<br>||||||








|00k<br>00k<br>00k<br>0|Term2|Col3|Col4|Term2<br>0k<br>0|Col6|Col7|
|---|---|---|---|---|---|---|
|0<br>00k<br>00k<br>00k<br>|||||||
|0<br>00k<br>00k<br>00k<br>|||||||
|0<br>00k<br>00k<br>00k<br>|||||||












|200 Term3 3<br>2<br>100<br>1<br>0<br>0 4k 7k 10k<br>edits|Term3|Col3|3<br>2|Term3<br>00<br>00<br>00<br>0<br>0 4k 7k 10|Col6|Col7|
|---|---|---|---|---|---|---|
|~~0~~<br>~~4k~~<br>~~7k~~<br>~~10~~k<br>0<br>100<br>200~~ Term3~~<br>1<br>2<br>3<br>edits|||||||
|~~0~~<br>~~4k~~<br>~~7k~~<br>~~10~~k<br>0<br>100<br>200~~ Term3~~<br>1<br>2<br>3<br>edits|||||||
|~~0~~<br>~~4k~~<br>~~7k~~<br>~~10~~k<br>0<br>100<br>200~~ Term3~~<br>1<br>2<br>3<br>edits|||||||



Figure 2: **Evolution of objective terms over** 10K **edits.** We compare RLSEDIT against baselines (ALPHAEDIT, MEMIT) on three
metrics: **Term 1** ( _∥_ _**K**_ _t_ _**W**_ _−_ _**V**_ _t∥_ [2] _F_ [) measures the fitting error for]
the current edit; **Term 2** ( _∥_ _**W**_ _−_ _**W**_ 0 _∥_ [2] _F_ [) measures parameter drift]
from the initial weights; and **Term 3** ( _∥_ _**K**_ 0 _**W**_ _−_ _**V**_ 0 _∥_ [2] _F_ [) measures]
the preservation error on the preserved knowledge. The results show
that RLSEDIT consistently maintains lower values across all three
terms, supporting the stability of our soft-constraint formulation.


preservation constraints (equivalently, a null-space condition)
via the standard penalty method. Thus RLSEdit interpolates
between the _hard write / soft preserve_ extreme and the _hard_
_preserve / soft fit_ extreme (null-space editors), while maintaining a stable soft–soft regime in long-edit streams. **As il-**
**lustrated in Figure 2**, RLSEDIT effectively suppresses the
growth of all three objective terms—fitting error, parameter drift, and preservation error—over 10K sequential edits,
whereas baselines exhibit instability in at least one component.


**4** **Theoretical Analysis**


We provide deviation bounds in terms of ( _λ, µ_ ): _λ_ controls
global parameter deviation from _**W**_ 0, and _µ_ controls deviation of the linear mapping _**K**_ 0 _**W**_ . Proofs are deferred to the
Appendix.


**Theorem 4.1** (Global deviation bounds ) **.** _Let_ _**W**_ _t_ _[∗]_ _[be the]_
_minimizer of Jt_ ( _**W**_ ) _and define_ _**R**_ _t_ := _**V**_ _t −_ _**K**_ _t_ _**W**_ _t_ _[∗]_ _−_ 1 _[. Let]_
_σ_ min( _**K**_ ) _denotes the smallest singular value of_ _**K**_ _._


_(i) (_ Parameter Deviation _) If λ >_ 0 _, then for any T ≥_ 1 _,_



_holds with improved uniform-denominator bound._
Theorem 4.1 clarifies how _µ_ and _λ_ affect deviation. _λ_ _[−]_ [1] _[/]_ [2]
bounds the movement of the least squared solution _**W**_ _T_ _[∗]_ [away]
from _**W**_ 0 at time _T_, while _µ_ _[−]_ [1] bounds deviation of the linear
mapping _**K**_ 0 _**W**_ from output _**V**_ 0. In practice, one increases
_λ_ to reduce parameter deviation and increases _µ_ to reduce
anchor mapping deviation. The _edit residual_ measuring how
well the current edit constraints are satisfied.


**4.1** **Asymptotic Scaling**
To connect ( _λ, µ_ ) to the many-edits regime, we view Equation (3) as a ridge-type estimator for a _layer-wise_ linear mapping. We use the statistical model

_**V**_ _i_ = _**K**_ _i_ _**W**_ _[⋆]_ + _**E**_ _i,_ sup E _∥_ _**E**_ _i∥_ [2] _F_ _[<][ ∞][,]_ (16)
_i_

where _**E**_ _i_ captures approximation error due to other layers,
context variability, and mismatch between the linear output.
Importantly, sequential edits need not be i.i.d and we only
assume long-run stability of second moments, i.e. there exist
matrices **Σ** _k_ and **Σ** _kv_ such that



+ _αt ∥_ _**W**_ _−_ _**W**_ 0 _∥_ [2] _F_ [+] _[ β][t][ ∥]_ _**[K]**_ [0] _**[W]**_ _[ −]_ _**[V]**_ [0] _[∥]_ _F_ [2] _[.]_

For asymptotic analysis, it is convenient to work with the normalized objective _J_ [˜] _t_ ( _**W**_ ) := _Jt_ ( _**W**_ ) _/t_, which has the same
minimizer as _Jt_ for each fixed _t_ .
**Proposition 4.2** (Asymptotic behavior of the RLS editor) **.** _Assume Equation_ (15) _,_ _Equation_ (16) _and that_
sup _i_ E _∥_ _**K**_ _i∥_ [4] _F_ _[<][ ∞][,]_ [ sup] _i_ [E] _[ ∥]_ _**[V]**_ _[i][∥]_ [4] _F_ _[<][ ∞][. Let]_ _**[ W]**_ _t_ _[ ∗]_ _[be the]_
_minimizer of Jt_ ( _**W**_ ) _, with αt_ = _λ_ [2] _t_ _[/t][,][ β][t]_ [=] _[ µ]_ [2] _t_ _[/t][ from Equa-]_
_tion_ (17) _._ _Suppose that αt →_ _α and βt →_ _β for some_
_α, β ∈_ [0 _, ∞_ ) _as t →∞. We define the population quadratic_
_risk R_ ( _W_ ) := E[ _∥KW −_ _V ∥_ [2] _F_ []] _[ under the limiting second-]_
_moment model in Equation_ (17) _. Then_


_(i) The normalized objectives_ _J_ [�] _t converge point-wise to_
_the regularized population risk_

_R_ ridge ( _**W**_ ) := _R_ ( _**W**_ ) + _α ∥_ _**W**_ _−_ _**W**_ 0 _∥_ [2] _F_ (19)
+ _β ∥_ _**K**_ 0 _**W**_ _−_ _**V**_ 0 _∥_ [2] _F_ _[.]_



(17)


(18)



1


_t_



_t_





- _**K**_ _i_ _[⊤]_ _**[K]**_ _[i]_ _[→]_ **[Σ]** _[k][,]_ 1

_t_

_i_ =1



_t_



_t_

- _**K**_ _i_ _[⊤]_ _**[V]**_ _[i]_ _[→]_ **[Σ]** _[kv][,]_

_i_ =1



s.t. **Σ** _k ≻_ 0 (on the relevant subspace) _._


Allow _λ_ = _λt_ and _µ_ = _µt_ to depend on _t_ and define

_αt_ := _λ_ [2] _t_ _[/t,]_ _βt_ := _µ_ [2] _t_ _[/t.]_


Then the normalized objective at step _t_ is



_J_ ˜ _t_ ( _**W**_ ) = [1]

_t_



_t_

- _∥_ _**K**_ _i_ _**W**_ _−_ _**V**_ _i∥_ [2] _F_

_i_ =1



_._
����� _F_



1
_∥_ _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0] _[∥]_ _F_ _[≤]_
_λ_ [2]



�����



_T_





- _**K**_ _t_ _[⊤]_ [(] _**[V]**_ _[t]_ _[−]_ _**[K]**_ _[t]_ _**[W]**_ [0][)]

_t_ =1



_(ii) (_ Linear Map Deviation _) If µ >_ 0 _, then for any T ≥_ 1 _,_



_∥_ _**K**_ 0( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][)] _[∥]_ _F_ _[≤]_ [1]

_µ_



_T_

- _∥_ _**R**_ _t∥F ._

_t_ =1


**Method** **Model** **Efficacy** _↑_ **Generalization** _↑_ **Specificity** _↑_ **Fluency** _↑_ **Consistency** _↑_



**RLSEdit** (Ours) **89** _._ **94** _±_ **0** _._ **75** **72** _._ **84** _±_ **1** _._ **21** **60** _._ **56** _±_ **0** _._ **35** **615** _._ **58** _±_ **4** _._ **34** **26** _._ **27** _±_ **0** _._ **35**

AlphaEdit 66 _._ 78 _±_ 3 _._ 19 58 _._ 27 _±_ 1 _._ 59 51 _._ 79 _±_ 0 _._ 70 489 _._ 91 _±_ 33 _._ 83 4 _._ 59 _±_ 0 _._ 39
ROME 47 _._ 57 _±_ 0 _._ 10 48 _._ 45 _±_ 0 _._ 33 52 _._ 52 _±_ 0 _._ 44 465 _._ 02 _±_ 17 _._ 88 1 _._ 83 _±_ 0 _._ 14
MEMIT 49 _._ 73 _±_ 1 _._ 44 49 _._ 24 _±_ 0 _._ 48 51 _._ 54 _±_ 0 _._ 68 323 _._ 01 _±_ 16 _._ 40 3 _._ 45 _±_ 1 _._ 62
FT 74 _._ 76 _±_ 0 _._ 00 64 _._ 49 _±_ 0 _._ 00 39 _._ 69 _±_ 0 _._ 00 342 _._ 42 _±_ 0 _._ 20 1 _._ 31 _±_ 0 _._ 00



**RLSEdit** (Ours) **94** _._ **45** _±_ **1** _._ **07** 68 _._ 55 _±_ 0 _._ 47 73 _._ 37 _±_ 0 _._ 44 **625** _._ **74** _±_ **0** _._ **71** 31 _._ 62 _±_ 0 _._ 81

AlphaEdit 94 _._ 10 _±_ 0 _._ 42 **70** _._ **29** _±_ **2** _._ **30** **75** _._ **29** _±_ **0** _._ **65** 623 _._ 51 _±_ 0 _._ 24 31 _._ 37 _±_ 0 _._ 49
ROME 35 _._ 70 _±_ 1 _._ 36 37 _._ 16 _±_ 1 _._ 19 65 _._ 20 _±_ 1 _._ 42 619 _._ 67 _±_ 16 _._ 98 **31** _._ **79** _±_ **3** _._ **59**
MEMIT 53 _._ 13 _±_ 0 _._ 72 51 _._ 39 _±_ 0 _._ 49 51 _._ 52 _±_ 0 _._ 92 532 _._ 38 _±_ 24 _._ 31 1 _._ 63 _±_ 2 _._ 22
FT 65 _._ 72 _±_ 0 _._ 00 56 _._ 46 _±_ 0 _._ 00 45 _._ 23 _±_ 0 _._ 00 324 _._ 70 _±_ 0 _._ 04 1 _._ 87 _±_ 0 _._ 03



Table 1: CounterFact results on Llama-3-8B and Qwen2.5-7B, comparison of **RLSEdit** with the baselines. We report mean _±_ standard
deviation over **3** random seeds, evaluated on the full CounterFact test set after completing all sequential edits (10K Edits in total, with a batch
size of 100). We evaluate on five metrics: Efficacy, Generalization, Specificity, Fluency, and Consistency. The best-performing results are
highlighted in bold, and the secondbest results are underlined.



_(ii) The function R_ ridge _is strictly convex and admits a_
_unique minimizer_ _**W**_ _[†]_ _._
_(iii) The RLS editor is consistent for_ _**W**_ _[†]_ _:_

_**W**_ _t_ _[∗]_ _[→]_ _**[W]**_ _[ †][ a.s.][ t][ →∞][.]_ (20)

If _α_ = _β_ = 0 (e.g., when _λt, µt_ are held fixed), then
_**W**_ _[†]_ = _**W**_ _[⋆]_ and _**W**_ _t_ _[∗]_ [converges to the least-squares popula-]
tion minimizer. If _α >_ 0 and/or _β >_ 0, then _**W**_ _[†]_ interpolates
between the data-driven optimum _**W**_ _[⋆]_ and the anchor constraints encoded by ( _**W**_ 0 _,_ _**K**_ 0 _,_ _**V**_ 0): larger _α_ shrinks _**W**_ _[†]_ toward _**W**_ 0, and larger _β_ enforces _**K**_ 0 _**W**_ _[†]_ _≈_ _**V**_ 0 even as _t_ _→∞_ .
This proposition shows that our optimized solution weights
will be stable and converge to some point with mild conditions. In practice, increasing _µ_ and _λ_ makes the update more
conservative. This keeps _**W**_ _t_ _[∗]_ [closer to the original model,]
but fits the new edit less accurately, leading to larger residuals
_∥_ _**R**_ _t∥F_ . A common policy is to set a deviation budget for the
associated penalties, then tune ( _µ, λ_ ) to satisfy both bounds.
The limits _µ, λ →∞_ yield hard anchoring ( _**K**_ 0 _**W**_ = _**V**_ 0) and
freezes parameters ( _**W**_ _t_ _[∗]_ _[→]_ _**[W]**_ [0][).]


**5** **Experiments and Results**

**5.1** **Experimental Setup**
**Models and Baselines.** We conduct experiments with two
backbone models, Llama3-8B and Qwen2.5-7B, against ALPHAEDIT [Fang et al., 2025], ROME [Meng et al., 2022],
MEMIT [Meng et al., 2023], and fine-tuning (FT) [Zhu et al.,
2020].

**Datasets and Metrics.** Following prior work, we use the
**CounterFact** dataset [Meng et al., 2022]. We report **Effi-**
**cacy** (rewrite success), **Generalization** (paraphrase success),
**Specificity** (neighborhood success), **Fluency** (generation entropy), and **Consistency** (reference score). The detailed
hyper-parameter setup is included in Section B.


**5.2** **Main Results**
**Editing Results.** Table 1 reports performance after 10K
edits (batch size 100) with Llama3-8B and Qwen2.5-7B on



the CounterFact dataset, our method **RLSEdit** demonstrates
strong overall performance. For Llama-3-8B, **RLSEdit**
achieves the best scores across all five metrics. Notably,
it shows substantial leads in Efficacy (89.94 vs. 74.76
for second-best FT), Generalization, Fluency, and Consistency. For Qwen2.5-7B, the results are more nuanced. While
textbfRLSEdit obtains the highest Efficacy and Fluency, ALPHAEDIT is strongest in Generalization and Specificity, and
ROME leads in Consistency. **RLSEdit** and ALPHAEDIT perform comparably on this model, with both significantly outperforming ROME, MEMIT, and FT in most metrics. Overall, these results demonstrate the strong editing effectiveness
of **RLSEdit** in long, sequential editing scenarios.
To assess how well editing methods preserve the preedited model’s general abilities, we evaluate 5 tasks from
GLUE (SST, MMLU, MRPC, CoLa, RTE) [Wang et al.,
2018], together with additional benchmarks that test _gen-_
_eral knowledge_ (MMLU), _math reasoning_ (GSM8K), and
_coding ability_ (HumanEval, MBPP). Details of these benchmarks are provided in Appendix C. We conduct the evaluation of these benchmarks on multiple editing checkpoints of
the Llama3-8B model, using 10K total edits with a batch size
of 100.


**General Capability Results.** Figure 3 summarizes the general capability evaluations. Across all language understanding tasks from GLUE and the three code/math reasoning
benchmarks, **RLSEdit** consistently delivers the strongest performance throughout the entire editing trajectory. Its stability is especially notable given the scale of the editing workload, maintaining high accuracy even as the number of edits grows large. In contrast, MEMIT, ROME, and FT exhibit rapid degradation as edits accumulate, suggesting limited robustness under sustained modification. ALPHAEDIT
performs competitively in the early stages but undergoes a
pronounced drop after approximately 8 _,_ 000 edits, indicating
a threshold beyond which its internal representations begin to
destabilize. Additional qualitative examples and case studies
are provided in the supplementary material (Section D). In


**1.00**


**0.80**


**0.60**


**0.40**


**0.20**


**0.00**


**0.70**


**0.60**


**0.50**


**0.40**


**0.30**


**0.20**


**0.10**


**0.00**



**SST**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**


**NLI**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**



**0.60**


**0.50**


**0.40**


**0.30**


**0.20**


**0.10**


**0.00**


**0.80**


**0.60**


**0.40**


**0.20**


**0.00**



**MRPC**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**


**HumanEval**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**



**0.80**


**0.60**


**0.40**


**0.20**


**0.00**


**0.70**


**0.60**


**0.50**


**0.40**


**0.30**


**0.20**


**0.10**


**0.00**



**CoLA**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**


**MBPP**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**



**RTE**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**


**RLSEdit**
**AlphaEdit**
**MEMIT**
**ROME**
**FT**



**MMLU**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**


**GSM8K**


**pre** **2k** **4k** **6k** **8k** **10k**
**#edits**



**0.80**


**0.60**


**0.40**


**0.20**


**0.00**


**0.70**


**0.60**


**0.50**


**0.40**


**0.30**


**0.20**


**0.10**


**0.00**



**0.35**


**0.30**


**0.25**


**0.20**


**0.15**


**0.10**


**0.05**


**0.00**



Figure 3: **General capability preservation.** We evaluate 5 GLUE tasks and additional benchmarks for general knowledge, math reasoning
and coding ability (MMLU, GSM8K, HumanEval, MBPP) at multiple editing checkpoints (Pre-edit, 2k–10k edits). **RLSEdit** is compared
against baselines and consistently better preserves the model’s general capabilities across tasks and edit scales. The x-axis shows the cumulative number of applied edits, and the y-axis reports the corresponding score (F1 or accuracy).







summary, these results demonstrate that **RLSEdit** more effectively preserves the model’s general language understanding and reasoning abilities while still applying edits reliably
and at scale.


**5.3** **Analysis and Discussion**


**Early Edits Comparison.** To examine how well **RLSEdit**
and the baselines preserve earlier edits in a sequential editing setting, we re-evaluate the first _N_ edited cases ( _N ∈_
_{_ 500 _,_ 1K _,_ 2K _,_ 4K _}_ ) after performing 10K sequential edits
(batch size = 100) on Llama3-8B. As shown in Figure 4,
**RLSEdit** consistently achieves the best retention across all
_N_ : its Rewrite scores range from 71 _._ 22 (at _N_ =500) to 81 _._ 28
(at _N_ =4K), and its Paraphrase scores range from 60 _._ 49 to
66 _._ 98. In contrast, baseline methods remain noticeably lower
(typically around 45 to 70 on Rewrite and 46 to 62 on Para


**Llama3-8B** **Qwen2.5-7B**
**Method**

100 200 500 100 200 500


AlphaEdit 525.15 227.93 108.07 978.32 412.94 197.49
**RLSEdit** **328.39** **166.84** **66.85** **545.65** **271.20** **112.88**


Table 2: Update time (seconds) for performing 10K edits on
Llama3-8B and Qwen2.5-7B using batch sizes _{_ 100, 200, 500 _}_ .
Lower values indicate faster updates. Comparison of **RLSEdit** versus AlphaEdit.


phrase), suggesting weaker preservation of previously edited
knowledge under long, sequential editing.


**Speed-up Analysis.** Table 2 reports the update computation
time for **RLSEdit** and ALPHAEDIT when performing edits
across two model backbones (Llama3-8B and Qwen2.5-7B)
and three batch sizes (BS _∈{_ 100,200,500 _}_ ). Across all
six configurations, **RLSEdit** consistently runs faster, reducing update time by 1 _._ 37 _×_ –1 _._ 79 _×_ relative to ALPHAEDIT.
This empirical advantage is consistent with the theoretical
time-complexity analysis presented in Section 3.2.


**6** **Conclusion**


Existing model editing methods suffer from performance loss
when the number of edits scales up. To address this, we propose **RLSEdit**, a recursive least-squares framework that implements soft editing and soft preservation targeting long-edit
tasks. The main novelty of our method can be summarized
into two parts. First, we find an efficient recursive updating
algorithm that minimizes the new edit residuals while keeping
the old edit residuals small. Second, our formulation is more
flexible and generalizable than the existing hard-constraint
editing methods by introducing two regularization terms. By


controlling deviation from pre-trained weights and anchors,
RLSEdit balances model performance and flexibility while
achieving _fast_, constant-time updates via Woodbury recursion
formula. Empirically, RLSEdit scales stably to 10K edits on
Llama-3 and Qwen2.5, significantly outperforming baselines
in _early edits_ . Crucially, it preserves both general capabilities
and reasoning capabilities in various benchmarks, validating
our recursive formulation as a robust solution for continuous
model editing.


**Ethical Statement**


While our work centers on model-editing methods, it is important to acknowledge that such techniques can also be misused to inject undesirable knowledge or behavioral traits into
a model. These risks merit careful consideration and discussion.


**References**


J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski,
D. Dohan, E. Jiang, C. J. Cai, M. Terry, Q. V. Le, and
C. Sutton. Program synthesis with large language models. _ArXiv_ [, abs/2108.07732, 2021. URL https://api.semant](https://api.semanticscholar.org/CorpusID:237142385)
[icscholar.org/CorpusID:237142385.](https://api.semanticscholar.org/CorpusID:237142385)


L. Bentivogli, B. Magnini, I. Dagan, H. T. Dang, and D. Giampiccolo. The fifth PASCAL recognizing textual entailment challenge. In _TAC_ . NIST, 2009.


M. Chen, J. Tworek, H. Jun, Q. Yuan, H. Pond´e, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman,
A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov,
A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet,
F. P. Such, D. W. Cummings, M. Plappert, F. Chantzis,
E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol,
I. Babuschkin, S. Balaji, S. Jain, A. Carr, J. Leike,
J. Achiam, V. Misra, E. Morikawa, A. Radford, M. M.
Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder,
B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and
W. Zaremba. Evaluating large language models trained
on code. _ArXiv_, abs/2107.03374, 2021. [URL https:](https://api.semanticscholar.org/CorpusID:235755472)
[//api.semanticscholar.org/CorpusID:235755472.](https://api.semanticscholar.org/CorpusID:235755472)


Q. Chen, T. Zhang, X. He, D. Li, C. Wang, L. Huang,
and H. Xue’. Lifelong knowledge editing for llms with
retrieval-augmented continuous prompt learning. In Y. AlOnaizan, M. Bansal, and Y. Chen, editors, _Proceedings_
_of the 2024 Conference on Empirical Methods in Natu-_
_ral Language Processing, EMNLP 2024, Miami, FL, USA,_
_November 12-16, 2024_, pages 13565–13580. Association
for Computational Linguistics, 2024.


K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun,
L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano,
C. Hesse, and J. Schulman. Training verifiers to solve
math word problems. _ArXiv_, abs/2110.14168, 2021. URL
[https://api.semanticscholar.org/CorpusID:239998651.](https://api.semanticscholar.org/CorpusID:239998651)


N. De Cao, W. Aziz, and I. Titov. Editing factual knowledge
in language models. In _Proceedings of the 2021 Confer-_
_ence on Empirical Methods in Natural Language Process-_



_ing_, pages 6491–6506. Association for Computational Linguistics, 2021. doi: 10.18653/v1/2021.emnlp-main.522.
[URL https://aclanthology.org/2021.emnlp-main.522/.](https://aclanthology.org/2021.emnlp-main.522/)


DeepSeek-AI, D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang,
R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi, X. Zhang, X. Yu,
Y. Wu, Z. F. Wu, Z. Gou, Z. Shao, Z. Li, Z. Gao, A. Liu,
B. Xue, B. Wang, B. Wu, B. Feng, C. Lu, C. Zhao,
C. Deng, C. Zhang, C. Ruan, D. Dai, D. Chen, D. Ji, E. Li,
F. Lin, F. Dai, F. Luo, G. Hao, G. Chen, G. Li, H. Zhang,
H. Bao, H. Xu, H. Wang, H. Ding, H. Xin, H. Gao, H. Qu,
H. Li, J. Guo, J. Li, J. Wang, J. Chen, J. Yuan, J. Qiu,
J. Li, J. L. Cai, J. Ni, J. Liang, J. Chen, K. Dong, K. Hu,
K. Gao, K. Guan, K. Huang, K. Yu, L. Wang, L. Zhang,
L. Zhao, L. Wang, L. Zhang, L. Xu, L. Xia, M. Zhang,
M. Zhang, M. Tang, M. Li, M. Wang, M. Li, N. Tian,
P. Huang, P. Zhang, Q. Wang, Q. Chen, Q. Du, R. Ge,
R. Zhang, R. Pan, R. Wang, R. J. Chen, R. L. Jin, R. Chen,
S. Lu, S. Zhou, S. Chen, S. Ye, S. Wang, S. Yu, S. Zhou,
S. Pan, and S. S. Li. Deepseek-r1: Incentivizing reasoning
capability in llms via reinforcement learning, 2025. URL
[https://doi.org/10.48550/arXiv.2501.12948.](https://doi.org/10.48550/arXiv.2501.12948)


J. Deng, Z. Wei, L. Pang, H. Ding, H. Shen, and X. Cheng.
Everything is editable: Extend knowledge editing to unstructured data in large language models. In _The Thir-_
_teenth International Conference on Learning Representa-_
_tions, ICLR 2025, Singapore, April 24-28, 2025_ . OpenRe[view.net, 2025. URL https://openreview.net/forum?id=X5](https://openreview.net/forum?id=X5rO5VyTgB)
[rO5VyTgB.](https://openreview.net/forum?id=X5rO5VyTgB)


W. B. Dolan and C. Brockett. Automatically constructing a corpus of sentential paraphrases. In _Proceed-_
_ings of the Third International Workshop on Paraphrasing_
_(IWP2005)_ [, 2005. URL https://aclanthology.org/I05-500](https://aclanthology.org/I05-5002/)
[2/.](https://aclanthology.org/I05-5002/)


A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle,
A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan,
A. Goyal, A. Hartshorn, A. Yang, A. Mitra, A. Sravankumar, A. Korenev, A. Hinsvark, A. Rao, A. Zhang,
A. Rodriguez, A. Gregerson, A. Spataru, B. Rozi`ere,
B. Biron, B. Tang, B. Chern, C. Caucheteux, C. Nayak,
C. Bi, C. Marra, C. McConnell, C. Keller, C. Touret,
C. Wu, C. Wong, C. C. Ferrer, C. Nikolaidis, D. Allonsius, D. Song, D. Pintz, D. Livshits, D. Esiobu, D. Choudhary, D. Mahajan, D. Garcia-Olano, D. Perino, D. Hupkes, E. Lakomkin, E. AlBadawy, E. Lobanova, E. Dinan, E. M. Smith, F. Radenovic, F. Zhang, G. Synnaeve,
G. Lee, G. L. Anderson, G. Nail, G. Mialon, G. Pang,
G. Cucurell, H. Nguyen, H. Korevaar, H. Xu, H. Touvron,
I. Zarov, I. A. Ibarra, I. M. Kloumann, I. Misra, I. Evtimov, J. Copet, J. Lee, J. Geffert, J. Vranes, J. Park, J. Mahadeokar, J. Shah, J. van der Linde, J. Billock, J. Hong,
J. Lee, J. Fu, J. Chi, J. Huang, J. Liu, J. Wang, J. Yu, J. Bitton, J. Spisak, J. Park, J. Rocca, J. Johnstun, J. Saxe, J. Jia,
K. V. Alwala, K. Upasani, K. Plawiak, K. Li, K. Heafield,
K. Stone, and et al. The llama 3 herd of models, 2024.
[URL https://doi.org/10.48550/arXiv.2407.21783.](https://doi.org/10.48550/arXiv.2407.21783)


J. Fang, H. Jiang, K. Wang, Y. Ma, J. Shi, X. Wang,
X. He, and T. Chua. Alphaedit: Null-space constrained


knowledge editing for language models. In _The Thir-_
_teenth International Conference on Learning Representa-_
_tions, ICLR 2025, Singapore, April 24-28, 2025_ . OpenReview.net, 2025.


A. Gupta, A. Rao, and G. Anumanchipalli. Model editing
at scale leads to gradual and catastrophic forgetting. In
_Findings of the Association for Computational Linguistics:_
_ACL 2024_, pages 15202–15232, Bangkok, Thailand, Aug.
2024. Association for Computational Linguistics. doi: 10
[.18653/v1/2024.findings-acl.902. URL https://aclantholo](https://aclanthology.org/2024.findings-acl.902/)
[gy.org/2024.findings-acl.902/.](https://aclanthology.org/2024.findings-acl.902/)


W. W. Hager. Updating the inverse of a matrix. _SIAM Review_,
31(2):221–239, 1989. doi: 10.1137/1031049.


T. Hartvigsen, S. Sankaranarayanan, H. Palangi, Y. Kim, and
M. Ghassemi. Aging with GRACE: lifelong model editing
with discrete key-value adaptors. In _Advances in Neural_
_Information Processing Systems 36 (NeurIPS 2023)_, 2023.
[URL http://papers.nips.cc/paper](http://papers.nips.cc/paper_files/paper/2023/hash/95b6e2ff961580e03c0a662a63a71812-Abstract-Conference.html) files/paper/2023/hash/9
[5b6e2ff961580e03c0a662a63a71812-Abstract-Conferenc](http://papers.nips.cc/paper_files/paper/2023/hash/95b6e2ff961580e03c0a662a63a71812-Abstract-Conference.html)
[e.html.](http://papers.nips.cc/paper_files/paper/2023/hash/95b6e2ff961580e03c0a662a63a71812-Abstract-Conference.html)


D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika,
D. X. Song, and J. Steinhardt. Measuring massive multitask language understanding. _ArXiv_, abs/2009.03300,
[2020. URL https://api.semanticscholar.org/CorpusID:](https://api.semanticscholar.org/CorpusID:221516475)
[221516475.](https://api.semanticscholar.org/CorpusID:221516475)


H. Jiang, J. Fang, N. Zhang, M. Wan, G. Ma, X. Wang, X. He,
and T. Chua. Anyedit: Edit any knowledge encoded in
language models. In _Forty-second International Confer-_
_ence on Machine Learning, ICML 2025, Vancouver, BC,_
_Canada, July 13-19, 2025_ . OpenReview.net, 2025.


K. Meng, D. Bau, A. Andonian, and Y. Belinkov. Locating and editing factual associations in GPT. In S. Koyejo,
S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh,
editors, _Advances in Neural Information Processing Sys-_
_tems 35: Annual Conference on Neural Information Pro-_
_cessing Systems 2022, NeurIPS 2022, New Orleans, LA,_
_USA, November 28 - December 9, 2022_, 2022.


K. Meng, A. S. Sharma, A. J. Andonian, Y. Belinkov, and
D. Bau. Mass-editing memory in a transformer. In _The_
_Eleventh International Conference on Learning Represen-_
_tations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023_ . OpenReview.net, 2023.


E. Mitchell, C. Lin, A. Bosselut, C. Finn, and C. D. Manning.
Fast model editing at scale. In _International Conference_
_on Learning Representations (ICLR)_ [, 2022. URL https:](https://openreview.net/forum?id=0DcZxeWfOPt)
[//openreview.net/forum?id=0DcZxeWfOPt.](https://openreview.net/forum?id=0DcZxeWfOPt)


[OpenAI. GPT-4 technical report, 2023. URL https://doi.org/](https://doi.org/10.48550/arXiv.2303.08774)
[10.48550/arXiv.2303.08774.](https://doi.org/10.48550/arXiv.2303.08774)


A. H. Sayed. _Fundamentals of Adaptive Filtering_ . WileyIEEE Press, 2003. ISBN 978-0471461265.


J. Sherman and W. J. Morrison. Adjustment of an inverse
matrix corresponding to a change in one element of a given
matrix. _The Annals of Mathematical Statistics_, 21(1):124–
127, 1950. doi: 10.1214/aoms/1177729893.



R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Ng, and C. Potts. Recursive deep models for
semantic compositionality over a sentiment treebank. In
D. Yarowsky, T. Baldwin, A. Korhonen, K. Livescu, and
S. Bethard, editors, _Proceedings of the 2013 Conference_
_on Empirical Methods in Natural Language Processing_,
pages 1631–1642, Seattle, Washington, USA, Oct. 2013.
Association for Computational Linguistics. [URL https:](https://aclanthology.org/D13-1170/)
[//aclanthology.org/D13-1170/.](https://aclanthology.org/D13-1170/)

W. Sun, T. Qu, M. Li, J. Davis, and M.-F. Moens. Mitigating negative interference in multilingual knowledge editing through null-space constraints. In W. Che, J. Nabende,
E. Shutova, and M. T. Pilehvar, editors, _Findings of the_
_Association for Computational Linguistics: ACL 2025_,
pages 8796–8810, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-89176256-5. doi: 10.18653/v1/2025.findings-acl.460. URL
[https://aclanthology.org/2025.findings-acl.460/.](https://aclanthology.org/2025.findings-acl.460/)

A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In T. Linzen,
G. Chrupała, and A. Alishahi, editors, _Proceedings of the_
_2018 EMNLP Workshop BlackboxNLP: Analyzing and In-_
_terpreting Neural Networks for NLP_, pages 353–355, Brussels, Belgium, Nov. 2018. Association for Computational
[Linguistics. doi: 10.18653/v1/W18-5446. URL https:](https://aclanthology.org/W18-5446/)
[//aclanthology.org/W18-5446/.](https://aclanthology.org/W18-5446/)

P. Wang, Z. Li, N. Zhang, Z. Xu, Y. Yao, Y. Jiang, P. Xie,
F. Huang, and H. Chen. WISE: rethinking the knowledge
memory for lifelong model editing of large language models. In A. Globersons, L. Mackey, D. Belgrave, A. Fan,
U. Paquet, J. M. Tomczak, and C. Zhang, editors, _Ad-_
_vances in Neural Information Processing Systems 38: An-_
_nual Conference on Neural Information Processing Sys-_
_tems 2024, NeurIPS 2024, Vancouver, BC, Canada, De-_
_cember 10 - 15, 2024_, 2024.

A. Warstadt, A. Singh, and S. R. Bowman. Neural network
acceptability judgments. _Transactions of the Association_
_for Computational Linguistics_, 7:625–641, 2019. doi: 10
.1162/tacl a [00290. URL https://aclanthology.org/Q19-1](https://aclanthology.org/Q19-1040/)
[040/.](https://aclanthology.org/Q19-1040/)

A. Williams, N. Nangia, and S. Bowman. A broad-coverage
challenge corpus for sentence understanding through inference. In M. Walker, H. Ji, and A. Stent, editors, _Pro-_
_ceedings of the 2018 Conference of the North American_
_Chapter of the Association for Computational Linguistics:_
_Human Language Technologies, Volume 1 (Long Papers)_,
pages 1112–1122, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v
[1/N18-1101. URL https://aclanthology.org/N18-1101/.](https://aclanthology.org/N18-1101/)

M. A. Woodbury. Inverting modified matrices. Memorandum
Report 42, Statistical Research Group, Princeton University, 1950.

A. Yang, B. Yang, B. Zhang, B. Hui, B. Zheng, B. Yu,
C. Li, D. Liu, F. Huang, H. Wei, H. Lin, J. Yang, J. Tu,
J. Zhang, J. Yang, J. Yang, J. Zhou, J. Lin, K. Dang, K. Lu,
K. Bao, K. Yang, L. Yu, M. Li, M. Xue, P. Zhang, Q. Zhu,


R. Men, R. Lin, T. Li, T. Xia, X. Ren, X. Ren, Y. Fan,
Y. Su, Y. Zhang, Y. Wan, Y. Liu, Z. Cui, Z. Zhang, and
Z. Qiu. Qwen2.5 technical report, 2024. [URL https:](https://doi.org/10.48550/arXiv.2412.15115)
[//doi.org/10.48550/arXiv.2412.15115.](https://doi.org/10.48550/arXiv.2412.15115)


C. Zhu, A. S. Rawat, M. Zaheer, S. Bhojanapalli, D. Li, F. X.
Yu, and S. Kumar. Modifying memories in transformer
models. _ArXiv_ [, abs/2012.00363, 2020. URL https://api.se](https://api.semanticscholar.org/CorpusID:227238659)
[manticscholar.org/CorpusID:227238659.](https://api.semanticscholar.org/CorpusID:227238659)


**A** **Preliminaries.**

Recall the stacked least-squares form















_λ_ _**W**_ 0
_µ_ _**V**_ 0
_**V**_ 1
...
_**V**_ _t_



Using the anchor condition equation 27, we have

_**K**_ 0 _[⊤]_ _**[V]**_ [0] [=] _**[ K]**_ 0 _[⊤]_ _**[K]**_ [0] _**[W]**_ [0] _[.]_ (34)


Subtracting _**S**_ _T_ _**W**_ 0 from both sides of equation 31 gives



_**S**_ _T_ ( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][) =] _**[ T]**_ _[T]_ _[−]_ _**[S]**_ _[T]_ _**[W]**_ [0] [=]


Thus






_,_ _**B**_ _t_ =







_,_ (21)




_**A**_ _t_ =







_λI_
_µ_ _**K**_ 0
_**K**_ 1
...
_**K**_ _t_



_T_

- _**K**_ _i_ _[⊤]_ [(] _**[V]**_ _[i]_ _[−]_ _**[K]**_ _[i]_ _**[W]**_ [0][)] _[.]_

_i_ =1

(35)



_**W**_ _t_ _[∗]_ [= arg min] _F_ _[,]_ (22)
_**W**_ _[∥]_ _**[A]**_ _[t]_ _**[W]**_ _[ −]_ _**[B]**_ _[t][∥]_ [2]


and define the normal-equation matrices



_T_

- _**K**_ _i_ _[⊤]_ [(] _**[V]**_ _[i]_ _[−]_ _**[K]**_ _[i]_ _**[W]**_ [0][)] _[.]_ (36)

_i_ =1



By submultiplicativity and _**S**_ _T ⪰_ _λ_ [2] _I_ (when _λ >_ 0),



_**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0] [=] _**[ S]**_ _T_ _[−]_ [1]



_**S**_ _t_ := _**A**_ _[⊤]_ _t_ _**[A]**_ _[t]_ [=] _[ λ]_ [2] _[I]_ [ +] _[ µ]_ [2] _**[K]**_ 0 _[⊤]_ _**[K]**_ [0] [+]



_t_

- _**K**_ _i_ _[⊤]_ _**[K]**_ _[i][,]_ (23)

_i_ =1



_t_

_**T**_ _t_ := _**A**_ _[⊤]_ _t_ _**[B]**_ _[t]_ [=] _[ λ]_ [2] _**[W]**_ [0] [+] _[ µ]_ [2] _**[K]**_ 0 _[⊤]_ _**[V]**_ [0] [+] - _**K**_ _i_ _[⊤]_ _**[V]**_ _[i][.]_ (24)

_i_ =1



�����



����� _F_



_∥_ _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0] _[∥][F]_ _[≤∥]_ _**[S]**_ _T_ _[−]_ [1] _[∥]_ [2]



_T_





- _**K**_ _i_ _[⊤]_ [(] _**[V]**_ _[i]_ _[−]_ _**[K]**_ _[i]_ _**[W]**_ [0][)]

_i_ =1



Whenever _**S**_ _t ≻_ 0, the minimizer is unique and satisfies

_**W**_ _t_ _[∗]_ [=] _**[ S]**_ _t_ _[−]_ [1] _**T**_ _t,_ _**C**_ _t_ := _**S**_ _t_ _[−]_ [1] _._ (25)

We will use the one-step identity (a standard RLS consequence of stacking and normal equations)

_**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [=] _**[ C]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ _**[R]**_ _[t][,]_ _**R**_ _t_ := _**V**_ _t −_ _**K**_ _t_ _**W**_ _t_ _[∗]_ _−_ 1 _[.]_ [ (26)]

Finally, we assume the anchor is satisfied by the initializer:


_**K**_ 0 _**W**_ 0 = _**V**_ 0 _._ (27)


**Alternative: streaming QR update**
For improved numerical stability, one may maintain a QR factorization of _**A**_ _t_ . Assume that at time _t−_ 1 we have orthogonal
transforms



_,_ (37)
����� _F_



_≤_ [1]

_λ_ [2]



�����



_T_





- _**K**_ _i_ _[⊤]_ [(] _**[V]**_ _[i]_ _[−]_ _**[K]**_ _[i]_ _**[W]**_ [0][)]

_i_ =1



_**Q**_ _[⊤]_ _t−_ 1 _**[A]**_ _[t][−]_ [1] [=] - _**R**_ **0** _t−_ 1� _,_ _**Q**_ _[⊤]_ _t−_ 1 _**[B]**_ _[t][−]_ [1] [=] - _**BB**_ ¯˜ _tt−−_ 11




_,_ (28)



which proves the claim.


**Lemma A.1.** _Assume µ >_ 0 _and_ _**S**_ _t ≻_ 0 _. Then for each_
_t ≥_ 1 _,_

_∥_ _**K**_ 0( _**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [)] _[∥][F]_ _[≤]_ [1] (38)

_µ_ _[∥]_ _**[R]**_ _[t][∥][F][,]_

_∥_ _**K**_ 0( _**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [)] _[∥][F]_ _[≤∥]_ _**[K]**_ [0] _[∥]_ [2] _[∥]_ _**[K]**_ _[t][∥]_ [2] _[∥]_ _**[C]**_ _[t][∥]_ [2] _[∥]_ _**[R]**_ _[t][∥][F]_ _[.]_
(39)


_Moreover,_


1
_∥_ _**C**_ _t∥_ 2 _≤_ _._ (40)
_λ_ [2] + _µ_ [2] **Σ** [2] min [(] _**[K]**_ [0][) +] ~~[ �]~~ _[t]_ _i_ =1 **[Σ]** min [2] [(] _**[K]**_ _[i]_ [)]


_Proof._ From equation 26,

_**K**_ 0( _**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [) =] _**[ K]**_ [0] _**[C]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ _**[R]**_ _[t][.]_ (41)


The classical bound equation 39 follows from operator norm
submultiplicativity:

_∥_ _**K**_ 0 _**C**_ _t_ _**K**_ _t_ _[⊤]_ _**[R]**_ _[t][∥][F]_ _[≤∥]_ _**[K]**_ [0] _[∥]_ [2] _[∥]_ _**[C]**_ _[t][∥]_ [2] _[∥]_ _**[K]**_ _[t][∥]_ [2] _[∥]_ _**[R]**_ _[t][∥][F]_ _[.]_ (42)


For the tighter bound equation 38, consider


         -         _∥_ _**K**_ 0 _**C**_ _t_ _**K**_ _t_ _[⊤]_ _**[R]**_ _[t][∥]_ _F_ [2] [= tr] _Rt_ _[⊤]_ _**[K]**_ _[t]_ _**[C]**_ _[t]_ _**[K]**_ 0 _[⊤]_ _**[K]**_ [0] _**[C]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ _**[R]**_ _[t]_

_≤_ �� _**K**_ _t_ _**C**_ _t_ _**K**_ 0 _⊤_ _**[K]**_ [0] _**[C]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ ��2 _[∥]_ _**[R]**_ _[t][∥]_ _F_ [2] _[.]_
(43)


Using _∥_ _**MNM**_ _[⊤]_ _∥_ 2 _≤∥_ _**M**_ _∥_ [2] 2 _[∥]_ _**[N]**_ _[∥]_ [2] [with] _**[ M]**_ [ =] _**[ K]**_ _[t]_ _**[C]**_ _t_ [1] _[/]_ [2]
and _**N**_ = _**C**_ _t_ [1] _[/]_ [2] _**K**_ 0 _[⊤]_ _**[K]**_ [0] _**[C]**_ _t_ [1] _[/]_ [2],
�� _**K**_ _t_ _**C**_ _t_ _**K**_ 0 _⊤_ _**[K]**_ [0] _**[C]**_ _[t]_ _**[K]**_ _t_ _[⊤]_ ��2 _[≤∥]_ _**[K]**_ _[t]_ _**[C]**_ _[t]_ _**[K]**_ _t_ _[⊤][∥]_ [2] _[· ∥]_ _**[K]**_ [0] _**[C]**_ _[t]_ _**[K]**_ 0 _[⊤][∥]_ [2] _[.]_
(44)


We bound the two factors.
_(a) ∥_ _**K**_ _t_ _**C**_ _t_ _**K**_ _t_ _[⊤][∥]_ [2] _[≤]_ [1] _[.]_ [ Let] _**[ C]**_ _[t][−]_ [1] [:=] _**[ S]**_ _t_ _[−]_ _−_ [1] 1 [and define]

_**H**_ _t_ := _**K**_ _t_ _**C**_ _t−_ 1 _Kt_ _[⊤]_ _[⪰]_ [0] _[.]_ (45)



where _**R**_ _t−_ 1 _∈_ R _[d][K]_ _[×][d][K]_ is upper triangular. At time _t_, we
apply additional orthogonal transforms _**Q**_ [¯] _t_ to




- = - _**R**_ **0** _t_ - _,_ _**Q**_ ¯ _[⊤]_ _t_




- _**B**_ ¯ _t−_ 1� = - _**B**_ ¯ _t_
_**V**_ _t_ _**B**_ ˆ _t_




_._ (29)



_**Q**_ ¯ _[⊤]_ _t_




- _**R**_ _t−_ 1
_**K**_ _t_



Then _**W**_ _t_ _[∗]_ [is obtained by solving the triangular system]

_**R**_ _t_ _**W**_ _t_ _[∗]_ [= ¯] _**B**_ _t._ (30)

**Initialization.** Since _**R**_ 0 _[⊤]_ _**[R]**_ [0] [=] _[ λ]_ [2] _**[I]**_ [ +] _[ µ]_ [2] _**[K]**_ 0 _[⊤]_ _**[K]**_ [0][, we com-]
pute _**R**_ 0 via Cholesky and set _**B**_ [¯] 0 = _**R**_ 0 _**W**_ 0 (using _**K**_ 0 _**W**_ 0 =
_**V**_ 0).


**A. Proof of Theorem 4.1**
_Proof of Theorem 4.1(i) (parameter deviation)._ The normal
equations for _**W**_ _T_ _[∗]_ [are]

_**S**_ _T_ _**W**_ _T_ _[∗]_ [=] _**[ T]**_ _[T]_ _[,]_ (31)

where



_**S**_ _T_ = _λ_ [2] _**I**_ + _µ_ [2] _**K**_ 0 _[⊤]_ _**[K]**_ [0] [+]



_T_

- _**K**_ _i_ _[⊤]_ _**[K]**_ _[i][,]_ (32)

_i_ =1



_**T**_ _T_ = _λ_ [2] _**W**_ 0 + _µ_ [2] _**K**_ 0 _[⊤][V]_ [0] [+]



_T_

- _**K**_ _i_ _[⊤]_ _**[V]**_ _[i][.]_ (33)

_i_ =1


By Sherman–Morrison–Woodbury,

_**C**_ _t_ = _**C**_ _t−_ 1 _−_ _**C**_ _t−_ 1 _**K**_ _t_ _[⊤]_ [(] _[I]_ [ +] _**[ H]**_ _[t]_ [)] _[−]_ [1] _**[K]**_ _[t]_ _**[C]**_ _[t][−]_ [1] _[.]_ (46)


Hence,

_**K**_ _t_ _**C**_ _t_ _**K**_ _t_ _[⊤]_ [=] _**[ H]**_ _[t]_ _[−]_ _**[H]**_ _[t]_ [(] _[I]_ [ +] _**[ H]**_ _[t]_ [)] _[−]_ [1] _**[H]**_ _[t]_ [=] _**[ H]**_ _[t]_ [(] _[I]_ [ +] _**[ H]**_ _[t]_ [)] _[−]_ [1] _[.]_
(47)


The eigenvalues of _**H**_ _t_ ( _I_ + _**H**_ _t_ ) _[−]_ [1] are _h/_ (1 + _h_ ) _∈_ [0 _,_ 1) for
_h ≥_ 0, so _∥_ _**K**_ _t_ _**C**_ _t_ _**K**_ _t_ _[⊤][∥]_ [2] _[≤]_ [1][.]
_(b) ∥_ _**K**_ 0 _**C**_ _t_ _**K**_ 0 _[⊤][∥]_ [2] _[≤]_ [1] _[/µ]_ [2] _[.]_ [ Since] _**[ S]**_ _[t]_ _[⪰]_ _[µ]_ [2] _**[K]**_ 0 _[⊤]_ _**[K]**_ [0][, we]
have _**C**_ _t_ = _**S**_ _t_ _[−]_ [1] _⪯_ ( _µ_ [2] _**K**_ 0 _[⊤]_ _**[K]**_ [0][)] _[†]_ [ on the support of] _**[ K]**_ 0 _[⊤]_ _**[K]**_ [0][,]
hence



**B: Proofs for Proposition 4.2**


**Step 1: Expand the normalized objective.** Let _J_ [�] _t_ ( _W_ ) denote the normalized objective



_J_ - _t_ ( _W_ ) = [1] _t_



_t_

- _∥KiW_ _−Vi∥_ [2] _F_ [+] _[α][t][∥][W]_ _[−][W]_ [0] _[∥]_ _F_ [2] [+] _[β][t][∥][K]_ [0] _[W]_ _[−][V]_ [0] _[∥]_ _F_ [2] _[.]_

_i_ =1



_**K**_ 0 _**C**_ _t_ _**K**_ 0 _[⊤]_ _[⪯]_ [1]



_µ_ [2] _**[P][K]**_ [0] _[,]_ (48)



_µ_ [1][2] _**[K]**_ [0][(] _**[K]**_ 0 _[⊤]_ _**[K]**_ [0][)] _[†]_ _**[K]**_ 0 _[⊤]_ [=] _µ_ [1]



where _PK_ 0 is the orthogonal projector onto Row( _**K**_ 0).
Therefore _∥_ _**K**_ 0 _**C**_ _t_ _**K**_ 0 _[⊤][∥]_ [2] _[≤]_ [1] _[/µ]_ [2][.]
Combining equation 43–equation 48 yields

_∥_ _**K**_ 0 _**C**_ _t_ _**K**_ _t_ _[⊤]_ _**[R]**_ _[t][∥]_ _F_ [2] _[≤]_ _µ_ [1][2] _[∥]_ _**[R]**_ _[t][∥]_ _F_ [2] _[,]_ (49)


which implies equation 38.
Finally, for equation 40, note that



_**S**_ _t_ = _λ_ [2] _**I**_ + _µ_ [2] _**K**_ 0 _[⊤]_ _**[K]**_ [0] [+]


  


_t_

- _**K**_ _i_ _[⊤]_ _**[K]**_ _[i]_

_i_ =1







_**I**_ _,_ (50)



_t_





- **Σ** [2] min [(] _**[K]**_ _[i]_ [)]


_i_ =1



_⪰_



_λ_ [2] + _µ_ [2] **Σ** [2] min [(] _**[K]**_ [0][) +]



Expand the data-fit term using _∥KiW −_ _Vi∥_ [2] _F_ =
tr( _W_ _[⊤]_ _Ki_ _[⊤][K][i][W]_ [)] _[ −]_ [2 tr(] _[W][ ⊤][K]_ _i_ _[⊤][V][i]_ [) +] _[ ∥][V][i][∥]_ _F_ [2] [to obtain]


_J_  - _t_ ( _W_ ) = tr� _W_ _[⊤]_ Σ [�] _K,tW_  - _−_ 2 tr� _W_ _[⊤]_ Σ [�] _KV,t_  - + _ct_
(56)
+ _αt∥W −_ _W_ 0 _∥_ [2] _F_ [+] _[ β][t][∥][K]_ [0] _[W][ −]_ _[V]_ [0] _[∥]_ _F_ [2] _[.]_


**Step 2: Proof of (i) (pointwise convergence).** Fix any _W_ .
By the assumed moment convergence Equation (17),


Σ� _K,t →_ Σ _K,_ Σ� _KV,t →_ Σ _KV ._


Moreover, by the bounded fourth-moment assumption
sup _i_ E _∥Vi∥_ [4] _F_ _[<][ ∞]_ [, we have][ sup] _i_ [E] _[∥][V][i][∥]_ [2] _F_ _[<][ ∞]_ [, so] _[ {][c][t][}]_
is tight and (along the same probability-1 event used for
the empirical-moment convergence) converges to the constant
E _∥V ∥_ [2] _F_ [. Finally,] _[ α][t][ →]_ _[α]_ [ and] _[ β][t][ →]_ _[β]_ [ by assumption. Taking]
limits in Equation (56) yields, for each fixed _W_,


_J_ - _t_ ( _W_ ) _−→_ tr� _W_ _[⊤]_ Σ _KW_ - _−_ 2 tr� _W_ _[⊤]_ Σ _KV_ - + E _∥V ∥_ [2] _F_
+ _α∥W −_ _W_ 0 _∥_ [2] _F_ [+] _[ β][∥][K]_ [0] _[W][ −]_ _[V]_ [0] _[∥]_ _F_ [2] _[.]_
(57)


The right-hand side equals _R_ ( _W_ ) + _α∥W −_ _W_ 0 _∥_ [2] _F_ [+]
_β∥K_ 0 _W −_ _V_ 0 _∥_ [2] _F_ [, i.e.,] _[ R]_ [ridge][(] _[W]_ [)][ up to an additive constant.]
This proves (i).


**Step 3: Proof of (ii) (strict convexity and uniqueness).**


_R_ ridge( _W_ ) = tr� _W_ _[⊤]_ Σ _KW_ - _−_ 2 tr� _W_ _[⊤]_ Σ _KV_ 
+ _α∥W −_ _W_ 0 _∥_ [2] _F_ [+] _[ β][∥][K]_ [0] _[W][ −]_ _[V]_ [0] _[∥]_ _F_ [2] [+][ const]
(58)


Its Hessian (with respect to _W_ ) is the linear operator


         -         _∇_ [2] _R_ ridge( _W_ ) = 2 Σ _K_ + _αI_ + _βK_ 0 _[⊤][K]_ [0] _,_ (59)


acting identically on each of the _dV_ columns. Under the assumption in Equation (17) that Σ _K ≻_ 0 (on the relevant subspace), and since _α, β ≥_ 0, the matrix Σ _K_ + _αI_ + _βK_ 0 _[⊤][K]_ [0]
is positive definite on that subspace. Hence _R_ ridge is strictly
convex and admits a unique minimizer _W_ _[†]_ . This proves (ii).


**Step 4: Proof of (iii) (consistency via closed form).** Because _J_ [�] _t_ is quadratic, its minimizer _Wt_ _[∗]_ [has the closed form]

_Wt_ _[∗]_ [=] �Σ� _K,t_ + _αtI_ + _βtK_ 0 _[⊤][K]_ [0] - _−_ 1�Σ� _KV,t_ + _αtW_ 0+ _βtK_ 0 _[⊤][V]_ [0] - _._
(60)
Similarly, the unique minimizer _W_ _[†]_ of _R_ ridge satisfies

_W_ _[†]_ = �Σ _K_ + _αI_ + _βK_ 0 _[⊤][K]_ [0] - _−_ 1�Σ _KV_ + _αW_ 0 + _βK_ 0 _[⊤][V]_ [0] - _._
(61)



hence _∥_ _**C**_ _t∥_ 2 = 1 _/λ_ min( _**S**_ _t_ ) implies equation 40.


_Proof of Theorem 4.1(ii) and the adaptive spectral variant._
Telescoping gives



_**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0] [=]



_T_
�( _**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [)] _[.]_ (51)

_t_ =1



Left-multiply by _**K**_ 0 and apply the triangle inequality:



_∥_ _**K**_ 0( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][)] _[∥][F]_ _[≤]_



_T_

- _∥_ _**K**_ 0( _**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [)] _[∥][F]_ _[.]_ (52)

_t_ =1



Applying Lemma A.1 with equation 38 termwise yields



_∥_ _**K**_ 0( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][)] _[∥][F]_ _[≤]_ [1]

_µ_



_T_

- _∥_ _**R**_ _t∥F,_ (53)


_t_ =1



which proves Theorem 4.1(ii).
For the adaptive spectral variant, apply instead equation 39
and equation 40:

_∥_ _**K**_ 0( _**W**_ _t_ _[∗]_ _[−]_ _**[W]**_ _[ ∗]_ _t−_ 1 [)] _[∥][F]_ (54)

_≤∥_ _**K**_ 0 _∥_ 2 _∥_ _**K**_ _t∥_ 2 _∥_ _**C**_ _t∥_ 2 _∥_ _**R**_ _t∥F_

_∥_ _**K**_ 0 _∥_ 2 _∥_ _**K**_ _t∥_ 2
_≤_ _∥_ _**R**_ _t∥F ._ (55)
_λ_ [2] + _µ_ [2] **Σ** [2] min [(] _**[K]**_ [0][) +] ~~[ �]~~ _[t]_ _i_ =1 **[Σ]** min [2] [(] _**[K]**_ _[i]_ [)]


Summing equation 55 over _t_ = 1 _, . . ., T_ gives the stated inequality.


By Equation (17) and _αt →_ _α_, _βt →_ _β_, the matrices and
right-hand sides in Equation (60) converge:


Σ� _K,t_ + _αtI_ + _βtK_ 0 _[⊤][K]_ [0] _[−→]_ [Σ] _[K]_ [+] _[ αI]_ [ +] _[ βK]_ 0 _[⊤][K]_ [0] _[,]_


Σ� _KV,t_ + _αtW_ 0 + _βtK_ 0 _[⊤][V]_ [0] _[−→]_ [Σ] _[KV]_ [+] _[ αW]_ [0] [+] _[ βK]_ 0 _[⊤][V]_ [0] _[.]_

By (ii), the limit matrix Σ _K_ + _αI_ + _βK_ 0 _[⊤][K]_ [0] [is invertible]
(on the relevant subspace), and matrix inversion is continuous
on the set of invertible matrices. Therefore, taking limits in
Equation (60) yields


_Wt_ _[∗]_ _−→_ _W_ _[†]_ _,_


along the same probability-1 event, which establishes almost
sure convergence. This proves (iii) and completes the proof.


**C. Useful limit regimes (hard constraints as limits)**


**Corollary A.2** (Hard limits from soft penalties) **.** _Fix T_
_and {_ ( _**K**_ _i,_ _**V**_ _i_ ) _}_ _[T]_ _i_ =0 _[, and assume the anchor condition equa-]_
_tion 27. Let_ _**W**_ _T_ _[∗]_ _[minimize equation 3 at time][ T][ and define]_

_**D**_ _T_ := _∥_ _**K**_ 0( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][)] _[∥][F]_ _[,]_ _**P**_ _T_ := _∥_ _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0] _[∥][F]_ _[.]_
(62)


_Then:_


_(i) (_ Hard anchor as _µ →∞_ . _) For any fixed λ ≥_ 0 _,_



1 _/_ 2




_**D**_ _T ≤_ [1]

_µ_




- _T_

 - _∥_ _**K**_ _i_ _**W**_ 0 _−_ _**V**_ _i∥_ [2] _F_


_i_ =1



**B** **Detailed Hyperparameter Settings**

For sequential editing experiments, we perform 10K edits for
all methods. For methods that support batch editing (MEMIT,
AlphaEdit, and RLSEdit), we use a batch size of 100. We edit
layers _{_ 4,5,6,7,8 _}_ for Llama3-8B and layers _{_ 7,8,9,10,11 _}_
for Qwen2.5-7B for these methods. For ROME, we edit a
single layer, using layer 5 for Llama3-8B and layer 11 for
Qwen2.5-7B. For RLSEdit regularization, on Llama3-8B, we
set _λ_ = 3 and _µ_ = 20000 and on Qwen2.5-7B, we set _λ_ = 0
and _µ_ = 12000.


**C** **General Capability Benchmarks**

Here we list the benchmarks used in general capability tests
(5 GLUE experiments, MMLU, GSM8K, HumanEval, and
MBPP).
**GLUE Tasks** involve:


 - SST (STANFORD SENTIMENT TREEBANK) [Socher
et al., 2013]: A sentence-level sentiment classification
task that predicts the sentiment polarity of a given sentence.

 - MRPC (MICROSOFT RESEARCH PARAPHRASE CORPUS) [Dolan and Brockett, 2005]: A sentence-pair task
that determines whether two sentences are paraphrases
of each other.

 - COLA (CORPUS OF LINGUISTIC ACCEPTABILITY) [Warstadt et al., 2019]: A grammatical acceptability task that predicts whether a sentence is linguistically
acceptable.

 - RTE (RECOGNIZING TEXTUAL ENTAILMENT) [Bentivogli et al., 2009]: A natural language inference (NLI)
task in a binary setting. Given a premise and a hypothesis, the model predicts whether the premise entails the
hypothesis.

 - NLI (NATURAL LANGUAGE INFERENCE; COMMONLY
MNLI-STYLE) [Williams et al., 2018]: A sentence-pair
inference task that predicts the semantic relation between a premise and a hypothesis.

MMLU (MASSIVE MULTI-TASK LANGUAGE UNDERSTANDING) [Hendrycks et al., 2020]: A task that measures
broad factual knowledge and reasoning.
GSM8K (GRADE SCHOOL MATH 8K) [Cobbe et al.,
2021]: A math word-problem dataset that evaluates step-bystep arithmetic reasoning.
HUMANEVAL [Chen et al., 2021]: A code generation
benchmark where models synthesize Python functions from
natural-language problem descriptions and are evaluated by
unit tests.
MBPP (MOSTLY BASIC PROGRAMMING PROBLEMS) [Austin et al., 2021]: A programming benchmark
consisting of short problem statements and test cases.


**D** **Case Study**

We present a representative example using task 0 from the
HumanEval dataset to highlight how long edit streams can degrade reasoning and code-generation quality for ALPHAEDIT
and MEMIT, while **RLSEdit** preserves this capability.



_hence as µ →∞,_ _**D**_ _T →_ 0 _._


_(ii) (_ Freezing as _λ →∞_ . _) For any fixed µ ≥_ 0 _,_



(63)


_,_ (64)



1 _/_ 2




_**P**_ _T ≤_ [1]

_λ_




- _T_

 - _∥_ _**K**_ _i_ _**W**_ 0 _−_ _**V**_ _i∥_ [2] _F_


_i_ =1



_hence as λ →∞,_ _**P**_ _T →_ 0 _, and consequently_ _**D**_ _T →_ 0
_as well._


_Proof._ Let Φ _T_ ( _**W**_ ) denote the objective equation 3 at time
_T_ . Since _**W**_ _T_ _[∗]_ [is the minimizer,][ Φ] _[T]_ [ (] _**[W]**_ _T_ _[ ∗]_ [)] _[ ≤]_ [Φ] _[T]_ [ (] _**[W]**_ [0][)][. Using]
_**K**_ 0 _**W**_ 0 = _**V**_ 0, we have



Φ _T_ ( _**W**_ 0) =



_T_

- _∥_ _**K**_ _i_ _**W**_ 0 _−_ _**V**_ _i∥_ [2] _F_ _[.]_ (65)

_i_ =1



_(i) µ →∞._ From Φ _T_ ( _**W**_ _T_ _[∗]_ [)] _[ ≤]_ [Φ] _[T]_ [ (] _**[W]**_ [0][)][,]

_µ_ [2] _∥_ _**K**_ 0 _**W**_ _T_ _[∗]_ _[−]_ _**[V]**_ [0] _[∥]_ _F_ [2] _[≤]_ [Φ] _[T]_ [(] _**[W]**_ _T_ _[ ∗]_ [)] _[ ≤]_ [Φ] _[T]_ [(] _**[W]**_ [0][)] _[.]_ (66)

Since _**D**_ _T_ = _∥_ _**K**_ 0( _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0][)] _[∥][F]_ [ =] _[ ∥]_ _**[K]**_ [0] _**[W]**_ _T_ _[ ∗]_ _[−]_ _**[V]**_ [0] _[∥][F]_ [, com-]
bining with equation 65 yields equation 63.
_(ii) λ →∞._ Similarly,


_λ_ [2] _∥_ _**W**_ _T_ _[∗]_ _[−]_ _**[W]**_ [0] _[∥]_ _F_ [2] _[≤]_ [Φ] _[T]_ [(] _**[W]**_ _T_ _[ ∗]_ [)] _[ ≤]_ [Φ] _[T]_ [(] _**[W]**_ [0][)] _[,]_ (67)


and equation 65 implies equation 64. Then _**D**_ _T_ _≤_
_∥_ _**K**_ 0 _∥_ 2 _**P**_ _T →_ 0.


Figure 5: **Case study on HumanEval task 0 (AlphaEdit).** The prompt above is the original statement of HumanEval/0. ALPHAEDIT
remains correct at 2k edits but begins to fail from 4k edits onward (boundary error), later exhibiting a semantic bug at 8k and degenerating
into near-empty/garbled output at 10k.


Figure 6: **Case study on HumanEval task 0 (RLSEdit).** In contrast to ALPHAEDIT, **RLSEdit** preserves a correct implementation across
all checkpoints (2k–10k).


Figure 7: **Case study on HumanEval task 0 (MEMIT).** Under long edit streams, MEMIT quickly degenerates into non-executable, garbled
or empty text outputs across checkpoints, unlike **RLSEdit** which preserves a valid implementation.


