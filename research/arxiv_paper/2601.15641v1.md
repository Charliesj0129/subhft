# Machine Failure Detection Based on Projected Quantum Models

Larry Bowden _[∗]_, Qi Chu _[∗]_, Bernard Cena _[∗]_, Kentaro Ohno _[†]_, Bob Parney _[‡]_, Deepak Sharma _[§]_, Mitsuharu Takeori _[†]_

_∗_ Digital, Woodside Energy, Perth, Australia

_†_ Quantum, IBM Research, Tokyo, Japan

_‡_ Quantum, IBM Research, New York, USA
_§_ Quantum, IBM Research, Melbourne, Australia



_**Abstract**_ **—Detecting machine failures promptly is of utmost**
**importance in industry for maintaining efficiency and minimizing**
**downtime. This paper introduces a failure detection algorithm**
**based on quantum computing and a statistical change-point**
**detection approach. Our method leverages the potential of**
**projected quantum feature maps to enhance the precision of**
**anomaly detection in machine monitoring systems. We empir-**
**ically validate our approach on benchmark multi-dimensional**
**time series datasets as well as on a real-world dataset comprising**
**IoT sensor readings from operational machines, ensuring the**
**practical relevance of our study. The algorithm was executed**
**on IBM’s 133-qubit Heron quantum processor, demonstrating**
**the feasibility of integrating quantum computing into industrial**
**maintenance procedures. The presented results underscore the**
**effectiveness of our quantum-based failure detection system,**
**showcasing its capability to accurately identify anomalies in noisy**
**time series data. This work not only highlights the potential of**
**quantum computing in industrial diagnostics but also paves the**
**way for more sophisticated quantum algorithms in the realm of**
**predictive maintenance.**
_**Index**_ _**Terms**_ **—Anomaly** **detection,** **change-point** **detection,**
**quantum machine learning**


I. INTRODUCTION

In the rapidly evolving industrial landscape, the ability to
predict and prevent machine failures has become a critical
necessity [1]. Traditional methods of fault detection, often
reliant on periodic inspections or reactive maintenance strategies, fall short in addressing the nuanced patterns indicative
of impending failures. These limitations result in unplanned
downtime, reduced productivity, and escalating maintenance
costs. Consequently, there is a pressing need for advanced,
proactive diagnostic tools capable of identifying and mitigating
potential failures before they cause significant disruptions.
Recent advancements in machine learning technology have
opened new avenues for enhanced industrial diagnostics [2],

[3]. Powerful data-driven models can learn from historical and
real-time data to predict machine behavior and detect anomalies that may signal impending failures. Despite the progress,
however, achieving high precision is still a challenging task,
especially for multidimensional time series [4], [5].
This paper explores the integration of quantum computing
with machine learning to engineer a superior failure detection
algorithm tailored for industrial applications, in the light
of the recent remarkable progress in the field of quantum
computing [6]–[9]. Quantum computers, with their unique



computational capabilities, could be utilized to recognize complex patterns that are beyond the reach of classical computing
systems [10]. In this context, we investigate the potential
of quantum computing in developing a cutting-edge failure
detection algorithm for machine health monitoring.
Our approach combines the theoretical framework of projected quantum models [11] with a statistical change-point
detection technique [12], as schematically shown in Fig. 1.
The machine failure detection is formulated as a changepoint detection problem that can be approached with statistical
methods such as density ratio estimation [13], [14]. Projected
quantum models are a class of quantum machine learning
models proposed as an alternative to traditional quantum
kernel methods [15]. The hybrid methodology would enable
us to identify subtle anomalies in multidimensional machine
operation data, thereby facilitating timely interventions and
preventive maintenance.
To empirically validate the effectiveness of our proposed
framework, we evaluate our methodology on two benchmark
datasets of multi-dimensional change-point detection. The
observations of the behavior of our proposed quantum model
demonstrate the potential of quantum feature transformation to
effectively identify change-points in complex time series. We
also employed a real-world dataset derived from IoT sensor
readings of operational machines. This dataset, encompassing
a wide range of operating conditions and failure modes,
provides a practical and relevant context for evaluating our
method. The algorithm was implemented and tested on IBM’s
133-qubit quantum processor, demonstrating the feasibility and
scalability of integrating quantum computing into industrial
maintenance procedures. The results of our study underscore
the potential of quantum-based failure detection systems in
improving machine reliability and reducing maintenance costs.
Although the practical application at present carries computational overhead of quantum workload that may not guarantee
superior speed over classical computing methods, our findings
highlight the transformative potential and broader implications
of quantum computing in the realm of predictive maintenance.
The outline of this paper is as follows. Machine failure detection is formulated and an existing statistical approach is reviewed in Section II. We provide a methodological background
for projected quantum models in Section III. Our framework
for machine failure detection is introduced in Section IV.


Normal Period Target Period


Projected Quantum
Feature Extraction


Sliding Windows



Time



Divergence Estimation


Normal Data Target Time Window


Score

Behavior Change

Detected!


Time



Fig. 1: Overview of the proposed framework for machine failure detection based on projected quantum feature extraction
and statistical change-point detection approach. Original feature vectors obtained from sensors are transformed to projected
quantum features of dimension _d_ _[′]_ that depends on the quantum circuit used for transformation. New feature vectors are used for
statistical divergence estimation to measure anomaly score _as_ . Large _as_ implies that a fault has likely occurred on a machine.



The experimental results are presented in Section V. Lastly,
Section VI concludes this paper.


II. STATISTICAL CHANGE-POINT DETECTION

In this section, we formalize the machine failure detection
problem as a statistical change-point detection problem on
multi-variate time series.


_A. Problem setting_

First, we describe the generic assumptions for time series
data under consideration.

**Multidimensionality** : Each timestamp is associated with
multiple data values, e.g., readings from multiple sensors.
**Access to Normal Data** : Data of a certain period of time
during which the machines are in normal operation are
available.
**Stationarity** : The machines are in a steady state in a wide
sense, i.e., the sensor data may contain some periodicity
and other general stationary behavior, under normal operations, while the data are subjective to certain amount of
noise.
**Persistent Behavior Change due to Failure** : Once a
failure occurs, the machine behavior changes persistently
until it is fixed.
For detecting the behavior change on time series, we can
make use of statistical change-point detection methods [12].
Since our task is to detect machine failures as soon as possible
after obtaining anomalous data, it is an _online_ detection task.
It is also _unsupervised_ as only normal data are available.



Statistical approaches to unsupervised change-point detection
are typically categorized into parametric and non-parametric
methods. The latter are often more scalable and robust than the
former when applied to change-point detection in stationary
processes [12], thus are suitable in our setting. In these
approaches, the target time series is divided into time windows
of appropriate size, each of which is considered as a dataset
or empirical probability distribution. Time windows containing
timestamps after the anomaly occurrence will be statistically
discriminated from the normal distribution, thereby enabling
detecting the behavior change.
Let _X_ = _{xt}t_ =1 _,...,T_ denote the given target and normal
time series, where _xt_ are _d_ -dimensional vectors for each
timestamp _t_ . We assume a sub dataset _X_ [norm] = _xt_ _t_ 1 _≤t≤t_ 2
_{_ _}_
on an interval [ _t_ 1 _, t_ 2] is a normal dataset, i.e., does not contain
anomalies. Given window length _L >_ 0 and sliding width
_w >_ 0, time windows are formally defined as


_Xs_ = _{xt}t_ = _sw,...,sw_ + _L, s_ = 1 _,_ 2 _, . . . ._ (1)


With this notation, the task is to measure the statistical
divergence _as_ between distributions of _X_ [norm] and _Xs_ for
each _s_, which is viewed as a score representing how likely
an anomaly or change has occurred.
Despite huge technical advances in change-point detection
algorithms, highly precise detection is still challenging, especially for multidimensional data [4], [5]. Among the existing
methods, _density ratio estimation_ [14], [16] is empirically
the most powerful non-parametric approach to change-point


detection [12]. Therefore, we incorporate quantum modeling
into this approach to enhance its accuracy.


_B. Computing Divergence via Density Ratio Estimation_


We briefly review the density ratio estimation approach to
computing statistical divergence between normal and target
sample sets.
Let _p_ ( _x_ ) and _p_ _[′]_ ( _x_ ) be density functions representing probability distributions on a domain in R _[d]_ . Density ratio estimation
is to estimate the ratio function _r_ ( _x_ ) := _p_ ( _x_ ) _/p_ _[′]_ ( _x_ ) of the
density functions using sample sets for these distributions.
The ratio _r_ ( _x_ ) can be used to calculate the divergence of two
probability distributions. For example, the Pearson divergence
PE( _p ∥_ _p_ _[′]_ ) is written as


          PE( _p ∥_ _p_ _[′]_ ) = ( _r_ ( _x_ ) _−_ 1) [2] _p_ _[′]_ ( _x_ ) d _x_ (2)



Ignoring the last term, which is constant, and approximating
the expectation by empirical averages, the following objective
is obtained:



1
_J_ ˆ( _α_ ) =
2 _n_ _[′]_



_n_ _[′]_





- _g_ ( _x_ _[′]_ _i_ [;] _[ α]_ [)][2] _[ −]_ [1]

_n_

_i_ =1



_n_



_n_

- _g_ ( _xi_ ; _α_ ) (8)

_i_ =1



_m_

- _αjh_ [ˆ] _j,_ (9)

_j_ =1



_m_




= [1]

2



_m_


_αjαj′H_ [ˆ] _j,j′_
_−_
_j,j_ _[′]_ =1



_m_




where


_H_ ˆ _j,j′_ = [1]

_n_ _[′]_




- _ηj_ ( _x_ _[′]_ _i_ [)] _[η][j][′]_ [(] _[x][′]_ _i_ [)] _[,]_ _h_ ˆ _j_ = [1]

_n_

_i_ =1



_n_



_n_ _[′]_




_n_

- _ηj_ ( _xi_ ) _._ (10)

_i_ =1



= [1]

2




_r_ ( _x_ ) _p_ ( _x_ ) d _x_ (3)
_−_ 2 [1] _[.]_



Adding a regularization term _λ∥α∥_ [2] with a positive number
_λ >_ 0 to _J_ [ˆ] ( _α_ ), a minimizer is analytically derived as

_α_ ˆ := ( _H_ [ˆ] + _λIm_ ) _[−]_ [1] _h._ [ˆ] (11)

To assure the positivity of the model function _g_ ( _x_ ; ˆ _α_ ), we
truncate the negative part of ˆ _α_ :



The point in directly estimating the ratio _p_ ( _x_ ) _/p_ _[′]_ ( _x_ ) instead
of estimating _p_ and _p_ _[′]_ first and taking the quotient of them is
to avoid the accumulation of approximation errors [13].
Algorithms for density ratio estimation consists of two
steps: modeling the ratio function with a suitable function and
solving a minimization problem to fit the model to the actual
density ratio function. In this work, we employ a method called
unconstrained least-squares importance fitting (uLSIF) [16]
since the minimization can be solved analytically, thereby
offering a fast and stable computational solution [13]. Let
_X_ = _{x_ 1 _, . . ., xn}_ and _X_ _[′]_ = _{x_ _[′]_ 1 _[, . . ., x][′]_ _n_ _[′][}]_ [ denote sample]
sets from _p_ ( _x_ ) and _p_ _[′]_ ( _x_ ), respectively. In uLSIF, the ratio
function is modeled by the following linear function:



_α_ ˆ _j_ max(0 _,_ ˆ _αj_ ) for _j_ = 1 _, . . ., m._ (12)
_←_



Using the obtained function ˆ _g_ ( _x_ ) := _g_ ( _x_ ; ˆ _α_ ), we can estimate
the Pearson divergence PE( _p ∥_ _p_ _[′]_ ) between _p_ and _p_ _[′]_ as



(13)
2 _[.]_



PE(� _X_ _, X_ _[′]_ ) := 2 [1] _n_



_n_





- _g_ ˆ( _xi_ )

_−_ [1] 2
_i_ =1



_g_ ( _x_ ; _α_ ) :=



_m_

- _αjηj_ ( _x_ ) _,_ (4)

_j_ =1



where _ηj_ ( _x_ ) is a basis function. Typically, _ηj_ ( _x_ ) is defined
as follows using a subsample _xij_ and a Gaussian radial
basis function (RBF) kernel _k_ : R _∈X_ _[d]_ _×_ R _[d]_ _→_ R with a scale
parameter _l >_ 0:




       _ηj_ ( _x_ ) := _k_ ( _x, xij_ ) = exp _−_ _[∥][x][ −]_ 2 _l_ _[x]_ [2] _[i][j]_ _[∥]_ [2]




_._ (5)



The overall complexity of the algorithm is _O_ ( _m_ [3] + _n_ + _n_ _[′]_ ).


III. PROJECTED QUANTUM MODELS

In this section, we review the projected quantum model [11],
which is the core of our method. The projected quantum model
is invented based on the careful analysis of a necessary condition for potential quantum advantage in quantum machine
learning, working around a critical issue in traditional quantum
kernel methods. Below, we show a specific form of projected
quantum models, referring to the original paper [11] for the
analysis results.
Consider a parametrized quantum circuit representing a
unitary operator _U_ ( _θ_ ) with a parameter vector _θ_ . Let _nq_
be the number of qubits. We assume _θ_ is _d_ -dimensional,
that is, has the same dimension as a data point _x ∈_ R _[d]_ .
For each data point _x_, the quantum circuit maps the initial
state _|ψ⟩_ to _|ϕ_ ( _x_ ) _⟩_ := _U_ ( _x_ ) _|ψ⟩_ . Let _ρ_ ( _x_ ) denote a density
matrix corresponding to _|ϕ_ ( _x_ ) _⟩_ . In projected quantum models,
we take projection of _ρ_ ( _x_ ) rather than using _ρ_ ( _x_ ) itself to
represent a quantum feature of _x_ . In this study, we employ oneparticle reduced density matrix (1-RDM) _ρk_ ( _x_ ) _, k_ = 1 _, . . ., nq_
obtained by projecting _ρ_ ( _x_ ) to each qubits:


_ρk_ ( _x_ ) := Tr _j_ = _k_ [ _ρ_ ( _x_ )] _._ (14)

While the projection apparently loses information on entanglement of quantum states, it can actually help improving
prediction accuracy of machine learning models [11]. On the
basis of this fact, the main idea in this work is to build a
detection model based on the 1-RDM features instead of the



The parameters _α_ = ( _α_ 1 _, . . ., αm_ ) are determined so that the
following squared error _J_ is minimized:



�2
_p_ _[′]_ ( _x_ ) d _x_ (6)



_J_ ( _α_ ) = [1]

2



��
_g_ ( _x_ ; _α_ )
_−_ _p_ _[p][′]_ [(] ( _[x]_ _x_ [)] )



= [1]

2




- _g_ ( _x_ ; _α_ ) [2] _p_ _[′]_ ( _x_ ) d _x −_ _g_ ( _x_ ; _α_ ) _p_ ( _x_ ) d _x_



+ [1]

2




- _p_ ( _x_ )2

(7)
_p_ _[′]_ ( _x_ ) [d] _[x.]_


original feature vectors. In practice, it is useful to represent
_ρk_ ( _x_ ) in the Pauli basis ( _σ_ 0 _, σ_ 1 _, σ_ 2 _, σ_ 3) = ( _I, X, Y, Z_ ) as



_|_ 0 _⟩_ _U_ 1


_|_ 0 _⟩_ _U_ 2


_|_ 0 _⟩_ _U_ 3


_|_ 0 _⟩_ _U_ 4



_RZZ_ ( _tθ_ 0) _RY Y_ ( _tθ_ 0) _RXX_ ( _tθ_ 0)


_RZZ_ ( _tθ_ 1) _RY Y_ ( _tθ_ 1) _RXX_ ( _tθ_ 1)



_ρk_ ( _x_ ) =



3

- _ck,iσi_ (15)

_i_ =0



_RZZ_ ( _tθ_ 2) _RY Y_ ( _tθ_ 2) _RXX_ ( _tθ_ 2)



with real coefficients _ck,i, i_ = 0 _,_ 1 _,_ 2 _,_ 3. Note that each
coefficient satisfies

_ck,i_ = [1] (16)

2 [Tr(] _[ρ][k][σ][i]_ [)] _[,]_

resulting in _ck,_ 0 = 1 _/_ 2. The rest coefficients _ck,_ 1 _, ck,_ 2 _, ck,_ 3
can be computed on a gate-based quantum computer by taking
expected values of observables


_I_ _[⊗][n][q][−][k]_ _σi_ _I_ _[⊗][k][−]_ [1] _,_ _i_ = 1 _,_ 2 _,_ 3 (17)
_⊗_ _⊗_

for the quantum state _|ϕ_ ( _x_ ) _⟩_ . By concatenating them over _k_ =
1 _, . . ., nq_, we obtain a new feature vector

_x_ ˜ := ( _c_ 1 _,_ 1 _, c_ 1 _,_ 2 _, c_ 1 _,_ 3 _, c_ 2 _,_ 1 _, . . ., cnq,_ 3) R [3] _[n]_ (18)
_∈_

representing 1-RDM of all qubits. We call ˜ _x_ the projected
quantum feature of _x_ . By appropriately choosing the quantum
circuit for _U_ ( _θ_ ), computing projected quantum features can
be neither classically simulatable nor learnable by classical
machine learning models [11].


IV. PROPOSED METHOD

Based on notions introduced in the previous sections, we
present a machine failure detection workflow utilizing quantum computers.
Our method consists of the following procedures, as described in Fig. 1. Let _X_ = _{xt}t_ =1 _,...,T_ and _X_ [norm] =
_{xt}t_ 1 _≤t≤t_ 2 be given target and normal time series. First, we
convert the original time series data _X_ into a sequence of
1-RDM projected quantum features _X_ [˜] = _x_ ˜ _t_ by running a
_{_ _}_
certain quantum circuit _U_ ( _xt_ ) on a quantum computer for each
_t_ = 1 _, . . ., T_ . Let _X_ [˜] [norm] = _{x_ ˜ _t}t_ 1 _≤t≤t_ 2 denote the sequence
of normal data converted into projected quantum features.
Then, we create sliding time windows _X_ [˜] _s, s_ = 1 _,_ 2 _, . . ._ from
the new time series _X_ [˜] following the same way in Section II-A.
The anomaly score _as_ for each time window _X_ [˜] _s_ is computed
as the estimated Pearson divergence

_as_ = PE( [�] _X_ [˜] [norm] _,_ _X_ [˜] _s_ ) (19)

by running uLSIF for two sample sets _X_ ˜ [norm] _,_ ˜ _Xs_ on a
classical computer. Timestamp _s_ having a large value of _as_
is viewed as the time after the anomaly or machine failure
occurred. This detection is done by thresholding _as_ and the
threshold might be adjusted during the machine operation.


V. EXPERIMENTS

We conduct numerical experiments to validate the proposed
method. First, we investigate the effect of quantum feature
transform in the change-point detection setting using simulation of quantum circuits. Then, we test our approach to failure
detection on actual industrial time series data using quantum
hardware as well as a simulator. On each experiment, our



repeat _p_ times


Fig. 2: Schematic diagram of the quantum circuit in our
experiment for _nq_ = 4. _U_ 1 _, . . ., U_ 4 are Haar-random unitary
gates with a fixed random seed and _RXX_ _, RY Y, RZZ_ are 2qubit rotation gates with respect to _XX, Y Y, ZZ_, respectively.
_t_ is set to a fixed constant and _θ_ represents feature vectors.


method is compared with the uLSIF method without the use of
quantum feature transform to observe how quantum modeling
changes the behavior of the algorithm.


_A. Experiment Setup_

We use a quantum circuit based on 1-dimensional Heisenberg Hamiltonian, inspired by earlier work [11], [17]. The
choice is motivated by the expectation that this circuit is hard
to simulate and resistant against ‘dequantization’ [18] unlike
other common circuit proposed in previous research [19].
Additionally, its use aligns with recent simulation efforts
in quantum chemistry and material science [20], signifying
potential for a clear separation from classical computing
methods. For another choice of the circuit, see Appendix A.
We describe the circuit used in our experiments. For a
system of _nq_ qubits, we define



_⌊nq/_ 2 _⌋_

- _θ_ 2 _iσ_ 2 _iσ_ 2 _i_ +1

_i_ =1



_Hσσ_ [even] =



_⌊nq/_ 2 _⌋_

- _θ_ 2 _i−_ 1 _σ_ 2 _i−_ 1 _σ_ 2 _i,_ _Hσσ_ [odd] [=]

_i_ =1



for each Pauli operator _σ ∈{X, Y, Z}_ . Then, the quantum
circuit is defined by

_U_ ( _θ_ ) =    - _G_ ( _HXX_ [odd][)] _[G]_ [(] _[H]_ _Y Y_ [odd][)] _[G]_ [(] _[H]_ _ZZ_ [odd][)]

_G_ ( _HXX_ [even][)] _[G]_ [(] _[H]_ _Y Y_ [even][)] _[G]_ [(] _[H]_ _ZZ_ [even][))] _[p][,]_ (20)

where _G_ ( _H_ ) = exp( _−itH_ ) with some constant _t >_ 0. The
initial state _ψ_ = _i_ _ψi_ is defined as a separable state
_|_ _⟩_ _⊗_ _|_ _⟩_
consisting of Haar-random single-qubit quantum state _ψi_
_|_ _⟩_
(the random state is fixed over all data for consistency). We
set _p_ = 1 so that the circuit is not too deep for obtaining
meaningful results from hardware. We fix the value of _t_ to
0.5 on the basis of a preliminary experiment where we test
_t ∈_ [0 _._ 1 _,_ 2] on the synthetic data below and take the value
yielding the most stable outputs. The number of qubits is
_nq_ = _d_ +1 where _d_ is the feature dimension so that the number
of parameters is matched to the feature dimension of the data.
The circuit diagram for _nq_ = 4 is shown in Fig. 2. The data
point _x_ is encoded as _θ_ = arctan( _x_ ) to bound the encoding
angle to [ _−π/_ 2 _, π/_ 2]. For datasets used in our experiments,
_nq_ is small enough to simulate the quantum circuit exactly.
Therefore, we compute 1-RDM features with a state vector
simulator using Qiskit 1.2.0 [21].


(b) Change scores.



(a) Data values.



(c) 1-RDM feature values.







(b) Change scores.



(c) 1-RDM feature obtained by
observables _IIIIY_ and _IZIII_ .



Fig. 3: Experiments on 2-dimensional synthetic data. Changepoints are represented by black dotted lines.


_B. Change-Point Detection Experiments_

We evaluate how the quantum feature transform changes the
behavior of detection algorithms on existing multi-dimensional
change-point detection datasets. To qualitatively observe the
effect of the quantum model, we deliberately choose smallscale datasets, allowing clear visualization and exact simulation of quantum circuits. Unlike the failure detection problem
having only one change-point, the time series in the datasets
have multiple change-points representing transitions between
possible states. In this problem setting, normal data do not
exist and instead, each target time window is compared with
an adjacent time window that also slides along the time axis.
Specifically, by setting _w_ = 1 in Eq. (1), we compute the
divergence between _Xs_ (or _X_ [˜] _s_ ) and _Xs−L_ (or _X_ [˜] _s−L_ ) which
we call the _change score_ . Change-points are detected at points
where the score takes a peak.
For the parameters in uLSIF, the regularization coefficient
is fixed to _λ_ = 0 _._ 1, as we found that varying the value does
not significantly change the output. The stability of the uLSIF
method heavily depends on the scale parameter _l >_ 0 in
Eq. (5). Therefore, we vary _l_ for a certain range and report
the best value giving the smallest noisy deviation.
_1) Synthetic Data:_ We follow the data generation protocol
in the existing study [14] to produce 2-dimensional synthetic
data. Specifically, we take a sample at each timestamp _t_ from
the origin-centered normal distribution with covariance matrix



(a) Data values.



5 500

5 500 1

_−_ [4] _[−]_ _[N]_ _[−]_ [2]



5 500

[4] _[−]_ _[N]_ _[−]_ [2]



500 1




1 5

_−_ [4]







(21)



5 500

[4] _[−]_ _[N]_ _[−]_ [2]







Fig. 4: Experiments on bee-waggling data. Change-points are
represented by black dotted lines.


For computing the change score, the window length _L_ is
set to 50. The basis function in Eq. (5) is computed using the
first 50 data points, resulting in 50 basis functions. The scale
parameter _l_ in Eq. (5) is varied over _{_ 0 _._ 5 _,_ 1 _,_ 2 _,_ 5 _}_, and the
reported best value is _l_ = 1 and _l_ = 5 for the classical and
quantum detection model, respectively.
The change scores obtained by usual uLSIF (‘Classical’)
and uLSIF on 1-RDM feature (‘Quantum’) are shown in
Fig. 3(b). While the classical model already detects the
change-points fairly well, we see that the quantum model
emphasizes them better by showing clearer peaks. To investigate the reason of this result, we plot the computed 1-RDM
feature vectors in Fig. 3(c). Interestingly, it is observed that the
behavior change (alternating between two states) in the data
are clearly visualized for several dimensions in the 1-RDM
feature. We consider that this separation makes it easier for
the model to capture the change-points.
_2) Bee Waggle Dance Data:_ We take a public time series
dataset for change-point detection from the existing study [22].
The dataset contains two 2-dimensional time series ( _apple_,
_run log_ ) and two 4-dimensional time series ( _bee waggle 6_,
_occupancy_ ). We choose _bee waggle 6_ data (Fig. 4(a)) for our
test, since other sequences contains a number of discontinuous points and most change-points can be detected only by
monitoring such discontinuity.
The window length is set to 150 and the basis function is
computed using the first 150 data points. The scale parameter
_l_ is varied over _{_ 1 _,_ 5 _,_ 10 _,_ 20 _}_ and _l_ = 10 is found to be the
best for both classical and quantum models.
The change scores are shown in Fig. 4(b). We see that
the quantum model detects the two change-points accurately,
while the usual uLSIF model is missing the second changepoint. Meanwhile, the quantum score takes several peaks on



Σ =








5 500 _N_ = 1 _,_ 3 _,_ 5 _, . . ._

5 500 1

- _−_ [4] _[−]_ 1 _[N]_ _[−]_ [2] 45 [+] _[N]_ 500 _[−]_ [2] 






5 500

45 [+] _[N]_ 500 _[−]_ [2] 1



500 1



_N_ = 2 _,_ 4 _,_ 6 _, . . ._



for _t ∈_ [100( _N −_ 1) _,_ 100 _N_ ]. Fig. 3(a) shows the generated
data. Note that the changes are not clearly visible in the data.


(a) Sequence 1.



(b) Sequence 7.



Fig. 5: Examples of time series data collected from IoT devices. For visibility, the dimension of plotted feature vectors are
reduced from 13 to 5 by using the top five significant principal components (PCs). PC _i_ represents the feature value projected
onto the _i_ -th principal component. Normal period (blue shaded) is used as reference data distribution to compute the statistical
divergence to each target time window. Anomaly period (red shaded) is annotated as ground truth.



the low-score regime, possibly interpreted as the false-positive.
Practically, these models could be used selectively taking the
difference in the model behavior and the tradeoff between
sensitivity and specificity into account. We also plot 1-RDM
feature values of major two dimensions that visually well
describe the state transition in Fig. 4(c). Unlike the original
data, we observe abrupt changes in 1-RDM feature aligned
with change-points, which presumably improves the model
accuracy.


_C. Machine Failure Detection on Sensor Data_

We validate the proposed method on actual industrial data
with quantum device as well as the simulator.
_1) Dataset Description:_ We introduce the real-world sensor
data used in this experiment. The data streams were collected
with IoT devices monitoring vibration of fin fan coolers
on propane condenser heat exchangers. A data point was
recorded for every 30 minutes. After preprocessing in the
devices, the feature vector at each timestamp is given as 13
dimensional features including acceleration and accumulated
velocity characterizing vibration. Our task is to detect vibration
anomalies for fans and motors of fans such as belt damage or
fan bearing defect. Anomaly labels are defined on some data
sequences as a period by domain experts, which are used as
the ground truth for the evaluation of models.
We used the labeled sequences of a period from 2023-09-15
to 2024-05-20. The normal period is set to the first 30 days and
the rest is treated as a target period, from which we created
target time windows of length 7 days with a sliding width of 1
day. The sequences including an anomaly in the first 30 days
are excluded from the evaluation. As a result, seven sequences
were chosen for evaluation.
The original dataset has around 5000 timestamps in each
sequence. Since computing 1-RDM for this large amount of
data points could be expensive on current quantum computers,
we averaged the data over each day to create a smaller dataset.
The length of resulting sequences are around 200. Although
the aggregation might change the performance of the change


point detection algorithm, we confirm that it does not change
the result significantly in our case, see Appendix B for details.
_2) Computational Setup:_ We execute the quantum circuit
on real quantum hardware in addition to the simulator. For
the hardware experiments, ibm_torino, a 133-qubit Heron
device, is used with TREX [23] for error mitigation. The
number of shots for estimating 1-RDM of each data point
is set to 8192.
For applying uLSIF, the number of the basis functions _ηj_
equals to the number of data points in the normal period. The
scale parameter _l >_ 0 is varied for _l_ = _{_ 0 _._ 1 _,_ 1 _,_ 10 _}_ and the
most stable result is obtained with _l_ = 1 for the classical
model and _l_ = 0 _._ 1 for the quantum model.
_3) Results:_ First, we make a qualitative observation on the
behavior of detection models taking two sequences, Sequence
1 and 7, from the dataset. The time series are plotted in Fig. 5.
Since plotting 13-dimensional time series could be messy, we
reduced the feature dimension to 5 using principal component
analysis (PCA) in the figure, where the principal components
are computed using the data of the normal period. Fig. 6
shows the output _as_ of the classical and quantum models,
which is computed by uLSIF as _as_ = PE( [�] _X_ [norm] _, Xs_ ) for
classical and _as_ = PE( [�] _X_ [˜] [norm] _,_ _X_ [˜] _s_ ) for quantum, respectively.
On Sequence 1, the classical and quantum models perform
similarly: _as_ is small before the anomaly period and large on
the anomaly period, indicating that both models successfully
detect the machine failure. Additionally, the score obtained by
the hardware execution is well aligned to the simulator result.
This shows that the hardware is producing outputs close to
theoretical values, and we expect this behavior to hold true
even on larger scales that cannot be simulated classically.
Sequence 7 is another instance that involves more noise with
respect to the first principal component as shown in Fig. 5(b).
On this sequence, the score _as_ obtained from the classical
model takes large values on most timestamps as shown in
Fig. 6(b), leading to the false positive prediction. By contrast,
the quantum model outputs large scores only on the anomaly
period. This result indicates that the quantum model is more


(a) Sequence 1.



(b) Sequence 7.





Fig. 6: Anomaly score _as_ computed by uLSIF methods on raw features and projected quantum features. The scores are divided
by the maximum over the whole period for ease of comparison. Values on the x-axis correspond to the end of the time window
for which the score is calculated. Therefore, the scores are plotted from 2023-10-21, the last day of the first target time window
after the normal period.















(a) Sequence 1.



(b) Sequence 7.



Fig. 7: 1-RDM feature vectors plotted with dimensionality reduction by PCA as in Fig. 5.



TABLE I: AUC Scores on Real Industrial Time Series.


~~Quantum~~ ~~Quantum~~
Classical (Simulator) (Hardware)
~~Sequence 1~~ **0.994** ~~0.988~~ ~~0.981~~
Sequence 2 0.921 0.965 **0.971**
Sequence 3 0.973 **0.997** 0.996
Sequence 4 0.843 **1.000** **1.000**
Sequence 5 0.957 **0.993** 0.991
Sequence 6 0.973 **1.000** **1.000**
Sequence 7 0.940 **1.000** **1.000**


robust to noise in the data. To observe this effect more clearly,
we plot the obtained 1-RDM feature in Fig. 7. From the
figure, we confirm that the noisy behavior in the original data
of Sequence 7 has indeed disappeared. On the other hand,
on Sequence 1, the transformed data look noisier than the
original data over the period before the anomaly, which could
be the reason why the quantum anomaly score is higher than
the classical one over that period. These results provide the
insights into how quantum models deal with data noise, which
is an interesting future direction in quantum machine learning
research.
Next, we quantitatively evaluate the model performance.
The anomaly period can be viewed as labels for data points
in a time series, hence we can define the ROC-AUC score for



a labeled sequence. This metric represents the performance
of detection models taking the trade-off between the true
positive and false positive into account without specifying the
threshold. Table I shows AUC scores on test sequences. The
quantum model outperforms the classical model on 6 out of 7
test instances. The result indicates the potential of incorporating quantum feature transformation into traditional detection
models. Again, the hardware results are mostly similar to the
simulator results, which suggests that application of near-term
quantum computers to this task would be feasible enough.
Beyond evaluating the models using the AUC score, we further
investigate the practical performance based on other metrics
by setting the following threshold for the anomaly score. We
take the first seven anomaly scores after the normal period
and set the threshold as a constant multiple of the mean of the
scores. This constant should be determined by trial operation
on different data in practice, but here we choose a value that
results in comparable false positive alert rates between our
classical and quantum models, to enable explicit comparison
between the models. Specifically, the constant is set to 1.5 for
the classical model and 3 for the quantum model. Table II
shows the number of false alerts, i.e., the timestamps before
the anomaly with the score exceeding the threshold. The result
of the time to detection for each model are shown in Table III.


TABLE II: Number of False Alerts.


~~Quantum~~ ~~Quantum~~
Classical (Simulator) (Hardware)
~~Sequence 1~~ ~~53~~ ~~57~~ ~~46~~
Sequence 2 14 12 12
Sequence 3 27 0 0
Sequence 4 80 29 68
Sequence 5 0 6 3
Sequence 6 36 20 11
Sequence 7 0 27 42


TABLE III: Detection Time for Machine Failure.


~~Ground~~ ~~Quantum~~ ~~Quantum~~
Truth Classical (Simulator) (Hardware)
~~Seq. 1~~ ~~2024-03-16~~ ~~2024-03-16~~ ~~2024-03-16~~ ~~2024-03-17~~
Seq. 2 2024-01-13 2024-01-13 2024-01-13 2024-01-13
Seq. 3 2024-01-13 2024-01-13 2024-01-13 2024-01-13
Seq. 4 2024-03-10 2024-03-26 2024-03-26 2024-03-26
Seq. 5 2024-03-01 Not Detected 2024-03-01 2024-03-01
Seq. 6 2024-03-25 2024-03-27 2024-03-25 2024-03-25
Seq. 7 2024-03-25 Not Detected 2024-03-25 2024-03-25


We observe that the quantum model successfully detects the
anomaly on all sequences, while keeping the number of the
false alerts relatively small. Overall, these results demonstrate
the practical utility of the proposed quantum approach to
failure detection.


VI. CONCLUSION AND FUTURE PERSPECTIVE


We introduced a machine failure detection framework based
on a quantum machine learning approach. We empirically
validated the practical utility of projected quantum models
for fault detection in a real-world scenario as well as on
benchmark datasets. This study’s contribution lies in the
empirical exploration of quantum computing applications on
industrial data using a real quantum device, paving the way for
further investigations into harnessing the full potential of quantum computing in practice. The exact reasons why projected
quantum models yield precision improvements, particularly on
noisy time series, remain unclear, posing intriguing challenges
for future research. In particular, behavior analysis of the
quantum feature extraction from the perspective of Fourier
analysis [24] for example would be an essential step toward
understanding the impact on the performance of the detection
model.


APPENDIX


_A. Experiments with Two-Local Circuit_

In addition to the Heisenberg Hamiltonian circuit in the
main text, we tested a circuit called the two-local circuit with
alternating Z-rotation and CX gates as shown in Fig. 8. We
set the number of layer _p_ to 1. We plot the change scores
on change-detection experiments in Fig. 9. We see similar
results with those in the main text, while the second peak is
slightly less emphasized on the bee waggle dance data. Further
exploration of quantum circuits suited for our application is
left as future work.



_|_ 0 _⟩_ _RZ_ ( _θ_ 1)


_|_ 0 _⟩_ _RZ_ ( _θ_ 2)


_|_ 0 _⟩_ _RZ_ ( _θ_ 3)


_|_ 0 _⟩_ _RZ_ ( _θ_ 4)



_CX_


_CX_



_CX_



repeat _p_ times


Fig. 8: Schematic diagram of two-local quantum circuit for
_nq_ = 4 with parameters _θ_ .





(a) Synthetic data.







(b) Bee waggle dance data.



Fig. 9: Change-point scores with two-local ansatz.


_B. Experiments on Raw-resolution Dataset_

Table IV summarizes the AUC results on raw-resolution
datasets without averaging over each day. In this experiment,
the number of the basis functions was set to _m_ = 64 and the
regularization coefficient was _λ_ = 0 _._ 1 for uLSIF. In comparison with the results on the daily data (Table I), the AUC scores
slightly improves on most cases. The reason is possibly that
the statistical divergence estimation gets more accurate with
the increased number of data points. Nevertheless, the general
trends are similar to the results on the daily data. In particular,
the quantum model (executed with a simulator) got better AUC
scores than the classical model on 4 instances.


REFERENCES


[1] A. Davies, _Handbook of Condition Monitoring: Techniques and Method-_
_ology_ . Springer Science & Business Media, 1998.

[2] Y. Lei, B. Yang, X. Jiang, F. Jia, N. Li, and A. K. Nandi, “Applications
of machine learning to machine fault diagnosis: A review and roadmap,”
_Mechanical systems and signal processing_, vol. 138, p. 106587, 2020.

[3] O. Surucu, S. A. Gadsden, and J. Yawney, “Condition monitoring
using machine learning: A review of theory, applications, and recent
advances,” _Expert Systems with Applications_, vol. 221, p. 119738, 2023.

[4] L. I. Kuncheva and W. J. Faithfull, “Pca feature extraction for change
detection in multidimensional unlabeled data,” _IEEE transactions on_
_neural networks and learning systems_, vol. 25, no. 1, pp. 69–80, 2013.

[5] K. Faber, R. Corizzo, B. Sniezynski, M. Baron, and N. Japkowicz,
“Watch: Wasserstein change point detection for high-dimensional time
series data,” in _2021 IEEE International Conference on Big Data (Big_
_Data)_ . IEEE, 2021, pp. 4450–4459.

[6] A. J. Daley, I. Bloch, C. Kokail, S. Flannigan, N. Pearson, M. Troyer,
and P. Zoller, “Practical quantum advantage in quantum simulation,”
_Nature_, vol. 607, no. 7920, pp. 667–676, 2022.

[7] M. Cerezo, G. Verdon, H.-Y. Huang, L. Cincio, and P. J. Coles,
“Challenges and opportunities in quantum machine learning,” _Nature_
_computational science_, vol. 2, no. 9, pp. 567–576, 2022.

[8] H.-L. Huang, X.-Y. Xu, C. Guo, G. Tian, S.-J. Wei, X. Sun, W.-S. Bao,
and G.-L. Long, “Near-term quantum computing techniques: Variational
quantum algorithms, error mitigation, circuit compilation, benchmarking
and classical simulation,” _Science China Physics, Mechanics & Astron-_
_omy_, vol. 66, no. 5, p. 250302, 2023.


TABLE IV: AUC scores on raw resolution time series.


~~Quantum~~
Classical (Simulator)
~~Sequence 1~~ **0.998** ~~0.988~~
Sequence 2 0.907 **0.947**
Sequence 3 **1.000** **1.000**
Sequence 4 **1.000** **1.000**
Sequence 5 0.970 **1.000**
Sequence 6 0.999 **1.000**
Sequence 7 0.878 **1.000**


[9] Y. Kim, A. Eddins, S. Anand, K. X. Wei, E. Van Den Berg, S. Rosenblatt,
H. Nayfeh, Y. Wu, M. Zaletel, K. Temme _et al._, “Evidence for the
utility of quantum computing before fault tolerance,” _Nature_, vol. 618,
no. 7965, pp. 500–505, 2023.

[10] P. Mujal, R. Mart´ınez-Pe˜na, G. L. Giorgi, M. C. Soriano, and R. Zambrini, “Time-series quantum reservoir computing with weak and projective measurements,” _npj Quantum Information_, vol. 9, no. 1, p. 16,
2023.

[11] H.-Y. Huang, M. Broughton, M. Mohseni, R. Babbush, S. Boixo,
H. Neven, and J. R. McClean, “Power of data in quantum machine
learning,” _Nature communications_, vol. 12, no. 1, p. 2631, 2021.

[12] S. Aminikhanghahi and D. J. Cook, “A survey of methods for time series
change point detection,” _Knowledge and information systems_, vol. 51,
no. 2, pp. 339–367, 2017.

[13] M. Sugiyama, T. Kanamori, T. Suzuki, S. Hido, J. Sese, I. Takeuchi, and
L. Wang, “A density-ratio framework for statistical data processing,”
_IPSJ Transactions on Computer Vision and Applications_, vol. 1, pp.
183–208, 2009.

[14] S. Liu, M. Yamada, N. Collier, and M. Sugiyama, “Change-point
detection in time-series data by relative density-ratio estimation,” _Neural_
_Networks_, vol. 43, pp. 72–83, 2013.

[15] V. Havl´ıˇcek, A. D. C´orcoles, K. Temme, A. W. Harrow, A. Kandala,
J. M. Chow, and J. M. Gambetta, “Supervised learning with quantumenhanced feature spaces,” _Nature_, vol. 567, no. 7747, pp. 209–212, 2019.

[16] Y. Kawahara and M. Sugiyama, “Change-point detection in time-series
data by direct density-ratio estimation,” in _Proceedings of the 2009 SIAM_
_international conference on data mining_ . SIAM, 2009, pp. 389–400.

[17] R. Wiersema, C. Zhou, Y. de Sereville, J. F. Carrasquilla, Y. B. Kim,
and H. Yuen, “Exploring entanglement and optimization within the
Hamiltonian variational ansatz,” _PRX quantum_, vol. 1, no. 2, p. 020319,
2020.

[18] S. Shin, Y. S. Teo, and H. Jeong, “Dequantizing quantum machine
learning models using tensor networks,” _Physical Review Research_,
vol. 6, no. 2, p. 023218, 2024.

[19] S. Sim, P. D. Johnson, and A. Aspuru-Guzik, “Expressibility and entangling capability of parameterized quantum circuits for hybrid quantumclassical algorithms,” _Advanced Quantum Technologies_, vol. 2, no. 12,
p. 1900070, 2019.

[20] K. Kumaran, M. Sajjan, B. Pokharel, J. Gibbs, J. Cohn, B. Jones,
S. Mostame, S. Kais, and A. Banerjee, “Quantum simulation of superdiffusion breakdown in heisenberg chains via 2d interactions,” _arXiv_
_preprint arXiv:2503.14371_, 2025.

[21] Qiskit contributors, “Qiskit: An open-source framework for quantum
computing,” 2023.

[22] G. J. Van den Burg and C. K. Williams, “An evaluation of change point
detection algorithms,” _arXiv preprint arXiv:2003.06222_, 2020.

[23] E. Van Den Berg, Z. K. Minev, and K. Temme, “Model-free readouterror mitigation for quantum expectation values,” _Physical Review A_,
vol. 105, no. 3, p. 032620, 2022.

[24] M. Schuld, R. Sweke, and J. J. Meyer, “Effect of data encoding on
the expressive power of variational quantum-machine-learning models,”
_Physical Review A_, vol. 103, no. 3, p. 032430, 2021.


