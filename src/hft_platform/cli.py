import argparse
import asyncio
import json
import os
import subprocess
import sys
import textwrap
from importlib import import_module
from pathlib import Path
from typing import Any, Dict

from structlog import get_logger

from hft_platform.config.loader import (
    detect_live_credentials,
    load_settings,
    summarize_settings,
)
from hft_platform.utils.logging import configure_logging

logger = get_logger("cli")


def _safe_write(path: str, content: str):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w") as f:
        f.write(content)


def cmd_run(args: argparse.Namespace):
    mode = args.mode or args.mode_flag or _resolve_default_mode()
    cli_overrides: Dict[str, Any] = {
        "mode": mode,
        "symbols": args.symbols or None,
    }
    if args.strategy:
        cli_overrides["strategy"] = {
            "id": args.strategy,
            "module": args.strategy_module or "hft_platform.strategies.simple_mm",
            "class": args.strategy_class or "SimpleMarketMaker",
            "params": {},
        }
    settings, defaults = load_settings({k: v for k, v in cli_overrides.items() if v})

    downgraded = None
    if settings.get("mode") == "live" and not detect_live_credentials():
        downgraded = "sim"
        settings["mode"] = "sim"
        logger.warning("No Shioaji credentials found, downgrading to sim mode")

    summary = summarize_settings(settings, downgraded_mode=downgraded)
    print(f"[hft run] {summary}")
    if downgraded:
        print("Hint: set SHIOAJI_API_KEY / SHIOAJI_SECRET_KEY to enable live.")

    if settings.get("mode") == "replay":
        print("Replay mode not yet wired; please use backtest runner directly.")
        return

    # Live/Sim share the same runtime pipeline; sim runs with Shioaji stub.
    from prometheus_client import start_http_server

    from hft_platform.main import HFTSystem

    start_http_server(settings.get("prometheus_port", 9090))
    print(f"Prometheus metrics started on :{settings.get('prometheus_port', 9090)}")

    system = HFTSystem(settings)
    try:
        asyncio.run(system.run())
    except KeyboardInterrupt:
        print("Interrupted, shutting down...")


def _resolve_default_mode() -> str:
    raw = str(os.getenv("HFT_MODE", "sim")).strip().lower()
    if raw == "real":
        return "live"
    if raw not in {"sim", "live", "replay"}:
        return "sim"
    return raw


def cmd_init(args: argparse.Namespace):
    """Question-lite init that drops a settings.py and a strategy skeleton."""
    strategy_id = args.strategy_id or "my_strategy"
    symbol = args.symbol or "2330"
    settings_tpl = (
        textwrap.dedent(
            f"""
        # Generated by hft init
        def get_settings():
            return {{
                "mode": "sim",
                "symbols": ["{symbol}"],
                "strategy": {{
                    "id": "{strategy_id}",
                    "module": "hft_platform.strategies.{strategy_id}",
                    "class": "Strategy",
                    "params": {{}},
                }},
                "paths": {{
                    "symbols": "config/symbols.yaml",
                    "strategy_limits": "config/base/strategy_limits.yaml",
                    "order_adapter": "config/base/order_adapter.yaml",
                }},
                "prometheus_port": 9090,
            }}
        """
        ).strip()
        + "\n"
    )

    strategy_tpl = (
        textwrap.dedent(
            f"""
        from structlog import get_logger
        from hft_platform.events import LOBStatsEvent
        from hft_platform.strategy.base import BaseStrategy

        logger = get_logger("{strategy_id}")


        class Strategy(BaseStrategy):
            default_params = {{"min_spread": 100, "qty": 1}}

            def __init__(self, strategy_id: str, **params):
                super().__init__(strategy_id)
                self.params = {{**self.default_params, **(params or {{}})}}
                self.symbols = {{"{symbol}"}}

            def on_stats(self, event: LOBStatsEvent):
                if event.symbol not in self.symbols:
                    return
                if event.spread <= self.params["min_spread"]:
                    return
                self.buy(event.symbol, event.best_bid, self.params["qty"])
                logger.info("placing order", price=event.best_bid, params=self.params)
        """
        ).strip()
        + "\n"
    )

    test_tpl = (
        textwrap.dedent(
            f"""
        import pytest
        from hft_platform.core.pricing import PriceCodec, SymbolMetadataPriceScaleProvider
        from hft_platform.strategies.{strategy_id} import Strategy
        from hft_platform.contracts.strategy import OrderIntent
        from hft_platform.events import LOBStatsEvent
        from hft_platform.feed_adapter.normalizer import SymbolMetadata
        from hft_platform.strategy.base import StrategyContext


        def _intent_factory(**kwargs):
            kwargs.setdefault("intent_id", 1)
            kwargs.setdefault("timestamp_ns", 0)
            return OrderIntent(**kwargs)

        def test_strategy_emits_intent():
            strat = Strategy(strategy_id="{strategy_id}")
            metadata = SymbolMetadata()
            price_codec = PriceCodec(SymbolMetadataPriceScaleProvider(metadata))
            ctx = StrategyContext(
                positions={{}},
                strategy_id="{strategy_id}",
                intent_factory=_intent_factory,
                price_scaler=price_codec.scale,
                lob_source=None,
            )
            event = LOBStatsEvent(
                symbol="{symbol}",
                ts=0,
                imbalance=0.0,
                best_bid=1000000,
                best_ask=1000200,
                bid_depth=10,
                ask_depth=10,
            )
            intents = strat.handle_event(ctx, event)
            assert intents, "strategy should emit intent on wide spread"
        """
        ).strip()
        + "\n"
    )

    _safe_write("config/settings.py", settings_tpl)
    _safe_write(f"src/hft_platform/strategies/{strategy_id}.py", strategy_tpl)
    _safe_write(f"tests/test_{strategy_id}.py", test_tpl)

    print("Initialized settings and strategy skeleton.")
    print(f"- config/settings.py\n- src/hft_platform/strategies/{strategy_id}.py\n- tests/test_{strategy_id}.py")
    print("Next steps: `hft run sim --strategy {strategy_id}` or `pytest -k test_{strategy_id}`")


def cmd_check(args: argparse.Namespace):
    settings, defaults = load_settings()
    missing = []
    if not settings.get("symbols"):
        missing.append("symbols")
    strat = settings.get("strategy", {})
    if not strat.get("id"):
        missing.append("strategy.id")
    if missing:
        print("Config errors:", ", ".join(missing))
        sys.exit(1)

    print("Configuration is valid.")
    if args.export:
        out = "config/exported_settings." + args.export
        if args.export == "yaml":
            try:
                import yaml

                payload = yaml.safe_dump(settings)
            except Exception:
                payload = json.dumps(settings, indent=2)
        else:
            payload = json.dumps(settings, indent=2)
        _safe_write(out, payload)
        print(f"Exported effective settings to {out}")


def cmd_wizard(args: argparse.Namespace):
    from hft_platform.config.wizard import run_wizard

    run_wizard()


def cmd_feed_status(args: argparse.Namespace):
    print("Feed status command is lightweight; ensure service is running.")
    # Try reading Prometheus metrics if reachable
    import urllib.request

    try:
        resp = urllib.request.urlopen(f"http://localhost:{args.port}/metrics", timeout=1.5)
        body = resp.read().decode("utf-8")
        has_feed = "feed_events_total" in body
        print(f"Metrics reachable on :{args.port}; feed metric present={has_feed}")
    except Exception as exc:
        print(f"Unable to reach metrics on :{args.port}: {exc}")


def cmd_diag(args: argparse.Namespace):
    # Minimal diag stub
    print("Diag:")
    print("- Check metrics at http://localhost:9090/metrics")
    print("- Common fixes: verify credentials, check network, ensure queues not full.")


def cmd_strat_test(args: argparse.Namespace):
    settings, _ = load_settings()
    module_name = args.module or settings.get("strategy", {}).get("module", "hft_platform.strategies.simple_mm")
    class_name = args.cls or settings.get("strategy", {}).get("class", "SimpleMarketMaker")
    strategy_id = args.strategy_id or settings.get("strategy", {}).get("id", "demo")
    symbol = args.symbol or (settings.get("symbols") or ["2330"])[0]
    try:
        mod = import_module(module_name)
        cls = getattr(mod, class_name)
    except Exception as exc:
        print(f"Failed to import strategy {module_name}.{class_name}: {exc}")
        sys.exit(1)

    strat = cls(strategy_id=strategy_id)

    from hft_platform.contracts.strategy import OrderIntent
    from hft_platform.core.pricing import PriceCodec, SymbolMetadataPriceScaleProvider
    from hft_platform.events import LOBStatsEvent
    from hft_platform.feed_adapter.normalizer import SymbolMetadata
    from hft_platform.strategy.base import StrategyContext

    def _intent_factory(**kwargs):
        kwargs.setdefault("intent_id", 1)
        kwargs.setdefault("timestamp_ns", 0)
        return OrderIntent(**kwargs)

    metadata = SymbolMetadata(settings.get("paths", {}).get("symbols"))
    price_codec = PriceCodec(SymbolMetadataPriceScaleProvider(metadata))

    ctx = StrategyContext(
        positions={},
        strategy_id=strategy_id,
        intent_factory=_intent_factory,
        price_scaler=price_codec.scale,
        lob_source=None,
    )

    event = LOBStatsEvent(
        symbol=symbol,
        ts=0,
        imbalance=0.0,
        best_bid=99,
        best_ask=101,
        bid_depth=10,
        ask_depth=10,
    )
    intents = strat.handle_event(ctx, event)
    print(f"Strategy emitted {len(intents)} intents.")
    for it in intents:
        print(f"- {it}")


def cmd_backtest(args: argparse.Namespace):
    if args.backtest_cmd is None:
        print("Please specify backtest subcommand (convert|run)")
        sys.exit(1)

    if args.backtest_cmd == "convert":
        try:
            from hft_platform.backtest.convert import convert_jsonl_to_npz

            convert_jsonl_to_npz(args.input, args.output, scale=args.scale)
            print(f"Converted to {args.output}")
        except Exception as exc:
            print(f"Convert failed: {exc}")
            sys.exit(1)
        return

    if args.backtest_cmd == "run":
        try:
            from hft_platform.backtest.adapter import StrategyHbtAdapter
            from hft_platform.backtest.runner import HftBacktestConfig, HftBacktestRunner
        except Exception as exc:
            print(f"Failed to import backtest modules: {exc}")
            sys.exit(1)

        # If strategy provided, use adapter; else simple buy-hold runner.
        if args.strategy_module:
            if len(args.data) > 1:
                print("Strategy bridge currently supports single-asset backtest; provide one data file.")
                sys.exit(1)
            adapter = StrategyHbtAdapter(
                data_path=args.data[0],
                strategy_module=args.strategy_module,
                strategy_class=args.strategy_class or "SimpleMarketMaker",
                strategy_id=args.strategy_id or "demo",
                symbol=args.symbol or "2330",
                tick_size=args.tick_size,
                lot_size=args.lot_size,
                maker_fee=(args.fee_maker or 0.0),
                taker_fee=(args.fee_taker or 0.0),
                partial_fill=not args.no_partial_fill,
                price_scale=args.price_scale,
                timeout=args.timeout,
                seed=int(args.seed),
            )
            adapter.run()
            print("Strategy backtest completed.")
        else:
            if len(args.data) != 1:
                print("Backtest runner currently supports one data file; run one symbol/file per invocation.")
                sys.exit(1)
            cfg = HftBacktestConfig(
                data=args.data,
                symbols=args.symbols,
                tick_sizes=args.tick_sizes or [args.tick_size],
                lot_sizes=args.lot_sizes or [args.lot_size],
                latency_entry=args.latency_entry,
                latency_resp=args.latency_resp,
                fee_maker=args.fee_maker,
                fee_taker=args.fee_taker,
                partial_fill=not args.no_partial_fill,
                strict_equity=bool(args.strict_equity),
                record_out=args.record_out,
                report=args.report,
                seed=int(args.seed),
            )
            runner = HftBacktestRunner(cfg)
            result = runner.run()
            if result is None:
                print("Backtest failed.")
                sys.exit(1)
            print(
                "Backtest completed.",
                f"run_id={result.run_id}",
                f"config={result.config_hash}",
                f"pnl={result.pnl:.2f}",
                f"synthetic={result.used_synthetic_equity}",
                f"equity_points={result.equity_points}",
            )


def cmd_alpha_scaffold(args: argparse.Namespace):
    cmd = [sys.executable, "-m", "research.tools.alpha_scaffold", args.alpha_id, "--complexity", str(args.complexity)]
    for ref in args.paper or []:
        cmd.extend(["--paper", str(ref)])
    if args.force:
        cmd.append("--force")

    proc = subprocess.run(
        cmd,
        cwd=".",
        capture_output=True,
        text=True,
        check=False,
    )
    if proc.stdout.strip():
        print(proc.stdout.strip())
    if proc.returncode != 0:
        if proc.stderr.strip():
            print(proc.stderr.strip())
        sys.exit(proc.returncode or 1)


def cmd_alpha_search(args: argparse.Namespace):
    mode = str(args.mode)
    if mode == "template" and not args.template:
        print("--template is required for template mode")
        sys.exit(2)

    try:
        np = import_module("numpy")
        AlphaSearchEngine = import_module("research.combinatorial.search_engine").AlphaSearchEngine
    except Exception as exc:
        print(f"Failed to import alpha search engine: {exc}")
        sys.exit(1)

    source = np.load(args.data, allow_pickle=False)
    try:
        if isinstance(source, np.lib.npyio.NpzFile):
            if "data" in source:
                arr = np.asarray(source["data"])
            else:
                first_key = source.files[0] if source.files else None
                if first_key is None:
                    raise ValueError("Empty NPZ file")
                arr = np.asarray(source[first_key])
        else:
            arr = np.asarray(source)
    finally:
        if isinstance(source, np.lib.npyio.NpzFile):
            source.close()

    field_names = [f.strip() for f in str(args.feature_fields).split(",") if f.strip()]
    if not field_names:
        print("--feature-fields is required (comma separated)")
        sys.exit(2)

    features: dict[str, np.ndarray] = {}
    if arr.dtype.names:
        for field in field_names:
            if field not in arr.dtype.names:
                print(f"Feature field not found in data: {field}")
                sys.exit(2)
            features[field] = np.asarray(arr[field], dtype=np.float64)
        returns = np.asarray(arr[args.returns_field], dtype=np.float64) if args.returns_field else None
    else:
        for i, field in enumerate(field_names):
            if arr.ndim == 1:
                if i > 0:
                    print("Non-structured 1D data supports only one feature field")
                    sys.exit(2)
                features[field] = np.asarray(arr, dtype=np.float64)
            else:
                if i >= arr.shape[1]:
                    print(f"Feature index out of range for field '{field}'")
                    sys.exit(2)
                features[field] = np.asarray(arr[:, i], dtype=np.float64)
        if args.returns_field:
            print("--returns-field is only supported for structured arrays")
            sys.exit(2)
        returns = None

    engine = AlphaSearchEngine(
        features=features,
        returns=returns,
        random_seed=int(args.seed),
    )

    if mode == "random":
        results = engine.random_search(n_trials=int(args.trials))
    elif mode == "template":
        grid = _parse_param_grid(args.grid)
        results = engine.template_sweep(args.template, grid)
    else:
        results = engine.genetic_search(population=int(args.population), generations=int(args.generations))

    top_n = max(1, int(args.top))
    top_results = results[:top_n]
    payload: dict[str, Any] = {
        "mode": mode,
        "count": len(top_results),
        "results": [item.to_dict() for item in top_results],
    }

    if args.save_results:
        payload["results_path"] = engine.save_results(top_results, path=str(args.save_results))

    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))


def _parse_param_grid(raw: str | None) -> dict[str, list[Any]]:
    if not raw:
        return {}
    grid: dict[str, list[Any]] = {}
    pairs = [part.strip() for part in str(raw).split(";") if part.strip()]
    for pair in pairs:
        if "=" not in pair:
            raise ValueError(f"Invalid grid token: {pair}")
        key, val = pair.split("=", 1)
        items = [item.strip() for item in val.split(",") if item.strip()]
        casted: list[Any] = []
        for item in items:
            try:
                casted.append(int(item))
                continue
            except ValueError:
                pass
            try:
                casted.append(float(item))
                continue
            except ValueError:
                pass
            casted.append(item)
        grid[key.strip()] = casted
    return grid


def cmd_alpha_list(args: argparse.Namespace):
    try:
        from research.registry.alpha_registry import AlphaRegistry
    except Exception as exc:
        print(f"Failed to import research registry: {exc}")
        sys.exit(1)

    registry = AlphaRegistry()
    loaded = registry.discover("research/alphas")
    if not loaded:
        print("No alpha artifacts discovered.")
        return

    for alpha_id in sorted(loaded):
        manifest = loaded[alpha_id].manifest
        print(f"{alpha_id}\tstatus={manifest.status.value}\ttier={manifest.tier.value if manifest.tier else '-'}")

    if registry.errors:
        print("\nDiscovery warnings:")
        for msg in registry.errors:
            print(f"- {msg}")


def cmd_alpha_validate(args: argparse.Namespace):
    try:
        from hft_platform.alpha.validation import ValidationConfig, run_alpha_validation
    except Exception as exc:
        print(f"Failed to import alpha validation pipeline: {exc}")
        sys.exit(1)

    config = ValidationConfig(
        alpha_id=args.alpha_id,
        data_paths=[str(p) for p in args.data],
        is_oos_split=float(args.is_oos_split),
        signal_threshold=float(args.signal_threshold),
        max_position=int(args.max_position),
        min_sharpe_oos=float(args.min_sharpe_oos),
        max_abs_drawdown=float(args.max_abs_drawdown),
        skip_gate_b_tests=bool(args.skip_gate_b_tests),
        pytest_timeout_s=int(args.pytest_timeout),
        project_root=".",
        experiments_dir=str(args.experiments_dir),
    )
    result = run_alpha_validation(config)
    summary = result.to_dict()
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(summary, indent=2, sort_keys=True))
    print(json.dumps(summary, indent=2, sort_keys=True))
    if not result.passed:
        sys.exit(2)


def cmd_alpha_promote(args: argparse.Namespace):
    try:
        from hft_platform.alpha.promotion import PromotionConfig, promote_alpha
    except Exception as exc:
        print(f"Failed to import alpha promotion pipeline: {exc}")
        sys.exit(1)

    config = PromotionConfig(
        alpha_id=args.alpha_id,
        owner=args.owner,
        project_root=".",
        scorecard_path=args.scorecard,
        shadow_sessions=int(args.shadow_sessions),
        min_shadow_sessions=int(args.min_shadow_sessions),
        drift_alerts=int(args.drift_alerts),
        execution_reject_rate=float(args.execution_reject_rate),
        max_execution_reject_rate=float(args.max_execution_reject_rate),
        min_sharpe_oos=float(args.min_sharpe_oos),
        max_abs_drawdown=float(args.max_abs_drawdown),
        max_turnover=float(args.max_turnover),
        max_correlation=float(args.max_correlation),
        canary_weight=(None if args.canary_weight is None else float(args.canary_weight)),
        expiry_days=int(args.expiry_days),
        max_live_slippage_bps=float(args.max_live_slippage_bps),
        max_live_drawdown_contribution=float(args.max_live_drawdown_contribution),
        max_execution_error_rate=float(args.max_execution_error_rate),
        force=bool(args.force),
    )
    result = promote_alpha(config)
    summary = result.to_dict()
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(summary, indent=2, sort_keys=True))
    print(json.dumps(summary, indent=2, sort_keys=True))
    if not result.approved:
        sys.exit(2)


def cmd_alpha_rl_promote(args: argparse.Namespace):
    try:
        promote_latest_rl_run = import_module("research.rl.lifecycle").promote_latest_rl_run
    except Exception as exc:
        print(f"Failed to import RL lifecycle promotion utility: {exc}")
        sys.exit(1)

    result = promote_latest_rl_run(
        alpha_id=str(args.alpha_id),
        owner=str(args.owner),
        base_dir=str(args.base_dir),
        project_root=str(args.project_root),
        shadow_sessions=int(args.shadow_sessions),
        min_shadow_sessions=int(args.min_shadow_sessions),
        drift_alerts=int(args.drift_alerts),
        execution_reject_rate=float(args.execution_reject_rate),
        force=bool(args.force),
    )
    payload = result.to_dict()
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))
    if not result.approved:
        sys.exit(2)


def cmd_alpha_pool(args: argparse.Namespace):
    try:
        import importlib

        pool_mod = importlib.import_module("hft_platform.alpha.pool")
    except Exception as exc:
        print(f"Failed to import alpha pool utilities: {exc}")
        sys.exit(1)

    pool_cmd = getattr(args, "pool_cmd", "matrix")
    threshold = float(getattr(args, "threshold", None) if getattr(args, "threshold", None) is not None else 0.7)
    method = str(getattr(args, "method", "equal_weight"))
    ridge_alpha = float(getattr(args, "ridge_alpha", 0.1))
    min_uplift = float(getattr(args, "min_uplift", 0.05))
    alpha_id = getattr(args, "alpha_id", None)
    payload: dict[str, Any]

    if pool_cmd == "optimize":
        result = pool_mod.optimize_pool_weights(
            base_dir=args.base_dir,
            method=method,
            ridge_alpha=ridge_alpha,
        )
        payload = {"optimization": result.to_dict()}
    elif pool_cmd == "marginal":
        if not alpha_id:
            print("alpha pool marginal requires --alpha-id")
            sys.exit(2)
        payload = {
            "marginal": pool_mod.evaluate_marginal_alpha(
                alpha_id=str(alpha_id),
                base_dir=args.base_dir,
                method=method,
                min_uplift=min_uplift,
                ridge_alpha=ridge_alpha,
            )
        }
    else:
        matrix = pool_mod.compute_pool_matrix(base_dir=args.base_dir)
        payload = {"matrix": matrix}
        include_redundant = bool(getattr(args, "redundant", False)) or pool_cmd == "redundant"
        if include_redundant:
            metric = str(getattr(args, "corr_metric", "pearson"))
            try:
                payload["redundant"] = pool_mod.flag_redundant_pairs(matrix, threshold=threshold, metric=metric)
            except TypeError:
                # Backward compatibility for legacy helper signature without metric arg.
                payload["redundant"] = pool_mod.flag_redundant_pairs(matrix, threshold=threshold)
            payload["threshold"] = threshold
            payload["metric"] = metric

    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))


def cmd_alpha_canary_status(args: argparse.Namespace):
    try:
        from hft_platform.alpha.canary import CanaryMonitor
    except Exception as exc:
        print(f"Failed to import canary monitor: {exc}")
        sys.exit(1)

    monitor = CanaryMonitor(promotions_dir=args.promotions_dir)
    canaries = monitor.load_active_canaries()
    if not canaries:
        print("No active canaries found.")
        return

    payload = []
    for c in canaries:
        payload.append(
            {
                "alpha_id": c.get("alpha_id", "?"),
                "weight": c.get("weight", 0),
                "enabled": c.get("enabled", False),
                "path": c.get("_path", ""),
            }
        )
    print(json.dumps({"canaries": payload, "count": len(payload)}, indent=2, sort_keys=True))


def cmd_alpha_canary_evaluate(args: argparse.Namespace):
    try:
        from hft_platform.alpha.canary import CanaryMonitor
    except Exception as exc:
        print(f"Failed to import canary monitor: {exc}")
        sys.exit(1)

    monitor = CanaryMonitor(promotions_dir=args.promotions_dir)
    live_metrics = {
        "slippage_bps": float(args.slippage_bps),
        "drawdown_contribution": float(args.dd_contrib),
        "execution_error_rate": float(args.error_rate),
        "sessions_live": int(args.sessions),
    }
    if args.sharpe_live is not None:
        live_metrics["sharpe_live"] = float(args.sharpe_live)

    status = monitor.evaluate(args.alpha_id, live_metrics)
    payload = status.to_dict()

    if args.apply:
        monitor.apply_decision(status)
        payload["applied"] = True

    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))


def cmd_alpha_experiments_compare(args: argparse.Namespace):
    try:
        from hft_platform.alpha.experiments import ExperimentTracker
    except Exception as exc:
        print(f"Failed to import experiment tracker: {exc}")
        sys.exit(1)

    tracker = ExperimentTracker(base_dir=args.base_dir)
    rows = tracker.compare(run_ids=list(args.run_ids))
    payload = {"runs": rows, "count": len(rows)}
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))


def cmd_alpha_experiments_list(args: argparse.Namespace):
    try:
        from hft_platform.alpha.experiments import ExperimentTracker
    except Exception as exc:
        print(f"Failed to import experiment tracker: {exc}")
        sys.exit(1)

    tracker = ExperimentTracker(base_dir=args.base_dir)
    rows = [run.to_dict() for run in tracker.list_runs(alpha_id=args.alpha_id)]
    payload = {"runs": rows, "count": len(rows)}
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))


def cmd_alpha_experiments_best(args: argparse.Namespace):
    try:
        from hft_platform.alpha.experiments import ExperimentTracker
    except Exception as exc:
        print(f"Failed to import experiment tracker: {exc}")
        sys.exit(1)

    tracker = ExperimentTracker(base_dir=args.base_dir)
    rows = tracker.best_by_metric(
        metric=args.metric,
        n=int(args.top),
        alpha_id=args.alpha_id,
    )
    payload = {"metric": args.metric, "runs": rows, "count": len(rows)}
    if args.out:
        out_path = Path(args.out)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(payload, indent=2, sort_keys=True))
    print(json.dumps(payload, indent=2, sort_keys=True))


def cmd_resolve_symbols(args: argparse.Namespace):
    """Resolve TSE/OTC exchanges for a list of symbols or from config."""
    import shioaji as sj
    import yaml

    try:
        from hft_platform.config.loader import detect_live_credentials, load_settings
    except ImportError:

        def load_settings(cli_overrides: dict[str, Any] | None = None) -> tuple[dict[str, Any], dict[str, Any]]:
            return {}, {}

    # Get credentials
    api_key = os.environ.get("SHIOAJI_API_KEY")
    secret_key = os.environ.get("SHIOAJI_SECRET_KEY")

    if not api_key or not secret_key:
        print("Error: SHIOAJI_API_KEY and SHIOAJI_SECRET_KEY env vars required.")
        sys.exit(1)

    print("Initializing Shioaji (Simulation mode)...")
    api = sj.Shioaji(simulation=True)
    try:
        api.login(api_key=api_key, secret_key=secret_key, contracts_timeout=60000)
    except Exception as e:
        print(f"Login failed: {e}")
        sys.exit(1)

    # Get symbols
    symbols = args.symbols
    if not symbols:
        # Load from config/symbols.yaml or existing
        print("No symbols provided via args, please provide list.")
        sys.exit(1)

    print("Building contract map...")
    code_map = {}
    try:
        for c in api.Contracts.Stocks.TSE:
            code_map[c.code] = "TSE"
        for c in api.Contracts.Stocks.OTC:
            code_map[c.code] = "OTC"
    except Exception as e:
        print(f"Contract fetch warning: {e}")

    result = []
    for code in symbols:
        exch = code_map.get(code)
        if exch:
            result.append({"code": code, "exchange": exch})
        else:
            print(f"Warning: {code} not found in TSE/OTC contracts.")

    output_data = {"symbols": result}

    if args.output:
        with open(args.output, "w") as f:
            yaml.dump(output_data, f, sort_keys=False)
        print(f"Written to {args.output}")
    else:
        print(yaml.dump(output_data, sort_keys=False))


def _print_issues(errors: list[str], warnings: list[str]):
    if warnings:
        print("Warnings:")
        for msg in warnings[:20]:
            print(f"- {msg}")
        if len(warnings) > 20:
            print(f"... {len(warnings) - 20} more warnings")
    if errors:
        print("Errors:")
        for msg in errors[:20]:
            print(f"- {msg}")
        if len(errors) > 20:
            print(f"... {len(errors) - 20} more errors")


def cmd_symbols_build(args: argparse.Namespace):
    from hft_platform.config.symbols import (
        build_symbols,
        load_contract_cache,
        preview_lines,
        validate_symbols,
        write_symbols_yaml,
    )

    contract_index = None if args.no_contracts else load_contract_cache(args.contracts, args.metrics)
    result = build_symbols(args.list_path, contract_index)
    validation = validate_symbols(result.symbols, contract_index, max_subscriptions=args.max_subscriptions)

    errors = result.errors + validation.errors
    warnings = result.warnings + validation.warnings

    if args.preview:
        for line in preview_lines(result, sample=args.sample):
            print(line)

    if warnings or errors:
        _print_issues(errors, warnings)

    if errors:
        sys.exit(1)

    write_symbols_yaml(result.symbols, args.output)
    print(f"Written {len(result.symbols)} symbols to {args.output}")


def cmd_symbols_preview(args: argparse.Namespace):
    from hft_platform.config.symbols import build_symbols, load_contract_cache, preview_lines, validate_symbols

    contract_index = None if args.no_contracts else load_contract_cache(args.contracts, args.metrics)
    result = build_symbols(args.list_path, contract_index)
    validation = validate_symbols(result.symbols, contract_index, max_subscriptions=args.max_subscriptions)

    for line in preview_lines(result, sample=args.sample):
        print(line)

    errors = result.errors + validation.errors
    warnings = result.warnings + validation.warnings
    if warnings or errors:
        _print_issues(errors, warnings)

    if errors:
        sys.exit(1)


def cmd_symbols_validate(args: argparse.Namespace):
    from hft_platform.config.symbols import (
        ContractIndex,
        build_symbols,
        fetch_contracts_from_broker,
        load_contract_cache,
        load_metrics_cache,
        validate_symbols,
    )

    contract_index = None
    if args.online:
        contracts = fetch_contracts_from_broker()
        metrics = load_metrics_cache(args.metrics) if args.metrics else {}
        contract_index = ContractIndex(contracts=contracts, metrics_by_code=metrics)
    elif not args.no_contracts:
        contract_index = load_contract_cache(args.contracts, args.metrics)

    if args.symbols_path:
        import yaml

        with open(args.symbols_path, "r") as f:
            data = yaml.safe_load(f) or {}
        symbols = data.get("symbols", [])
    else:
        result = build_symbols(args.list_path, contract_index)
        symbols = result.symbols
        if result.errors:
            _print_issues(result.errors, result.warnings)
            sys.exit(1)

    validation = validate_symbols(symbols, contract_index, max_subscriptions=args.max_subscriptions)

    if validation.errors or validation.warnings:
        _print_issues(validation.errors, validation.warnings)

    if validation.errors:
        sys.exit(1)

    print("Configuration is valid.")


def cmd_symbols_sync(args: argparse.Namespace):
    from hft_platform.config.symbols import (
        ContractIndex,
        build_symbols,
        fetch_contracts_from_broker,
        load_metrics_cache,
        preview_lines,
        validate_symbols,
        write_contract_cache,
        write_symbols_yaml,
    )

    contracts = fetch_contracts_from_broker()
    write_contract_cache(contracts, args.contracts)
    metrics = load_metrics_cache(args.metrics) if args.metrics else {}
    contract_index = ContractIndex(contracts=contracts, metrics_by_code=metrics)

    result = build_symbols(args.list_path, contract_index)
    validation = validate_symbols(result.symbols, contract_index, max_subscriptions=args.max_subscriptions)

    errors = result.errors + validation.errors
    warnings = result.warnings + validation.warnings

    if args.preview:
        for line in preview_lines(result, sample=args.sample):
            print(line)

    if warnings or errors:
        _print_issues(errors, warnings)

    if errors:
        sys.exit(1)

    write_symbols_yaml(result.symbols, args.output)
    print(f"Written {len(result.symbols)} symbols to {args.output}")
    print(f"Contract cache saved to {args.contracts}")


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(prog="hft", description="HFT Platform CLI")
    sub = parser.add_subparsers(dest="command")

    # ... (Previous commands)

    config_cmd = sub.add_parser("config", help="Configuration utilities")
    config_sub = config_cmd.add_subparsers(dest="config_cmd")

    resolve = config_sub.add_parser("resolve", help="Resolve exchanges for symbols")
    resolve.add_argument("symbols", nargs="+", help="List of stock codes")
    resolve.add_argument("--output", help="Output YAML file path")
    resolve.set_defaults(func=cmd_resolve_symbols)

    build = config_sub.add_parser("build", help="Build symbols.yaml from symbols.list")
    build.add_argument("--list", dest="list_path", default="config/symbols.list", help="Input symbols list")
    build.add_argument("--output", default="config/symbols.yaml", help="Output symbols YAML")
    build.add_argument("--contracts", default="config/contracts.json", help="Contract cache path")
    build.add_argument("--metrics", default=None, help="Metrics cache path (optional)")
    build.add_argument("--no-contracts", action="store_true", help="Skip contract cache lookup")
    build.add_argument("--max-subscriptions", type=int, default=200, help="Subscription limit")
    build.add_argument("--preview", action="store_true", help="Show preview summary")
    build.add_argument("--sample", type=int, default=10, help="Preview sample size")
    build.set_defaults(func=cmd_symbols_build)

    preview = config_sub.add_parser("preview", help="Preview expanded symbols list")
    preview.add_argument("--list", dest="list_path", default="config/symbols.list", help="Input symbols list")
    preview.add_argument("--contracts", default="config/contracts.json", help="Contract cache path")
    preview.add_argument("--metrics", default=None, help="Metrics cache path (optional)")
    preview.add_argument("--no-contracts", action="store_true", help="Skip contract cache lookup")
    preview.add_argument("--max-subscriptions", type=int, default=200, help="Subscription limit")
    preview.add_argument("--sample", type=int, default=10, help="Preview sample size")
    preview.set_defaults(func=cmd_symbols_preview)

    validate = config_sub.add_parser("validate", help="Validate symbols configuration")
    validate.add_argument("--list", dest="list_path", default="config/symbols.list", help="Input symbols list")
    validate.add_argument("--symbols", dest="symbols_path", help="Validate an existing symbols.yaml")
    validate.add_argument("--contracts", default="config/contracts.json", help="Contract cache path")
    validate.add_argument("--metrics", default=None, help="Metrics cache path (optional)")
    validate.add_argument("--no-contracts", action="store_true", help="Skip contract cache lookup")
    validate.add_argument("--online", action="store_true", help="Validate against broker contracts")
    validate.add_argument("--max-subscriptions", type=int, default=200, help="Subscription limit")
    validate.set_defaults(func=cmd_symbols_validate)

    sync = config_sub.add_parser("sync", help="Sync broker contracts and build symbols.yaml")
    sync.add_argument("--list", dest="list_path", default="config/symbols.list", help="Input symbols list")
    sync.add_argument("--output", default="config/symbols.yaml", help="Output symbols YAML")
    sync.add_argument("--contracts", default="config/contracts.json", help="Contract cache path")
    sync.add_argument("--metrics", default=None, help="Metrics cache path (optional)")
    sync.add_argument("--max-subscriptions", type=int, default=200, help="Subscription limit")
    sync.add_argument("--preview", action="store_true", help="Show preview summary")
    sync.add_argument("--sample", type=int, default=10, help="Preview sample size")
    sync.set_defaults(func=cmd_symbols_sync)

    run = sub.add_parser("run", help="Run pipeline (sim|live|replay)")
    run.add_argument("mode", nargs="?", choices=["sim", "live", "replay"])
    run.add_argument("--mode", dest="mode_flag", choices=["sim", "live", "replay"])
    run.add_argument("--strategy", help="Strategy id to run")
    run.add_argument("--strategy-module", help="Override strategy module")
    run.add_argument("--strategy-class", help="Override strategy class")
    run.add_argument("--symbols", nargs="+", help="Symbols to load")
    run.set_defaults(func=cmd_run)

    init = sub.add_parser("init", help="Generate settings and strategy skeleton")
    init.add_argument("--strategy-id", help="Strategy id/name")
    init.add_argument("--symbol", help="Primary symbol")
    init.set_defaults(func=cmd_init)

    check = sub.add_parser("check", help="Validate settings")
    check.add_argument("--export", choices=["yaml", "json"], help="Export effective settings")
    check.set_defaults(func=cmd_check)

    wizard = sub.add_parser("wizard", help="Interactive configuration setup")
    wizard.set_defaults(func=cmd_wizard)

    feed = sub.add_parser("feed", help="Feed utilities")
    feed_sub = feed.add_subparsers(dest="feed_cmd")
    feed_status = feed_sub.add_parser("status", help="Check feed metrics")
    feed_status.add_argument("--port", type=int, default=9090)
    feed_status.set_defaults(func=cmd_feed_status)

    diag = sub.add_parser("diag", help="Quick diagnostics")
    diag.set_defaults(func=cmd_diag)

    strat = sub.add_parser("strat", help="Strategy helpers")
    strat_sub = strat.add_subparsers(dest="strat_cmd")
    strat_test = strat_sub.add_parser("test", help="Run a synthetic smoke test for strategy")
    strat_test.add_argument("--strategy-id", help="Strategy id")
    strat_test.add_argument("--module", help="Strategy module path")
    strat_test.add_argument("--cls", help="Strategy class name")
    strat_test.add_argument("--symbol", help="Symbol to test")
    strat_test.set_defaults(func=cmd_strat_test)

    backtest = sub.add_parser("backtest", help="Backtest utilities (convert/run)")
    back_sub = backtest.add_subparsers(dest="backtest_cmd")

    back_convert = back_sub.add_parser("convert", help="Convert JSONL feed to hftbacktest npz")
    back_convert.add_argument("--input", required=True, help="Input JSONL (our normalized events)")
    back_convert.add_argument("--output", required=True, help="Output npz path")
    back_convert.add_argument("--scale", type=int, default=10000, help="Price scale (default 10000)")
    back_convert.set_defaults(func=cmd_backtest)

    back_run = back_sub.add_parser("run", help="Run backtest using hftbacktest")
    back_run.add_argument("--data", nargs="+", required=True, help="NPZ paths containing hftbacktest event data")
    back_run.add_argument("--tick-size", type=float, default=0.01, help="Tick size")
    back_run.add_argument("--lot-size", type=float, default=1.0, help="Lot size")
    back_run.add_argument("--tick-sizes", nargs="+", type=float, help="Tick sizes per asset (align with data)")
    back_run.add_argument("--lot-sizes", nargs="+", type=float, help="Lot sizes per asset (align with data)")
    back_run.add_argument("--symbols", nargs="+", help="Symbols per asset (align with data)")
    back_run.add_argument("--record-out", help="Path to save recorder output npz")
    back_run.add_argument("--strategy-module", help="Strategy module path for adapter")
    back_run.add_argument("--strategy-class", help="Strategy class for adapter")
    back_run.add_argument("--strategy-id", help="Strategy id", default="demo")
    back_run.add_argument("--symbol", help="Symbol", default="2330")
    back_run.add_argument("--price-scale", type=int, default=10000, help="Price scale used by strategy ints")
    back_run.add_argument("--timeout", type=int, default=0, help="wait_next_feed timeout (0 = no timeout)")
    back_run.add_argument("--latency-entry", type=float, help="Order entry latency for backtest")
    back_run.add_argument("--latency-resp", type=float, help="Order response latency for backtest")
    back_run.add_argument("--fee-maker", type=float, help="Maker fee (per value, negative for rebate)")
    back_run.add_argument("--fee-taker", type=float, help="Taker fee (per value, negative for rebate)")
    back_run.add_argument("--seed", type=int, default=42, help="Deterministic random seed")
    back_run.add_argument(
        "--no-partial-fill", action="store_true", help="Disable partial fill (use no_partial_fill_exchange)"
    )
    back_run.add_argument(
        "--strict-equity", action="store_true", help="Fail run if real equity extraction is unavailable"
    )
    back_run.add_argument("--report", action="store_true", help="Generate HTML Tearsheet")
    back_run.set_defaults(func=cmd_backtest)

    alpha = sub.add_parser("alpha", help="Alpha research pipeline utilities")
    alpha_sub = alpha.add_subparsers(dest="alpha_cmd")

    alpha_list = alpha_sub.add_parser("list", help="List discovered research alphas")
    alpha_list.set_defaults(func=cmd_alpha_list)

    alpha_scaffold = alpha_sub.add_parser("scaffold", help="Scaffold a new research alpha artifact")
    alpha_scaffold.add_argument("alpha_id", help="Immutable alpha id (e.g. ofi_mc_v2)")
    alpha_scaffold.add_argument("--paper", action="append", default=[], help="Paper reference (repeatable)")
    alpha_scaffold.add_argument("--complexity", default="O1", help="Complexity target, e.g. O1 or ON")
    alpha_scaffold.add_argument("--force", action="store_true", help="Overwrite existing files")
    alpha_scaffold.set_defaults(func=cmd_alpha_scaffold)

    alpha_search = alpha_sub.add_parser("search", help="Run combinatorial alpha search")
    alpha_search.add_argument("--mode", choices=["random", "template", "genetic"], default="random")
    alpha_search.add_argument("--data", required=True, help="Input npy/npz data path")
    alpha_search.add_argument("--feature-fields", required=True, help="Comma-separated feature field names")
    alpha_search.add_argument("--returns-field", help="Structured array field name for forward returns")
    alpha_search.add_argument("--trials", type=int, default=100, help="Random search trials")
    alpha_search.add_argument("--template", help="Template expression for template mode")
    alpha_search.add_argument(
        "--grid",
        help="Template parameter grid, e.g. 'w=5,10,20;lag=1,2'",
    )
    alpha_search.add_argument("--population", type=int, default=40, help="Genetic search population")
    alpha_search.add_argument("--generations", type=int, default=10, help="Genetic search generations")
    alpha_search.add_argument("--seed", type=int, default=42, help="Random seed")
    alpha_search.add_argument("--top", type=int, default=10, help="Top-N results in output")
    alpha_search.add_argument("--save-results", help="Optional path to persist result artifacts")
    alpha_search.add_argument("--out", help="Optional JSON output path")
    alpha_search.set_defaults(func=cmd_alpha_search)

    alpha_validate = alpha_sub.add_parser("validate", help="Run alpha validation pipeline (Gate A-C)")
    alpha_validate.add_argument("--alpha-id", required=True, help="Alpha id under research/alphas")
    alpha_validate.add_argument("--data", nargs="+", required=True, help="npy/npz path(s) for validation")
    alpha_validate.add_argument("--is-oos-split", type=float, default=0.7, help="IS ratio for temporal split")
    alpha_validate.add_argument("--signal-threshold", type=float, default=0.3, help="Signal threshold")
    alpha_validate.add_argument("--max-position", type=int, default=5, help="Max absolute position")
    alpha_validate.add_argument("--min-sharpe-oos", type=float, default=0.0, help="Gate C minimum OOS Sharpe")
    alpha_validate.add_argument("--max-abs-drawdown", type=float, default=0.3, help="Gate C max absolute drawdown")
    alpha_validate.add_argument("--skip-gate-b-tests", action="store_true", help="Skip per-alpha pytest in Gate B")
    alpha_validate.add_argument("--pytest-timeout", type=int, default=300, help="Gate B timeout in seconds")
    alpha_validate.add_argument(
        "--experiments-dir",
        default="research/experiments",
        help="Directory to store experiment run artifacts",
    )
    alpha_validate.add_argument("--out", help="Optional summary JSON output path")
    alpha_validate.set_defaults(func=cmd_alpha_validate)

    alpha_promote = alpha_sub.add_parser("promote", help="Run promotion pipeline (Gate D-E) and write canary config")
    alpha_promote.add_argument("--alpha-id", required=True, help="Alpha id under research/alphas")
    alpha_promote.add_argument("--owner", required=True, help="Promotion owner")
    alpha_promote.add_argument("--scorecard", help="Optional scorecard path override")
    alpha_promote.add_argument("--shadow-sessions", type=int, default=0, help="Observed shadow sessions")
    alpha_promote.add_argument("--min-shadow-sessions", type=int, default=5, help="Required shadow sessions for Gate E")
    alpha_promote.add_argument("--drift-alerts", type=int, default=0, help="Drift alerts count from shadow run")
    alpha_promote.add_argument(
        "--execution-reject-rate", type=float, default=0.0, help="Observed reject rate in shadow run"
    )
    alpha_promote.add_argument(
        "--max-execution-reject-rate", type=float, default=0.01, help="Gate E max acceptable reject rate"
    )
    alpha_promote.add_argument("--min-sharpe-oos", type=float, default=1.0, help="Gate D minimum OOS Sharpe")
    alpha_promote.add_argument("--max-abs-drawdown", type=float, default=0.2, help="Gate D max absolute drawdown")
    alpha_promote.add_argument("--max-turnover", type=float, default=2.0, help="Gate D max turnover")
    alpha_promote.add_argument("--max-correlation", type=float, default=0.7, help="Gate D max correlation to pool")
    alpha_promote.add_argument("--canary-weight", type=float, help="Override canary weight")
    alpha_promote.add_argument("--expiry-days", type=int, default=30, help="Expiry review date offset")
    alpha_promote.add_argument("--max-live-slippage-bps", type=float, default=3.0, help="Rollback slippage threshold")
    alpha_promote.add_argument(
        "--max-live-drawdown-contribution", type=float, default=0.02, help="Rollback drawdown contribution threshold"
    )
    alpha_promote.add_argument(
        "--max-execution-error-rate", type=float, default=0.01, help="Rollback execution error rate"
    )
    alpha_promote.add_argument("--force", action="store_true", help="Force-write promotion config even if gates fail")
    alpha_promote.add_argument("--out", help="Optional summary JSON output path")
    alpha_promote.set_defaults(func=cmd_alpha_promote)

    alpha_rl_promote = alpha_sub.add_parser(
        "rl-promote",
        help="Promote latest RL run using the same Gate D-E pipeline",
    )
    alpha_rl_promote.add_argument("--alpha-id", required=True, help="RL alpha id")
    alpha_rl_promote.add_argument("--owner", required=True, help="Promotion owner")
    alpha_rl_promote.add_argument("--base-dir", default="research/experiments", help="RL experiment base dir")
    alpha_rl_promote.add_argument("--project-root", default=".", help="Project root for promotion config output")
    alpha_rl_promote.add_argument("--shadow-sessions", type=int, default=0, help="Observed shadow sessions")
    alpha_rl_promote.add_argument(
        "--min-shadow-sessions", type=int, default=5, help="Required shadow sessions for Gate E"
    )
    alpha_rl_promote.add_argument("--drift-alerts", type=int, default=0, help="Drift alerts count")
    alpha_rl_promote.add_argument("--execution-reject-rate", type=float, default=0.0, help="Observed reject rate")
    alpha_rl_promote.add_argument(
        "--force", action="store_true", help="Force-write promotion config even if gates fail"
    )
    alpha_rl_promote.add_argument("--out", help="Optional summary JSON output path")
    alpha_rl_promote.set_defaults(func=cmd_alpha_rl_promote)

    alpha_pool = alpha_sub.add_parser("pool", help="Show alpha pool correlation matrix from latest experiment runs")
    alpha_pool.add_argument(
        "pool_cmd",
        nargs="?",
        choices=["matrix", "redundant", "optimize", "marginal"],
        default="matrix",
        help="pool mode (matrix/redundant/optimize/marginal)",
    )
    alpha_pool.add_argument("--base-dir", default="research/experiments", help="Experiment base dir")
    alpha_pool.add_argument("--threshold", type=float, default=None, help="Redundant correlation threshold")
    alpha_pool.add_argument(
        "--corr-metric", choices=["pearson", "spearman"], default="pearson", help="Correlation metric"
    )
    alpha_pool.add_argument("--redundant", action="store_true", help="Include redundant pair detection")
    alpha_pool.add_argument(
        "--method",
        choices=["equal_weight", "ic_weighted", "mean_variance", "ridge"],
        default="equal_weight",
        help="Pool weight optimization method",
    )
    alpha_pool.add_argument("--ridge-alpha", type=float, default=0.1, help="Ridge regularization strength")
    alpha_pool.add_argument("--alpha-id", help="Target alpha id for pool marginal contribution test")
    alpha_pool.add_argument(
        "--min-uplift", type=float, default=0.05, help="Minimum uplift for marginal contribution pass"
    )
    alpha_pool.add_argument("--out", help="Optional JSON output path")
    alpha_pool.set_defaults(func=cmd_alpha_pool)

    alpha_canary = alpha_sub.add_parser("canary", help="Canary monitor for promoted alphas")
    alpha_canary_sub = alpha_canary.add_subparsers(dest="canary_cmd")

    canary_status = alpha_canary_sub.add_parser("status", help="List all active canaries")
    canary_status.add_argument(
        "--promotions-dir", default="config/strategy_promotions", help="Promotions YAML directory"
    )
    canary_status.set_defaults(func=cmd_alpha_canary_status)

    canary_eval = alpha_canary_sub.add_parser("evaluate", help="Evaluate canary metrics")
    canary_eval.add_argument("--alpha-id", required=True, help="Alpha id to evaluate")
    canary_eval.add_argument("--slippage-bps", type=float, default=0.0, help="Live slippage in bps")
    canary_eval.add_argument("--dd-contrib", type=float, default=0.0, help="Live drawdown contribution")
    canary_eval.add_argument("--error-rate", type=float, default=0.0, help="Live execution error rate")
    canary_eval.add_argument("--sessions", type=int, default=0, help="Number of live sessions")
    canary_eval.add_argument("--sharpe-live", type=float, default=None, help="Live Sharpe ratio (for escalation)")
    canary_eval.add_argument("--apply", action="store_true", help="Apply decision (modify YAML)")
    canary_eval.add_argument("--promotions-dir", default="config/strategy_promotions", help="Promotions YAML directory")
    canary_eval.add_argument("--out", help="Optional JSON output path")
    canary_eval.set_defaults(func=cmd_alpha_canary_evaluate)

    alpha_exp = alpha_sub.add_parser("experiments", help="Experiment tracking utilities")
    alpha_exp_sub = alpha_exp.add_subparsers(dest="alpha_exp_cmd")

    alpha_exp_list = alpha_exp_sub.add_parser("list", help="List experiment runs")
    alpha_exp_list.add_argument("--base-dir", default="research/experiments", help="Experiment base dir")
    alpha_exp_list.add_argument("--alpha-id", help="Filter by alpha id")
    alpha_exp_list.add_argument("--out", help="Optional JSON output path")
    alpha_exp_list.set_defaults(func=cmd_alpha_experiments_list)

    alpha_exp_compare = alpha_exp_sub.add_parser("compare", help="Compare experiment runs by run_id")
    alpha_exp_compare.add_argument("run_ids", nargs="+", help="Run IDs to compare")
    alpha_exp_compare.add_argument("--base-dir", default="research/experiments", help="Experiment base dir")
    alpha_exp_compare.add_argument("--out", help="Optional JSON output path")
    alpha_exp_compare.set_defaults(func=cmd_alpha_experiments_compare)

    alpha_exp_best = alpha_exp_sub.add_parser("best", help="List best runs by metric")
    alpha_exp_best.add_argument("--metric", default="sharpe_oos", help="Metric name")
    alpha_exp_best.add_argument("--top", type=int, default=10, help="Top N runs")
    alpha_exp_best.add_argument("--alpha-id", help="Filter by alpha id")
    alpha_exp_best.add_argument("--base-dir", default="research/experiments", help="Experiment base dir")
    alpha_exp_best.add_argument("--out", help="Optional JSON output path")
    alpha_exp_best.set_defaults(func=cmd_alpha_experiments_best)

    return parser


def main(argv=None):
    configure_logging()
    parser = build_parser()
    args = parser.parse_args(argv)
    if not hasattr(args, "func"):
        parser.print_help()
        return 1
    args.func(args)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
