# Tasks – Backtest & Analytics

| ID | Title | Description & Acceptance | Dependencies |
| --- | --- | --- | --- |
| T1 | Define backtest schemas & configs | Add ClickHouse DDLs for `backtest_runs`, `backtest_timeseries`, and supporting views (order behavior, PnL attribution). Create config schemas for latency/slippage profiles and backtest runs. **Acceptance**: schemas applied to CH; reviewed with analytics team. | — |
| T2 | Implement ClickHouse streaming client | Build data-access layer that streams `market_data` (and other tables) in symbol/date chunks, with optional Parquet export for reuse. **Acceptance**: unit tests show deterministic ordering and bounded memory use; CLI can export a sample slice. | T1 |
| T3 | Build ClickHouseReplayFeed | Create feed component that replays events onto the bus from streamed data, feeding StrategyRunner just like live mode. **Acceptance**: integration test replays sample day and strategies receive events in correct order. | T2 |
| T4 | Implement SimulatedBroker | Replace OrderAdapter with a simulated broker using configurable latency/slippage models (top-5 depth, passive fills) and producing `OrderEvent`/`FillEvent`. **Acceptance**: unit tests cover aggressive/passive scenarios; integration run shows fills generated. | T3 |
| T5 | Create BacktestRunner & CLI | Wire feed, StrategyRunner, RiskEngine, SimulatedBroker, and PositionStore into a runner with Python API and CLI. Support config files (symbols, date range, latency profile). **Acceptance**: CLI runs a short backtest end-to-end and reports run ID. | T3, T4 |
| T6 | Persist run outputs | Implement writers for `backtest_runs` summaries and `backtest_timeseries` curves; add ability to tag runs with config hash/git commit. **Acceptance**: after sample run, tables contain summary/time-series rows referencing run ID. | T5 |
| T7 | Notebook templates & analytics views | Provide Jupyter notebooks for factor analysis, slippage studies, and run result visualization; define ClickHouse views for order behavior and PnL attribution. **Acceptance**: notebooks executed successfully; views return expected aggregates. | T6 |
| T8 | Parallel execution support | Add utilities (multiprocessing/joblib/dask) to run multiple configs/symbols in parallel with isolation of strategy instances. **Acceptance**: demo grid-search run executes N configs concurrently and records separate run IDs. | T5 |
| T9 | Testing & validation suite | Develop regression tests for latency models, fill logic, reproducibility (same config → same results), and performance (≥10k events/s). **Acceptance**: CI suite passes; documentation updated to describe test coverage. | T2–T8 |
